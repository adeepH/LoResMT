{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT-mr-en.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikpuranik11/LoResMT/blob/main/MT_mr_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE4MO-8bDtwD",
        "outputId": "1bc532f1-f59f-4d92-99c9-f8743dc17f5f"
      },
      "source": [
        "# create a seperate folder to store everything\n",
        "!mkdir finetuning\n",
        "%cd finetuning"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/finetuning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2Rs6_WkD_gF",
        "outputId": "7c1074ff-9ac4-42d6-cdeb-116e965a4ebf"
      },
      "source": [
        "# clone the repo for running finetuning\n",
        "!git clone https://github.com/AI4Bharat/indicTrans.git\n",
        "%cd indicTrans\n",
        "# clone requirements repositories\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!git clone https://github.com/rsennrich/subword-nmt.git\n",
        "%cd .."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indicTrans'...\n",
            "remote: Enumerating objects: 432, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 432 (delta 122), reused 105 (delta 105), pack-reused 293\u001b[K\n",
            "Receiving objects: 100% (432/432), 1.43 MiB | 6.61 MiB/s, done.\n",
            "Resolving deltas: 100% (248/248), done.\n",
            "/content/finetuning/indicTrans\n",
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1325, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 1325 (delta 84), reused 89 (delta 41), pack-reused 1178\u001b[K\n",
            "Receiving objects: 100% (1325/1325), 9.57 MiB | 13.13 MiB/s, done.\n",
            "Resolving deltas: 100% (688/688), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 29.50 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 580, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 580 (delta 0), reused 1 (delta 0), pack-reused 576\u001b[K\n",
            "Receiving objects: 100% (580/580), 237.41 KiB | 1.14 MiB/s, done.\n",
            "Resolving deltas: 100% (349/349), done.\n",
            "/content/finetuning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duwTvJ9xEBJ1",
        "outputId": "a2c54535-52c4-4dce-bec6-3b69b0d951b6"
      },
      "source": [
        "! sudo apt install tree\n",
        "\n",
        "# Install the necessary libraries\n",
        "!pip install sacremoses pandas mock sacrebleu tensorboardX pyarrow indic-nlp-library\n",
        "# Install fairseq from source\n",
        "!git clone https://github.com/pytorch/fairseq.git\n",
        "%cd fairseq\n",
        "# !git checkout da9eaba12d82b9bfc1442f0e2c6fc1b895f4d35d\n",
        "!pip install --editable ./\n",
        "%cd .."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 40.7 kB of archives.\n",
            "After this operation, 105 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n",
            "Fetched 40.7 kB in 0s (89.6 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.5MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 57.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Collecting indic-nlp-library\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/d4/495bb43b88a2a6d04b09c29fc5115f24872af74cd8317fe84026abd4ddb1/indic_nlp_library-0.81-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Collecting sphinx-rtd-theme\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/24/2475e8f83519b54b2148d4a56eb1111f9cec630d088c3ffc214492c12107/sphinx_rtd_theme-0.5.2-py2.py3-none-any.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2MB 38.7MB/s \n",
            "\u001b[?25hCollecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Collecting sphinx-argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/06/2b/dfad6a1831c3aeeae25d8d3d417224684befbf45e10c7f2141631616a6ed/sphinx-argparse-0.2.5.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (57.0.0)\n",
            "Collecting docutils<0.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/44/8a15e45ffa96e6cf82956dd8d7af9e666357e16b0d93b253903475ee947f/docutils-0.16-py2.py3-none-any.whl (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 46.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (1.8.5)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.6.1)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.9.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.11.3)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (0.7.12)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (20.9)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (1.2.4)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (1.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->sphinx-rtd-theme->indic-nlp-library) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->sphinx-rtd-theme->indic-nlp-library) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->sphinx-rtd-theme->indic-nlp-library) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->sphinx-rtd-theme->indic-nlp-library) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx->sphinx-rtd-theme->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx->sphinx-rtd-theme->indic-nlp-library) (2.4.7)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->sphinx-rtd-theme->indic-nlp-library) (1.1.5)\n",
            "Building wheels for collected packages: sphinx-argparse\n",
            "  Building wheel for sphinx-argparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sphinx-argparse: filename=sphinx_argparse-0.2.5-cp37-none-any.whl size=11552 sha256=3ab85e18a76f7ea2d29c928b37beef6c226c208832c2fbf505a3f7e8085f9a55\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/18/1b/4990a1859da4edc77ab312bc2986c08d2733fb5713d06e44f5\n",
            "Successfully built sphinx-argparse\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, mock, portalocker, sacrebleu, tensorboardX, docutils, sphinx-rtd-theme, morfessor, sphinx-argparse, indic-nlp-library\n",
            "  Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "Successfully installed docutils-0.16 indic-nlp-library-0.81 mock-4.0.3 morfessor-2.0.6 portalocker-2.0.0 sacrebleu-1.5.1 sacremoses-0.0.45 sphinx-argparse-0.2.5 sphinx-rtd-theme-0.5.2 tensorboardX-2.2\n",
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 28331, done.\u001b[K\n",
            "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 28331 (delta 62), reused 120 (delta 48), pack-reused 28181\u001b[K\n",
            "Receiving objects: 100% (28331/28331), 11.93 MiB | 19.02 MiB/s, done.\n",
            "Resolving deltas: 100% (21266/21266), done.\n",
            "/content/finetuning/fairseq\n",
            "Obtaining file:///content/finetuning/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc77eeb) (1.14.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc77eeb) (0.29.23)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc77eeb) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc77eeb) (4.41.1)\n",
            "Collecting hydra-core<1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e3/fbd70dd0d3ce4d1d75c22d56c0c9f895cfa7ed6587a9ffb821d6812d6a60/hydra_core-1.0.6-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc77eeb) (1.19.5)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc77eeb) (1.5.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc77eeb) (1.9.0+cu102)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+fc77eeb) (2.20)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+fc77eeb) (5.1.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+fc77eeb) (3.7.4.3)\n",
            "Collecting PyYAML>=5.1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+fc77eeb) (2.0.0)\n",
            "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core<1.1->fairseq==1.0.0a0+fc77eeb) (3.4.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=5781ae6f9c241fd62c3462c9852a0356980dfd2ebd13ce4c6be81dc69cb8230f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, PyYAML, omegaconf, hydra-core, fairseq\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 fairseq hydra-core-1.0.6 omegaconf-2.0.6\n",
            "/content/finetuning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD2EHQdqEH70",
        "outputId": "e3e148ce-129c-47af-bfc0-c714276b23ac"
      },
      "source": [
        "# download the indictrans model\n",
        "\n",
        "\n",
        "# downloading the en-indic model\n",
        "# this will contain:\n",
        "# en-indic/\n",
        "# ├── final_bin                          # contains fairseq dictionaries (we will use this to binarize the new finetuning data)\n",
        "# │   ├── dict.SRC.txt\n",
        "# │   └── dict.TGT.txt\n",
        "# ├── model                              # contains model checkpoint(s)\n",
        "# │   └── checkpoint_best.pt\n",
        "# └── vocab                              # contains bpes for src and tgt (since we train seperate vocabularies) generated with subword_nmt (we will use this bpes to convert finetuning data to subwords)\n",
        "#     ├── bpe_codes.32k.SRC\n",
        "#     ├── bpe_codes.32k.TGT\n",
        "#     ├── vocab.SRC\n",
        "#     └── vocab.TGT\n",
        "\n",
        "\n",
        "\n",
        "!wget https://storage.googleapis.com/samanantar-public/V0.2/models/indic-en.zip\n",
        "!unzip indic-en.zip\n",
        "\n",
        "# if you want to finetune indic-en models, use the link below\n",
        "\n",
        "# !wget https://akpublicdata.blob.core.windows.net/indicnlp/indictrans/indictrans-indic-en-v0.2.zip\n",
        "# !unzip indictrans-indic-en-v0.2.zip\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-21 09:23:46--  https://storage.googleapis.com/samanantar-public/V0.2/models/indic-en.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.101.128, 142.251.2.128, 142.250.141.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.101.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4551079075 (4.2G) [application/zip]\n",
            "Saving to: ‘indic-en.zip’\n",
            "\n",
            "indic-en.zip        100%[===================>]   4.24G  44.6MB/s    in 85s     \n",
            "\n",
            "2021-06-21 09:25:12 (51.0 MB/s) - ‘indic-en.zip’ saved [4551079075/4551079075]\n",
            "\n",
            "Archive:  indic-en.zip\n",
            "   creating: indic-en/\n",
            "   creating: indic-en/vocab/\n",
            "  inflating: indic-en/vocab/bpe_codes.32k.SRC  \n",
            "  inflating: indic-en/vocab/vocab.SRC  \n",
            "  inflating: indic-en/vocab/vocab.TGT  \n",
            "  inflating: indic-en/vocab/bpe_codes.32k.TGT  \n",
            "   creating: indic-en/final_bin/\n",
            "  inflating: indic-en/final_bin/dict.TGT.txt  \n",
            "  inflating: indic-en/final_bin/dict.SRC.txt  \n",
            "   creating: indic-en/model/\n",
            "  inflating: indic-en/model/checkpoint_best.pt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF4GladJ1W9e",
        "outputId": "a2e67949-d2e5-4b7c-ab38-f17effbe7b3e"
      },
      "source": [
        "!sudo apt-get install p7zip-full"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1WkK7RQyK5G"
      },
      "source": [
        "!mkdir /content/finetuning/dataset\n",
        "!mkdir /content/finetuning/dataset/train\n",
        "!mkdir /content/finetuning/dataset/dev\n",
        "!mkdir /content/finetuning/dataset/test\n",
        "!mkdir /content/finetuning/dataset/train/en-mr"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1KlcCvHeyvZ",
        "outputId": "5862a4b9-9b50-4ea0-a7ec-5ad3df2e750d"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AOrU9KHz2SS",
        "outputId": "0a0b037c-b259-430d-fa8e-520d56972fb9"
      },
      "source": [
        "!7z x /content/en_mr.zip\n",
        "#password loresmt2021@covidmr"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 1667350 bytes (1629 KiB)\n",
            "\n",
            "Extracting archive: /content/en_mr.zip\n",
            "--\n",
            "Path = /content/en_mr.zip\n",
            "Type = zip\n",
            "Physical Size = 1667350\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Enter password (will not be echoed):\n",
            "  0% - dev.en\b\b\b\b\b\b\b\b\b\b\b\b\b             \b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Would you like to replace the existing file:\n",
            "  Path:     ./train.en\n",
            "  Size:     2097152 bytes (2048 KiB)\n",
            "  Modified: 2021-06-21 09:23:34\n",
            "with the file from archive:\n",
            "  Path:     train.en\n",
            "  Size:     2198689 bytes (2148 KiB)\n",
            "  Modified: 2021-06-02 06:05:24\n",
            "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? y\n",
            "\n",
            "  3% 2 - train.en\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Would you like to replace the existing file:\n",
            "  Path:     ./train.mr\n",
            "  Size:     2097152 bytes (2048 KiB)\n",
            "  Modified: 2021-06-21 09:23:35\n",
            "with the file from archive:\n",
            "  Path:     train.mr\n",
            "  Size:     5537529 bytes (5408 KiB)\n",
            "  Modified: 2021-06-02 06:05:50\n",
            "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? y\n",
            "\n",
            " 31% 3 - train.mr\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 4\n",
            "Size:       8026001\n",
            "Compressed: 1667350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKYGc9Nk2Sbg"
      },
      "source": [
        "!cp /content/dev.en /content/finetuning/dataset/dev\n",
        "!cp /content/dev.mr /content/finetuning/dataset/dev"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXfTb2Zu2pE1"
      },
      "source": [
        "!mv /content/dev.en /content/finetuning/dataset/test/\n",
        "!mv /content/dev.mr /content/finetuning/dataset/test/"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzyPcs4O3bDc"
      },
      "source": [
        "!mv /content/train.en /content/finetuning/dataset/train/en-mr\n",
        "!mv /content/train.mr /content/finetuning/dataset/train/en-mr"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBtJOKgDHEyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c153a7-40d7-420d-ad53-2e6c8aa776b3"
      },
      "source": [
        "%cd /content/finetuning/dataset/train/en-mr"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/finetuning/dataset/train/en-mr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLmOqPTvHJuN"
      },
      "source": [
        "%cat *.mr > train1.mr"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2jAutJB4Dqg",
        "outputId": "0e0ce52a-46fc-48fe-c651-f894a2340dc7"
      },
      "source": [
        "%cd /content/finetuning/indicTrans"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/finetuning/indicTrans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yPTbM_clKfI",
        "outputId": "9f494dfd-734b-470a-9758-314dad99700a"
      },
      "source": [
        "%%shell\n",
        "\n",
        "exp_dir=../dataset\n",
        "src_lang=indic\n",
        "tgt_lang=en\n",
        "\n",
        "# change this to indic-en, if you have downloaded the indic-en dir\n",
        "download_dir=../indic-en\n",
        "\n",
        "train_data_dir=$exp_dir/train\n",
        "dev_data_dir=$exp_dir/dev\n",
        "test_data_dir=$exp_dir/test\n",
        "echo $exp_dir\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhwUXyYVXrOY",
        "outputId": "ca768f9b-ab25-475a-f4ec-1db12e3e0515"
      },
      "source": [
        "# all the data preparation happens in this cell\n",
        "%%shell\n",
        "\n",
        "exp_dir=../dataset\n",
        "src_lang=indic\n",
        "tgt_lang=en\n",
        "\n",
        "# change this to indic-en, if you have downloaded the indic-en dir\n",
        "download_dir=../indic-en\n",
        "\n",
        "train_data_dir=$exp_dir/train\n",
        "dev_data_dir=$exp_dir/dev\n",
        "test_data_dir=$exp_dir/test\n",
        "\n",
        "\n",
        "echo \"Running experiment ${exp_dir} on ${src_lang} to ${tgt_lang}\"\n",
        "\n",
        "\n",
        "train_processed_dir=$exp_dir/data\n",
        "devtest_processed_dir=$exp_dir/data\n",
        "\n",
        "out_data_dir=$exp_dir/final_bin\n",
        "\n",
        "mkdir -p $train_processed_dir\n",
        "mkdir -p $devtest_processed_dir\n",
        "mkdir -p $out_data_dir\n",
        "\n",
        "# indic languages.\n",
        "# cvit-pib corpus does not have as (assamese) and kn (kannada), hence its not part of this list\n",
        "langs=( mr )\n",
        "\n",
        "for lang in ${langs[@]};do\n",
        "\tif [ $src_lang == en ]; then\n",
        "\t\ttgt_lang=$lang\n",
        "\telse\n",
        "\t\tsrc_lang=$lang\n",
        "\tfi\n",
        "\n",
        "\ttrain_norm_dir=$exp_dir/norm/$src_lang-$tgt_lang\n",
        "\tdevtest_norm_dir=$exp_dir/norm/$src_lang-$tgt_lang\n",
        "\tmkdir -p $train_norm_dir\n",
        "\tmkdir -p $devtest_norm_dir\n",
        "\n",
        "\n",
        "    # preprocessing pretokenizes the input (we use moses tokenizer for en and indicnlp lib for indic languages)\n",
        "    # after pretokenization, we use indicnlp to transliterate all the indic data to devnagiri script\n",
        "\n",
        "\t# train preprocessing\n",
        "\ttrain_infname_src=$train_data_dir/en-${lang}/train.$src_lang\n",
        "\ttrain_infname_tgt=$train_data_dir/en-${lang}/train.$tgt_lang\n",
        "\ttrain_outfname_src=$train_norm_dir/train.$src_lang\n",
        "\ttrain_outfname_tgt=$train_norm_dir/train.$tgt_lang\n",
        "\techo \"Applying normalization and script conversion for train $lang\"\n",
        "\tinput_size=`python scripts/preprocess_translate.py $train_infname_src $train_outfname_src $src_lang true`\n",
        "\tinput_size=`python scripts/preprocess_translate.py $train_infname_tgt $train_outfname_tgt $tgt_lang true`\n",
        "\techo \"Number of sentences in train $lang: $input_size\"\n",
        "\n",
        "\t# dev preprocessing\n",
        "\tdev_infname_src=$dev_data_dir/dev.$src_lang\n",
        "\tdev_infname_tgt=$dev_data_dir/dev.$tgt_lang\n",
        "\tdev_outfname_src=$devtest_norm_dir/dev.$src_lang\n",
        "\tdev_outfname_tgt=$devtest_norm_dir/dev.$tgt_lang\n",
        "\techo \"Applying normalization and script conversion for dev $lang\"\n",
        "\tinput_size=`python scripts/preprocess_translate.py $dev_infname_src $dev_outfname_src $src_lang true`\n",
        "\tinput_size=`python scripts/preprocess_translate.py $dev_infname_tgt $dev_outfname_tgt $tgt_lang true`\n",
        "\techo \"Number of sentences in dev $lang: $input_size\"\n",
        "\n",
        "\t# test preprocessing\n",
        "\ttest_infname_src=$test_data_dir/test.$src_lang\n",
        "\ttest_infname_tgt=$test_data_dir/test.$tgt_lang\n",
        "\ttest_outfname_src=$devtest_norm_dir/test.$src_lang\n",
        "\ttest_outfname_tgt=$devtest_norm_dir/test.$tgt_lang\n",
        "\techo \"Applying normalization and script conversion for test $lang\"\n",
        "\tinput_size=`python scripts/preprocess_translate.py $test_infname_src $test_outfname_src $src_lang true`\n",
        "\tinput_size=`python scripts/preprocess_translate.py $test_infname_tgt $test_outfname_tgt $tgt_lang true`\n",
        "\techo \"Number of sentences in test $lang: $input_size\"\n",
        "done\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Now that we have preprocessed all the data, we can now merge these different text files into one\n",
        "# ie. for en-as, we have train.en and corresponding train.as, similarly for en-bn, we have train.en and corresponding train.bn\n",
        "# now we will concatenate all this into en-X where train.SRC will have all the en (src) training data and train.TGT will have all the concatenated indic lang data\n",
        "\n",
        "python scripts/concat_joint_data.py $exp_dir/norm $exp_dir/data $src_lang $tgt_lang 'train'\n",
        "python scripts/concat_joint_data.py $exp_dir/norm $exp_dir/data $src_lang $tgt_lang 'dev'\n",
        "python scripts/concat_joint_data.py $exp_dir/norm $exp_dir/data $src_lang $tgt_lang 'test'\n",
        "\n",
        "# use the vocab from downloaded dir\n",
        "cp -r $download_dir/vocab $exp_dir\n",
        "\n",
        "\n",
        "echo \"Applying bpe to the new finetuning data\"\n",
        "bash apply_single_bpe_traindevtest_notag.sh $exp_dir\n",
        "\n",
        "mkdir -p $exp_dir/final\n",
        "\n",
        "# We also add special tags to indicate the source and target language in the inputs\n",
        "#  Eg: to translate a sentence from english to hindi , the input would be   __src__en__   __tgt__hi__ <en bpe tokens>\n",
        "\n",
        "echo \"Adding language tags\"\n",
        "python scripts/add_joint_tags_translate.py $exp_dir 'train'\n",
        "python scripts/add_joint_tags_translate.py $exp_dir 'dev'\n",
        "python scripts/add_joint_tags_translate.py $exp_dir 'test'\n",
        "\n",
        "\n",
        "\n",
        "data_dir=$exp_dir/final\n",
        "out_data_dir=$exp_dir/final_bin\n",
        "\n",
        "rm -rf $out_data_dir\n",
        "\n",
        "# binarizing the new data (train, dev and test) using dictionary from the download dir\n",
        "\n",
        " num_workers=`python -c \"import multiprocessing; print(multiprocessing.cpu_count())\"`\n",
        "\n",
        "data_dir=$exp_dir/final\n",
        "out_data_dir=$exp_dir/final_bin\n",
        "\n",
        "# rm -rf $out_data_dir\n",
        "\n",
        "echo \"Binarizing data. This will take some time depending on the size of finetuning data\"\n",
        "fairseq-preprocess --source-lang SRC --target-lang TGT \\\n",
        " --trainpref $data_dir/train --validpref $data_dir/dev --testpref $data_dir/test \\\n",
        " --destdir $out_data_dir --workers $num_workers \\\n",
        " --srcdict $download_dir/final_bin/dict.SRC.txt --tgtdict $download_dir/final_bin/dict.TGT.txt --thresholdtgt 5 --thresholdsrc 5  "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running experiment ../dataset on indic to en\n",
            "Applying normalization and script conversion for train mr\n",
            "100% 81809/81809 [00:09<00:00, 9036.84it/s]\n",
            "100% 81809/81809 [00:15<00:00, 5393.67it/s]\n",
            "Number of sentences in train mr: 81809\n",
            "Applying normalization and script conversion for dev mr\n",
            "100% 500/500 [00:00<00:00, 4476.30it/s]\n",
            "100% 500/500 [00:00<00:00, 1116.53it/s]\n",
            "Number of sentences in dev mr: 500\n",
            "Applying normalization and script conversion for test mr\n",
            "100% 500/500 [00:00<00:00, 4342.56it/s]\n",
            "100% 500/500 [00:00<00:00, 1126.71it/s]\n",
            "Number of sentences in test mr: 500\n",
            "\n",
            "../dataset/data/train.SRC\n",
            "../dataset/data/train.TGT\n",
            "  0% 0/11 [00:00<?, ?it/s]src: as, tgt:en\n",
            "src: bn, tgt:en\n",
            "src: gu, tgt:en\n",
            "src: hi, tgt:en\n",
            "src: kn, tgt:en\n",
            "src: ml, tgt:en\n",
            "src: mr, tgt:en\n",
            "../dataset/norm/mr-en/train.mr\n",
            "../dataset/norm/mr-en/train.en\n",
            "src: or, tgt:en\n",
            "src: pa, tgt:en\n",
            "src: ta, tgt:en\n",
            "src: te, tgt:en\n",
            "100% 11/11 [00:00<00:00, 262.21it/s]\n",
            "  0% 0/11 [00:00<?, ?it/s]src: as, tgt:en\n",
            "src: bn, tgt:en\n",
            "src: gu, tgt:en\n",
            "src: hi, tgt:en\n",
            "src: kn, tgt:en\n",
            "src: ml, tgt:en\n",
            "src: mr, tgt:en\n",
            "../dataset/norm/mr-en/train.mr\n",
            "src: or, tgt:en\n",
            "src: pa, tgt:en\n",
            "src: ta, tgt:en\n",
            "src: te, tgt:en\n",
            "100% 11/11 [00:00<00:00, 168.83it/s]\n",
            "\n",
            "../dataset/data/dev.SRC\n",
            "../dataset/data/dev.TGT\n",
            "  0% 0/11 [00:00<?, ?it/s]src: as, tgt:en\n",
            "src: bn, tgt:en\n",
            "src: gu, tgt:en\n",
            "src: hi, tgt:en\n",
            "src: kn, tgt:en\n",
            "src: ml, tgt:en\n",
            "src: mr, tgt:en\n",
            "../dataset/norm/mr-en/dev.mr\n",
            "../dataset/norm/mr-en/dev.en\n",
            "src: or, tgt:en\n",
            "src: pa, tgt:en\n",
            "src: ta, tgt:en\n",
            "src: te, tgt:en\n",
            "100% 11/11 [00:00<00:00, 1132.90it/s]\n",
            "  0% 0/11 [00:00<?, ?it/s]src: as, tgt:en\n",
            "src: bn, tgt:en\n",
            "src: gu, tgt:en\n",
            "src: hi, tgt:en\n",
            "src: kn, tgt:en\n",
            "src: ml, tgt:en\n",
            "src: mr, tgt:en\n",
            "../dataset/norm/mr-en/dev.mr\n",
            "src: or, tgt:en\n",
            "src: pa, tgt:en\n",
            "src: ta, tgt:en\n",
            "src: te, tgt:en\n",
            "100% 11/11 [00:00<00:00, 12014.93it/s]\n",
            "\n",
            "../dataset/data/test.SRC\n",
            "../dataset/data/test.TGT\n",
            "  0% 0/11 [00:00<?, ?it/s]src: as, tgt:en\n",
            "src: bn, tgt:en\n",
            "src: gu, tgt:en\n",
            "src: hi, tgt:en\n",
            "src: kn, tgt:en\n",
            "src: ml, tgt:en\n",
            "src: mr, tgt:en\n",
            "../dataset/norm/mr-en/test.mr\n",
            "../dataset/norm/mr-en/test.en\n",
            "src: or, tgt:en\n",
            "src: pa, tgt:en\n",
            "src: ta, tgt:en\n",
            "src: te, tgt:en\n",
            "100% 11/11 [00:00<00:00, 931.13it/s]\n",
            "  0% 0/11 [00:00<?, ?it/s]src: as, tgt:en\n",
            "src: bn, tgt:en\n",
            "src: gu, tgt:en\n",
            "src: hi, tgt:en\n",
            "src: kn, tgt:en\n",
            "src: ml, tgt:en\n",
            "src: mr, tgt:en\n",
            "../dataset/norm/mr-en/test.mr\n",
            "src: or, tgt:en\n",
            "src: pa, tgt:en\n",
            "src: ta, tgt:en\n",
            "src: te, tgt:en\n",
            "100% 11/11 [00:00<00:00, 10323.86it/s]\n",
            "Applying bpe to the new finetuning data\n",
            "train\n",
            "Apply to SRC corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "Apply to TGT corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "dev\n",
            "Apply to SRC corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "Apply to TGT corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "test\n",
            "Apply to SRC corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "Apply to TGT corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "Adding language tags\n",
            "81809it [00:00, 210456.60it/s]\n",
            "500it [00:00, 88130.44it/s]\n",
            "500it [00:00, 152177.06it/s]\n",
            "Binarizing data. This will take some time depending on the size of finetuning data\n",
            "2021-06-21 09:35:17 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='../dataset/final_bin', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='SRC', srcdict='../indic-en/final_bin/dict.SRC.txt', suppress_crashes=False, target_lang='TGT', task='translation', tensorboard_logdir=None, testpref='../dataset/final/test', tgtdict='../indic-en/final_bin/dict.TGT.txt', threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer=None, tpu=False, trainpref='../dataset/final/train', use_plasma_view=False, user_dir=None, validpref='../dataset/final/dev', wandb_project=None, workers=2)\n",
            "2021-06-21 09:35:17 | INFO | fairseq_cli.preprocess | [SRC] Dictionary: 35864 types\n",
            "2021-06-21 09:35:31 | INFO | fairseq_cli.preprocess | [SRC] ../dataset/final/train.SRC: 81809 sents, 3078520 tokens, 0.176% replaced by <unk>\n",
            "2021-06-21 09:35:31 | INFO | fairseq_cli.preprocess | [SRC] Dictionary: 35864 types\n",
            "2021-06-21 09:35:31 | INFO | fairseq_cli.preprocess | [SRC] ../dataset/final/dev.SRC: 500 sents, 23527 tokens, 0.0383% replaced by <unk>\n",
            "2021-06-21 09:35:31 | INFO | fairseq_cli.preprocess | [SRC] Dictionary: 35864 types\n",
            "2021-06-21 09:35:31 | INFO | fairseq_cli.preprocess | [SRC] ../dataset/final/test.SRC: 500 sents, 23527 tokens, 0.0383% replaced by <unk>\n",
            "2021-06-21 09:35:31 | INFO | fairseq_cli.preprocess | [TGT] Dictionary: 32088 types\n",
            "2021-06-21 09:35:40 | INFO | fairseq_cli.preprocess | [TGT] ../dataset/final/train.TGT: 81809 sents, 2422630 tokens, 0.801% replaced by <unk>\n",
            "2021-06-21 09:35:40 | INFO | fairseq_cli.preprocess | [TGT] Dictionary: 32088 types\n",
            "2021-06-21 09:35:40 | INFO | fairseq_cli.preprocess | [TGT] ../dataset/final/dev.TGT: 500 sents, 16331 tokens, 0.153% replaced by <unk>\n",
            "2021-06-21 09:35:40 | INFO | fairseq_cli.preprocess | [TGT] Dictionary: 32088 types\n",
            "2021-06-21 09:35:40 | INFO | fairseq_cli.preprocess | [TGT] ../dataset/final/test.TGT: 500 sents, 16331 tokens, 0.153% replaced by <unk>\n",
            "2021-06-21 09:35:40 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ../dataset/final_bin\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz6tzbe2tcs7",
        "outputId": "333458ab-13cf-401d-8032-8efacde6432d"
      },
      "source": [
        "# Finetuning the model\n",
        "\n",
        "# pls refer to fairseq documentaion to know more about each of these options (https://fairseq.readthedocs.io/en/latest/command_line_tools.html)\n",
        "\n",
        "\n",
        "# some notable args:\n",
        "# --max-update=1000     -> for this example, to demonstrate how to finetune we are only training for 1000 steps, incrase this if needed\n",
        "# --arch=transformer_4x -> we use a custom transformer model and name it transformer_4x (4 times the parameter size of transformer  base)\n",
        "# --user_dir            -> we define the custom transformer arch in model_configs folder and pass it as an argument to user_dir for fairseq to register this architechture\n",
        "# --lr                  -> learning rate. From our limited experiments, we find that lower learning rates like 3e-5 works best for finetuning.\n",
        "# --restore-file        -> reload the pretrained checkpoint and start training from here (change this path for indic-en. Currently its is set to en-indic)\n",
        "# --reset-*             -> reset and not use lr scheduler, dataloader, optimizer etc of the older checkpoint\n",
        "# --max_tokns           -> this is max tokens per batch\n",
        "\n",
        "\n",
        "!( fairseq-train ../dataset/final_bin \\\n",
        "--max-source-positions=210 \\\n",
        "--max-target-positions=210 \\\n",
        "--max-update=100000 \\\n",
        "--save-interval=1 \\\n",
        "--arch=transformer_4x \\\n",
        "--criterion=label_smoothed_cross_entropy \\\n",
        "--source-lang=SRC \\\n",
        "--max-epoch=3 \\\n",
        "--lr-scheduler=inverse_sqrt \\\n",
        "--target-lang=TGT \\\n",
        "--label-smoothing=0.1 \\\n",
        "--optimizer adam \\\n",
        "--adam-betas \"(0.9, 0.98)\" \\\n",
        "--clip-norm 1.0 \\\n",
        "--warmup-init-lr 1e-07 \\\n",
        "--warmup-updates 4000 \\\n",
        "--dropout 0.2 \\\n",
        "--tensorboard-logdir ../dataset/tensorboard-wandb \\\n",
        "--save-dir ../dataset/model \\\n",
        "--keep-last-epochs 5 \\\n",
        "--patience 5 \\\n",
        "--skip-invalid-size-inputs-valid-test \\\n",
        "--fp16 \\\n",
        "--no-last-checkpoints \\\n",
        "--user-dir model_configs \\\n",
        "--update-freq=2 \\\n",
        "--distributed-world-size 1 \\\n",
        "--max-tokens 256 \\\n",
        "--lr 3e-5 \\\n",
        "--restore-file ../en-indic/model/checkpoint_best.pt \\\n",
        "--reset-lr-scheduler \\\n",
        "--reset-meters \\\n",
        "--reset-dataloader \\\n",
        "--reset-optimizer)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-21 09:35:53 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': '../dataset/tensorboard-wandb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'model_configs', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 256, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 256, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 3, 'max_update': 100000, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../dataset/model', 'restore_file': '../en-indic/model/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 5, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_4x', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_4x', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../dataset/final_bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=16, decoder_embed_dim=1536, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1536, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1536, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1536, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[3e-05], lr_scheduler='inverse_sqrt', max_epoch=3, max_source_positions=210, max_target_positions=210, max_tokens=256, max_tokens_valid=256, max_update=100000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=True, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=5, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='../en-indic/model/checkpoint_best.pt', save_dir='../dataset/model', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='SRC', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='TGT', task='translation', tensorboard_logdir='../dataset/tensorboard-wandb', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[2], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir='model_configs', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': '../dataset/final_bin', 'source_lang': 'SRC', 'target_lang': 'TGT', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 210, 'max_target_positions': 210, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}\n",
            "2021-06-21 09:35:53 | INFO | fairseq.tasks.translation | [SRC] dictionary: 35864 types\n",
            "2021-06-21 09:35:53 | INFO | fairseq.tasks.translation | [TGT] dictionary: 32088 types\n",
            "2021-06-21 09:35:59 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(35864, 1536, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(32088, 1536, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=1536, out_features=32088, bias=False)\n",
            "  )\n",
            ")\n",
            "2021-06-21 09:35:59 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2021-06-21 09:35:59 | INFO | fairseq_cli.train | model: TransformerModel\n",
            "2021-06-21 09:35:59 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2021-06-21 09:35:59 | INFO | fairseq_cli.train | num. shared model params: 474,796,032 (num. trained: 474,796,032)\n",
            "2021-06-21 09:35:59 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-06-21 09:35:59 | INFO | fairseq.data.data_utils | loaded 500 examples from: ../dataset/final_bin/valid.SRC-TGT.SRC\n",
            "2021-06-21 09:35:59 | INFO | fairseq.data.data_utils | loaded 500 examples from: ../dataset/final_bin/valid.SRC-TGT.TGT\n",
            "2021-06-21 09:35:59 | INFO | fairseq.tasks.translation | ../dataset/final_bin valid SRC-TGT 500 examples\n",
            "2021-06-21 09:36:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-06-21 09:36:11 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n",
            "2021-06-21 09:36:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-06-21 09:36:11 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-06-21 09:36:11 | INFO | fairseq_cli.train | max tokens per device = 256 and max sentences per device = None\n",
            "2021-06-21 09:36:11 | INFO | fairseq.trainer | Preparing to load checkpoint ../en-indic/model/checkpoint_best.pt\n",
            "2021-06-21 09:36:11 | INFO | fairseq.trainer | No existing checkpoint found ../en-indic/model/checkpoint_best.pt\n",
            "2021-06-21 09:36:11 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-06-21 09:36:11 | INFO | fairseq.data.data_utils | loaded 81,809 examples from: ../dataset/final_bin/train.SRC-TGT.SRC\n",
            "2021-06-21 09:36:11 | INFO | fairseq.data.data_utils | loaded 81,809 examples from: ../dataset/final_bin/train.SRC-TGT.TGT\n",
            "2021-06-21 09:36:11 | INFO | fairseq.tasks.translation | ../dataset/final_bin train SRC-TGT 81809 examples\n",
            "2021-06-21 09:36:11 | WARNING | fairseq.tasks.fairseq_task | 3 samples have invalid sizes and will be skipped, max_positions=(210, 210), first few sample ids=[14826, 5744, 18025]\n",
            "epoch 001:   0% 0/7170 [00:00<?, ?it/s]2021-06-21 09:36:11 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2021-06-21 09:36:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 001:   1% 99/7170 [00:31<37:11,  3.17it/s]2021-06-21 09:36:43.771093: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "epoch 001: 100% 7169/7170 [38:30<00:00,  3.13it/s, loss=7.457, nll_loss=6.311, ppl=79.39, wps=1046.9, ups=3.12, wpb=335.6, bsz=11.8, num_updates=7100, lr=2.25176e-05, gnorm=4.655, clip=100, loss_scale=128, train_wall=32, gb_free=4.1, wall=2289]2021-06-21 10:14:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-06-21 10:14:42 | WARNING | fairseq.tasks.fairseq_task | 1 samples have invalid sizes and will be skipped, max_positions=(210, 210), first few sample ids=[248]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/109 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   2% 2/109 [00:00<00:08, 13.12it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 7/109 [00:00<00:06, 16.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 12/109 [00:00<00:04, 20.97it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 17/109 [00:00<00:03, 25.36it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  21% 23/109 [00:00<00:02, 29.90it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  27% 29/109 [00:00<00:02, 33.93it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 35/109 [00:00<00:01, 37.68it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  38% 41/109 [00:00<00:01, 40.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  43% 47/109 [00:01<00:01, 43.92it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 53/109 [00:01<00:01, 46.12it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  53% 58/109 [00:01<00:01, 47.11it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 64/109 [00:01<00:00, 48.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  64% 70/109 [00:01<00:00, 49.06it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 76/109 [00:01<00:00, 49.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  75% 82/109 [00:01<00:00, 50.29it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  81% 88/109 [00:01<00:00, 49.27it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  86% 94/109 [00:01<00:00, 50.42it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 100/109 [00:02<00:00, 51.58it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 106/109 [00:02<00:00, 52.17it/s]\u001b[A\n",
            "                                                                          \u001b[A2021-06-21 10:14:45 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.558 | nll_loss 8.715 | ppl 420.09 | wps 7505.8 | wpb 148.5 | bsz 4.6 | num_updates 7170\n",
            "2021-06-21 10:14:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 7170 updates\n",
            "2021-06-21 10:14:45 | INFO | fairseq.trainer | Saving checkpoint to ../dataset/model/checkpoint1.pt\n",
            "tcmalloc: large alloc 1899184128 bytes == 0x562a0ccba000 @  0x7febd6a97b6b 0x7febd6ab7379 0x7feb6d3b626e 0x7feb6d3b79e2 0x7febb1ad2a73 0x7febb1008b7b 0x7febb1763bef 0x7febb1748480 0x7febb1351454 0x7febb0ffc1c8 0x7febb18d6310 0x7febb1aa1217 0x7febc3a199ae 0x7febc3b659de 0x5628fe197cc0 0x5628fe288fed 0x5628fe20b988 0x5628fe2064ae 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2067ad 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2067ad 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2067ad 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2067ad 0x5628fe1993ea\n",
            "tcmalloc: large alloc 1899184128 bytes == 0x562a7e7ee000 @  0x7febd6a97b6b 0x7febd6ab7379 0x7feb6d3b626e 0x7feb6d3b79e2 0x7febb1ad2a73 0x7febb1008b7b 0x7febb1763bef 0x7febb1748480 0x7febb1351454 0x7febb0ffc1c8 0x7febb18d6310 0x7febb1aa1217 0x7febc3a199ae 0x7febc3b659de 0x5628fe197cc0 0x5628fe288fed 0x5628fe20b988 0x5628fe2064ae 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2067ad 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2067ad 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2067ad 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2067ad 0x5628fe1993ea\n",
            "tcmalloc: large alloc 1899192320 bytes == 0x562aefb22000 @  0x7febd6ab51e7 0x5628fe1c9e68 0x5628fe194637 0x7febc3f7f7a7 0x7febb2243665 0x7febb223ef9e 0x7febb224413a 0x7febc3f7fd2e 0x7febc3a15b88 0x5628fe1988a8 0x5628fe20bfd5 0x5628fe2067ad 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2064ae 0x5628fe1993ea 0x5628fe20b7f0 0x5628fe19930a 0x5628fe2073b5 0x5628fe2064ae 0x5628fe1993ea 0x5628fe20832a 0x5628fe19930a 0x5628fe20760e 0x5628fe2067ad 0x5628fe1993ea 0x5628fe20b7f0 0x5628fe19930a 0x5628fe2073b5 0x5628fe0d8d14 0x5628fe208bb5\n",
            "tcmalloc: large alloc 1899192320 bytes == 0x562aefb22000 @  0x7febd6ab51e7 0x5628fe1c9e68 0x5628fe194637 0x7febc3f7f7a7 0x7febb2243665 0x7febb223ef9e 0x7febb224413a 0x7febc3f7fd2e 0x7febc3a15b88 0x5628fe1988a8 0x5628fe20bfd5 0x5628fe2067ad 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2064ae 0x5628fe1993ea 0x5628fe20b7f0 0x5628fe19930a 0x5628fe2073b5 0x5628fe2064ae 0x5628fe1993ea 0x5628fe20832a 0x5628fe19930a 0x5628fe20760e 0x5628fe2067ad 0x5628fe1993ea 0x5628fe20b7f0 0x5628fe19930a 0x5628fe2073b5 0x5628fe0d8d14 0x5628fe208bb5\n",
            "2021-06-21 10:16:41 | INFO | fairseq.trainer | Finished saving checkpoint to ../dataset/model/checkpoint1.pt\n",
            "2021-06-21 10:19:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../dataset/model/checkpoint1.pt (epoch 1 @ 7170 updates, score 9.558) (writing took 277.66607832499994 seconds)\n",
            "2021-06-21 10:19:22 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2021-06-21 10:19:23 | INFO | train | epoch 001 | loss 8.63 | nll_loss 7.64 | ppl 199.45 | wps 934.9 | ups 2.77 | wpb 337.8 | bsz 11.4 | num_updates 7170 | lr 2.24074e-05 | gnorm 5.328 | clip 100 | loss_scale 128 | train_wall 2286 | gb_free 4.1 | wall 2591\n",
            "epoch 002:   0% 0/7170 [00:00<?, ?it/s]2021-06-21 10:19:23 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2021-06-21 10:19:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "epoch 002: 100% 7169/7170 [38:23<00:00,  3.10it/s, loss=6.82, nll_loss=5.6, ppl=48.51, wps=1045.8, ups=3.12, wpb=334.9, bsz=11.2, num_updates=14300, lr=1.58666e-05, gnorm=5.088, clip=100, loss_scale=256, train_wall=32, gb_free=4.1, wall=4883]2021-06-21 10:57:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/109 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   1% 1/109 [00:00<00:12,  8.44it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   6% 6/109 [00:00<00:09, 11.13it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  11% 12/109 [00:00<00:06, 14.54it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  17% 18/109 [00:00<00:04, 18.50it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  21% 23/109 [00:00<00:03, 22.62it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  27% 29/109 [00:00<00:02, 27.18it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  32% 35/109 [00:00<00:02, 31.57it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  38% 41/109 [00:00<00:01, 35.61it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  43% 47/109 [00:01<00:01, 39.13it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  49% 53/109 [00:01<00:01, 41.98it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  53% 58/109 [00:01<00:01, 43.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  59% 64/109 [00:01<00:00, 45.86it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  63% 69/109 [00:01<00:00, 46.54it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  69% 75/109 [00:01<00:00, 47.91it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  74% 81/109 [00:01<00:00, 49.21it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  80% 87/109 [00:01<00:00, 49.14it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  85% 93/109 [00:01<00:00, 49.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  91% 99/109 [00:02<00:00, 50.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  96% 105/109 [00:02<00:00, 52.13it/s]\u001b[A\n",
            "                                                                          \u001b[A2021-06-21 10:57:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.753 | nll_loss 7.788 | ppl 221.09 | wps 7559.3 | wpb 148.5 | bsz 4.6 | num_updates 14340 | best_loss 8.753\n",
            "2021-06-21 10:57:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 14340 updates\n",
            "2021-06-21 10:57:49 | INFO | fairseq.trainer | Saving checkpoint to ../dataset/model/checkpoint2.pt\n",
            "tcmalloc: large alloc 1899184128 bytes == 0x562a0ccba000 @  0x7febd6a97b6b 0x7febd6ab7379 0x7feb6d3b626e 0x7feb6d3b79e2 0x7febb1ad2a73 0x7febb1008b7b 0x7febb1763bef 0x7febb1748480 0x7febb1351454 0x7febb0ffc1c8 0x7febb18d6310 0x7febb1aa1217 0x7febc3a199ae 0x7febc3b659de 0x5628fe197cc0 0x5628fe288fed 0x5628fe20b988 0x5628fe2064ae 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2067ad 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2067ad 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2067ad 0x5628fe1993ea 0x5628fe2073b5 0x5628fe2067ad 0x5628fe1993ea\n",
            "2021-06-21 11:00:17 | INFO | fairseq.trainer | Finished saving checkpoint to ../dataset/model/checkpoint2.pt\n",
            "2021-06-21 11:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../dataset/model/checkpoint2.pt (epoch 2 @ 14340 updates, score 8.753) (writing took 309.6475623280003 seconds)\n",
            "2021-06-21 11:02:59 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2021-06-21 11:02:59 | INFO | train | epoch 002 | loss 7.004 | nll_loss 5.804 | ppl 55.88 | wps 925.8 | ups 2.74 | wpb 337.8 | bsz 11.4 | num_updates 14340 | lr 1.58444e-05 | gnorm 4.896 | clip 100 | loss_scale 256 | train_wall 2281 | gb_free 4.1 | wall 5207\n",
            "epoch 003:   0% 0/7170 [00:00<?, ?it/s]2021-06-21 11:02:59 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2021-06-21 11:02:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "epoch 003: 100% 7169/7170 [38:14<00:00,  3.09it/s, loss=6.361, nll_loss=5.086, ppl=33.98, wps=1049.9, ups=3.14, wpb=333.8, bsz=11.4, num_updates=21500, lr=1.29399e-05, gnorm=5.365, clip=100, loss_scale=512, train_wall=31, gb_free=4.1, wall=7499]2021-06-21 11:41:14 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   0% 0/109 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   1% 1/109 [00:00<00:12,  8.67it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:   5% 5/109 [00:00<00:09, 11.22it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:   9% 10/109 [00:00<00:06, 14.57it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  15% 16/109 [00:00<00:05, 18.53it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  19% 21/109 [00:00<00:03, 22.69it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  25% 27/109 [00:00<00:03, 27.19it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  30% 33/109 [00:00<00:02, 31.60it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  35% 38/109 [00:00<00:02, 35.09it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  40% 44/109 [00:01<00:01, 38.83it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  46% 50/109 [00:01<00:01, 41.80it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  50% 55/109 [00:01<00:01, 42.23it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  56% 61/109 [00:01<00:01, 44.66it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  61% 66/109 [00:01<00:00, 45.27it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  65% 71/109 [00:01<00:00, 46.50it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  71% 77/109 [00:01<00:00, 47.88it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  76% 83/109 [00:01<00:00, 48.57it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  81% 88/109 [00:01<00:00, 48.86it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  86% 94/109 [00:02<00:00, 49.31it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  91% 99/109 [00:02<00:00, 49.15it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  96% 105/109 [00:02<00:00, 51.02it/s]\u001b[A\n",
            "                                                                          \u001b[A2021-06-21 11:41:16 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.285 | nll_loss 7.277 | ppl 155.11 | wps 7331.3 | wpb 148.5 | bsz 4.6 | num_updates 21510 | best_loss 8.285\n",
            "2021-06-21 11:41:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 21510 updates\n",
            "2021-06-21 11:41:16 | INFO | fairseq.trainer | Saving checkpoint to ../dataset/model/checkpoint3.pt\n",
            "2021-06-21 11:43:12 | INFO | fairseq.trainer | Finished saving checkpoint to ../dataset/model/checkpoint3.pt\n",
            "2021-06-21 11:45:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../dataset/model/checkpoint3.pt (epoch 3 @ 21510 updates, score 8.285) (writing took 279.61979531699944 seconds)\n",
            "2021-06-21 11:45:56 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2021-06-21 11:45:56 | INFO | train | epoch 003 | loss 6.464 | nll_loss 5.2 | ppl 36.75 | wps 939.9 | ups 2.78 | wpb 337.8 | bsz 11.4 | num_updates 21510 | lr 1.29369e-05 | gnorm 5.227 | clip 100 | loss_scale 512 | train_wall 2271 | gb_free 4.1 | wall 7784\n",
            "2021-06-21 11:45:56 | INFO | fairseq_cli.train | done training in 7784.3 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpPsT1e7vuO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9781367-4e26-40ca-e368-63fcb361f531"
      },
      "source": [
        "# To test the models after training, you can use joint_translate.sh\n",
        "\n",
        "\n",
        "\n",
        "# joint_translate takes src_file, output_fname, src_lang, tgt_lang, model_folder as inputs\n",
        "# src_file -> input text file to be translated\n",
        "# output_fname -> name of the output file (will get created) containing the model predictions\n",
        "# src_lang -> source lang code of the input text ( in this case we are using en-indic model and hence src_lang would be 'en')\n",
        "# tgt_lang -> target lang code of the input text ( tgt lang for en-indic model would be any of the 11 indic langs we trained on:\n",
        "#              as, bn, hi, gu, kn, ml, mr, or, pa, ta, te)\n",
        "# supported languages are:\n",
        "#              as - assamese, bn - bengali, gu - gujarathi, hi - hindi, kn - kannada, \n",
        "#              ml - malayalam, mr - marathi, or - oriya, pa - punjabi, ta - tamil, te - telugu\n",
        "\n",
        "# model_dir -> the directory containing the model and the vocab files\n",
        "\n",
        "# Note: if the translation is taking a lot of time, please tune the buffer_size and batch_size parameter for fairseq-interactive defined inside this joint_translate script\n",
        "\n",
        "\n",
        "# here we are translating the english sentences to hindi\n",
        "!bash /content/finetuning/indicTrans/joint_translate.sh /content/finetuning/dataset/test/test.mr en_mr_outputs.txt 'mr' 'en' /content/finetuning/dataset"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun 21 12:17:50 UTC 2021\n",
            "Applying normalization and script conversion\n",
            "100% 500/500 [00:00<00:00, 4327.20it/s]\n",
            "Number of sentences in input: 500\n",
            "Applying BPE\n",
            "Decoding\n",
            "Extracting translations, script conversion and detokenization\n",
            "Translation completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yEoqL1OlxZ1"
      },
      "source": [
        "!cat en_mr_outputs.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPqneByPxilN"
      },
      "source": [
        "# to compute bleu scores for the predicitions with a reference file, use the following command\n",
        "# arguments:\n",
        "# pred_fname: file that contains model predictions\n",
        "# ref_fname: file that contains references\n",
        "# src_lang and tgt_lang : the source and target language\n",
        "\n",
        "!bash /content/finetuning/indicTrans/compute_bleu.sh en_mr_outputs.txt /content/finetuning/dataset/test/test.en 'mr' 'en'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7etV5Lf7mbge"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAb-UWACsXbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f74a3df-6676-47ed-ab12-fd768e4c844f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZndA3RlhsYAB"
      },
      "source": [
        "!cp -r /content/finetuning/dataset /content/drive/MyDrive/en-mr/finetuning"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}