{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT-en-mr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikpuranik11/LoResMT/blob/main/MT_en_mr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE4MO-8bDtwD",
        "outputId": "a1b2e2e5-ca13-4539-8b67-bcf5a1b5a917"
      },
      "source": [
        "# create a seperate folder to store everything\n",
        "!mkdir finetuning\n",
        "%cd finetuning"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/finetuning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2Rs6_WkD_gF",
        "outputId": "2e81e3bc-466b-4d0e-f069-6d46921a199a"
      },
      "source": [
        "# clone the repo for running finetuning\n",
        "!git clone https://github.com/AI4Bharat/indicTrans.git\n",
        "%cd indicTrans\n",
        "# clone requirements repositories\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!git clone https://github.com/rsennrich/subword-nmt.git\n",
        "%cd .."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indicTrans'...\n",
            "remote: Enumerating objects: 398, done.\u001b[K\n",
            "remote: Counting objects: 100% (398/398), done.\u001b[K\n",
            "remote: Compressing objects: 100% (267/267), done.\u001b[K\n",
            "remote: Total 398 (delta 231), reused 251 (delta 126), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (398/398), 1.41 MiB | 14.60 MiB/s, done.\n",
            "Resolving deltas: 100% (231/231), done.\n",
            "/content/finetuning/indicTrans\n",
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1325, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 1325 (delta 84), reused 89 (delta 41), pack-reused 1178\u001b[K\n",
            "Receiving objects: 100% (1325/1325), 9.57 MiB | 12.96 MiB/s, done.\n",
            "Resolving deltas: 100% (688/688), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 31.59 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 580, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 576\u001b[K\n",
            "Receiving objects: 100% (580/580), 237.41 KiB | 11.87 MiB/s, done.\n",
            "Resolving deltas: 100% (349/349), done.\n",
            "/content/finetuning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duwTvJ9xEBJ1",
        "outputId": "20876a5f-4944-416d-b8f5-90269343e105"
      },
      "source": [
        "! sudo apt install tree\n",
        "\n",
        "# Install the necessary libraries\n",
        "!pip install sacremoses pandas mock sacrebleu tensorboardX pyarrow indic-nlp-library\n",
        "# Install fairseq from source\n",
        "!git clone https://github.com/pytorch/fairseq.git\n",
        "%cd fairseq\n",
        "# !git checkout da9eaba12d82b9bfc1442f0e2c6fc1b895f4d35d\n",
        "!pip install --editable ./\n",
        "%cd .."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 40.7 kB of archives.\n",
            "After this operation, 105 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n",
            "Fetched 40.7 kB in 1s (72.6 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.5MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 26.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Collecting indic-nlp-library\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/d4/495bb43b88a2a6d04b09c29fc5115f24872af74cd8317fe84026abd4ddb1/indic_nlp_library-0.81-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.41.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Collecting sphinx-rtd-theme\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/24/2475e8f83519b54b2148d4a56eb1111f9cec630d088c3ffc214492c12107/sphinx_rtd_theme-0.5.2-py2.py3-none-any.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2MB 24.8MB/s \n",
            "\u001b[?25hCollecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Collecting sphinx-argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/06/2b/dfad6a1831c3aeeae25d8d3d417224684befbf45e10c7f2141631616a6ed/sphinx-argparse-0.2.5.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (57.0.0)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (1.8.5)\n",
            "Collecting docutils<0.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/44/8a15e45ffa96e6cf82956dd8d7af9e666357e16b0d93b253903475ee947f/docutils-0.16-py2.py3-none-any.whl (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.23.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (0.7.12)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.9.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.6.1)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.11.3)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (1.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (1.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (20.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->sphinx-rtd-theme->indic-nlp-library) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->sphinx-rtd-theme->indic-nlp-library) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->sphinx-rtd-theme->indic-nlp-library) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->sphinx-rtd-theme->indic-nlp-library) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx->sphinx-rtd-theme->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->sphinx-rtd-theme->indic-nlp-library) (1.1.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx->sphinx-rtd-theme->indic-nlp-library) (2.4.7)\n",
            "Building wheels for collected packages: sphinx-argparse\n",
            "  Building wheel for sphinx-argparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sphinx-argparse: filename=sphinx_argparse-0.2.5-cp37-none-any.whl size=11552 sha256=968464d407680b22dcc58da4a1de945cd1d969cff5f80a1e0af00db03ba17f7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/18/1b/4990a1859da4edc77ab312bc2986c08d2733fb5713d06e44f5\n",
            "Successfully built sphinx-argparse\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, mock, portalocker, sacrebleu, tensorboardX, docutils, sphinx-rtd-theme, morfessor, sphinx-argparse, indic-nlp-library\n",
            "  Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "Successfully installed docutils-0.16 indic-nlp-library-0.81 mock-4.0.3 morfessor-2.0.6 portalocker-2.0.0 sacrebleu-1.5.1 sacremoses-0.0.45 sphinx-argparse-0.2.5 sphinx-rtd-theme-0.5.2 tensorboardX-2.2\n",
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 28222, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 28222 (delta 18), reused 20 (delta 8), pack-reused 28181\u001b[K\n",
            "Receiving objects: 100% (28222/28222), 11.82 MiB | 14.27 MiB/s, done.\n",
            "Resolving deltas: 100% (21222/21222), done.\n",
            "/content/finetuning/fairseq\n",
            "Obtaining file:///content/finetuning/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (1.8.1+cu101)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (1.14.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (2019.12.20)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (1.5.1)\n",
            "Requirement already satisfied: numpy; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (1.19.5)\n",
            "Collecting hydra-core<1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e3/fbd70dd0d3ce4d1d75c22d56c0c9f895cfa7ed6587a9ffb821d6812d6a60/hydra_core-1.0.6-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (0.29.23)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq==1.0.0a0+fc391ff) (3.7.4.3)\n",
            "Collecting PyYAML>=5.1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 44.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+fc391ff) (2.20)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+fc391ff) (2.0.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+fc391ff) (5.1.3)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core<1.1->fairseq==1.0.0a0+fc391ff) (3.4.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=32956dd9bb09fe5abf0b7f2d725291951b3768b7f9e034d31e4b2bb690cae7da\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, omegaconf, antlr4-python3-runtime, hydra-core, fairseq\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 fairseq hydra-core-1.0.6 omegaconf-2.0.6\n",
            "/content/finetuning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD2EHQdqEH70",
        "outputId": "10b90f71-837a-49a9-b7fe-d854e981fd80"
      },
      "source": [
        "# download the indictrans model\n",
        "\n",
        "\n",
        "# downloading the en-indic model\n",
        "# this will contain:\n",
        "# en-indic/\n",
        "# ├── final_bin                          # contains fairseq dictionaries (we will use this to binarize the new finetuning data)\n",
        "# │   ├── dict.SRC.txt\n",
        "# │   └── dict.TGT.txt\n",
        "# ├── model                              # contains model checkpoint(s)\n",
        "# │   └── checkpoint_best.pt\n",
        "# └── vocab                              # contains bpes for src and tgt (since we train seperate vocabularies) generated with subword_nmt (we will use this bpes to convert finetuning data to subwords)\n",
        "#     ├── bpe_codes.32k.SRC\n",
        "#     ├── bpe_codes.32k.TGT\n",
        "#     ├── vocab.SRC\n",
        "#     └── vocab.TGT\n",
        "\n",
        "\n",
        "\n",
        "!wget https://storage.googleapis.com/samanantar-public/V0.2/models/en-indic.zip\n",
        "!unzip en-indic.zip\n",
        "\n",
        "# if you want to finetune indic-en models, use the link below\n",
        "\n",
        "# !wget https://akpublicdata.blob.core.windows.net/indicnlp/indictrans/indictrans-indic-en-v0.2.zip\n",
        "# !unzip indictrans-indic-en-v0.2.zip\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-05 09:03:31--  https://akpublicdata.blob.core.windows.net/indicnlp/indictrans/inidctrans-en-indic-v0.2.zip\n",
            "Resolving akpublicdata.blob.core.windows.net (akpublicdata.blob.core.windows.net)... 52.239.246.4\n",
            "Connecting to akpublicdata.blob.core.windows.net (akpublicdata.blob.core.windows.net)|52.239.246.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4609212103 (4.3G) [application/x-zip-compressed]\n",
            "Saving to: ‘inidctrans-en-indic-v0.2.zip’\n",
            "\n",
            "inidctrans-en-indic  69%[============>       ]   2.98G  11.7MB/s    in 4m 10s  \n",
            "\n",
            "2021-06-05 09:07:42 (12.2 MB/s) - Read error at byte 3199811584/4609212103 (Connection reset by peer). Retrying.\n",
            "\n",
            "--2021-06-05 09:07:43--  (try: 2)  https://akpublicdata.blob.core.windows.net/indicnlp/indictrans/inidctrans-en-indic-v0.2.zip\n",
            "Connecting to akpublicdata.blob.core.windows.net (akpublicdata.blob.core.windows.net)|52.239.246.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4609212103 (4.3G) [application/x-zip-compressed]\n",
            "Saving to: ‘inidctrans-en-indic-v0.2.zip’\n",
            "\n",
            "inidctrans-en-indic  92%[=================>  ]   3.95G  15.3MB/s    in 4m 20s  \n",
            "\n",
            "2021-06-05 09:12:03 (15.6 MB/s) - Read error at byte 4243308544/4609212103 (Connection reset by peer). Retrying.\n",
            "\n",
            "--2021-06-05 09:12:05--  (try: 3)  https://akpublicdata.blob.core.windows.net/indicnlp/indictrans/inidctrans-en-indic-v0.2.zip\n",
            "Connecting to akpublicdata.blob.core.windows.net (akpublicdata.blob.core.windows.net)|52.239.246.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4609212103 (4.3G) [application/x-zip-compressed]\n",
            "Saving to: ‘inidctrans-en-indic-v0.2.zip’\n",
            "\n",
            "inidctrans-en-indic 100%[===================>]   4.29G  19.3MB/s    in 4m 48s  \n",
            "\n",
            "2021-06-05 09:16:54 (15.3 MB/s) - ‘inidctrans-en-indic-v0.2.zip’ saved [4609212103/4609212103]\n",
            "\n",
            "Archive:  inidctrans-en-indic-v0.2.zip\n",
            "   creating: en-indic/\n",
            "   creating: en-indic/vocab/\n",
            "  inflating: en-indic/vocab/bpe_codes.32k.SRC  \n",
            "  inflating: en-indic/vocab/vocab.SRC  \n",
            "  inflating: en-indic/vocab/vocab.TGT  \n",
            "  inflating: en-indic/vocab/bpe_codes.32k.TGT  \n",
            "   creating: en-indic/final_bin/\n",
            "  inflating: en-indic/final_bin/dict.TGT.txt  \n",
            "  inflating: en-indic/final_bin/dict.SRC.txt  \n",
            "   creating: en-indic/model/\n",
            "  inflating: en-indic/model/checkpoint_best.pt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF4GladJ1W9e",
        "outputId": "eb77997c-ae88-48f1-bed7-bb0057657461"
      },
      "source": [
        "!sudo apt-get install p7zip-full"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1WkK7RQyK5G"
      },
      "source": [
        "!mkdir /content/finetuning/dataset\n",
        "!mkdir /content/finetuning/dataset/train\n",
        "!mkdir /content/finetuning/dataset/dev\n",
        "!mkdir /content/finetuning/dataset/test\n",
        "!mkdir /content/finetuning/dataset/train/en-mr"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1KlcCvHeyvZ",
        "outputId": "f1a2f0ff-e6ef-43ce-9534-1a68fb222e0a"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AOrU9KHz2SS",
        "outputId": "0fc42991-a713-48ff-d0b9-32843aab26b9"
      },
      "source": [
        "!7z x /content/en_mr.zip\n",
        "#password loresmt2021@covidmr"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 1667350 bytes (1629 KiB)\n",
            "\n",
            "Extracting archive: /content/en_mr.zip\n",
            "--\n",
            "Path = /content/en_mr.zip\n",
            "Type = zip\n",
            "Physical Size = 1667350\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Enter password (will not be echoed):\n",
            "  0% - dev.en\b\b\b\b\b\b\b\b\b\b\b\b\b             \b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 4\n",
            "Size:       8026001\n",
            "Compressed: 1667350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKYGc9Nk2Sbg"
      },
      "source": [
        "!cp /content/dev.en /content/finetuning/dataset/dev\n",
        "!cp /content/dev.mr /content/finetuning/dataset/dev"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXfTb2Zu2pE1"
      },
      "source": [
        "!mv /content/dev.en /content/finetuning/dataset/test/\n",
        "!mv /content/dev.mr /content/finetuning/dataset/test/"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzyPcs4O3bDc"
      },
      "source": [
        "!mv /content/train.en /content/finetuning/dataset/train/en-mr\n",
        "!mv /content/train.mr /content/finetuning/dataset/train/en-mr"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2jAutJB4Dqg",
        "outputId": "8de17204-5690-4f03-c97e-a78bb72ec583"
      },
      "source": [
        "%cd /content/finetuning/indicTrans"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/finetuning/indicTrans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yPTbM_clKfI",
        "outputId": "a73cb838-7d55-4d00-f7e6-4642f137f5b7"
      },
      "source": [
        "%%shell\n",
        "\n",
        "exp_dir=../dataset\n",
        "src_lang=en\n",
        "tgt_lang=indic\n",
        "\n",
        "# change this to indic-en, if you have downloaded the indic-en dir\n",
        "download_dir=../en-indic\n",
        "\n",
        "train_data_dir=$exp_dir/train\n",
        "dev_data_dir=$exp_dir/dev\n",
        "test_data_dir=$exp_dir/test\n",
        "echo $exp_dir\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhwUXyYVXrOY",
        "outputId": "f4ab7ac9-f97a-4840-8b74-2b4060e7486b"
      },
      "source": [
        "# all the data preparation happens in this cell\n",
        "%%shell\n",
        "\n",
        "exp_dir=../dataset\n",
        "src_lang=en\n",
        "tgt_lang=indic\n",
        "\n",
        "# change this to indic-en, if you have downloaded the indic-en dir\n",
        "download_dir=../en-indic\n",
        "\n",
        "train_data_dir=$exp_dir/train\n",
        "dev_data_dir=$exp_dir/dev\n",
        "test_data_dir=$exp_dir/test\n",
        "\n",
        "\n",
        "echo \"Running experiment ${exp_dir} on ${src_lang} to ${tgt_lang}\"\n",
        "\n",
        "\n",
        "train_processed_dir=$exp_dir/data\n",
        "devtest_processed_dir=$exp_dir/data\n",
        "\n",
        "out_data_dir=$exp_dir/final_bin\n",
        "\n",
        "mkdir -p $train_processed_dir\n",
        "mkdir -p $devtest_processed_dir\n",
        "mkdir -p $out_data_dir\n",
        "\n",
        "# indic languages.\n",
        "# cvit-pib corpus does not have as (assamese) and kn (kannada), hence its not part of this list\n",
        "langs=( mr )\n",
        "\n",
        "for lang in ${langs[@]};do\n",
        "\tif [ $src_lang == en ]; then\n",
        "\t\ttgt_lang=$lang\n",
        "\telse\n",
        "\t\tsrc_lang=$lang\n",
        "\tfi\n",
        "\n",
        "\ttrain_norm_dir=$exp_dir/norm/$src_lang-$tgt_lang\n",
        "\tdevtest_norm_dir=$exp_dir/norm/$src_lang-$tgt_lang\n",
        "\tmkdir -p $train_norm_dir\n",
        "\tmkdir -p $devtest_norm_dir\n",
        "\n",
        "\n",
        "    # preprocessing pretokenizes the input (we use moses tokenizer for en and indicnlp lib for indic languages)\n",
        "    # after pretokenization, we use indicnlp to transliterate all the indic data to devnagiri script\n",
        "\n",
        "\t# train preprocessing\n",
        "\ttrain_infname_src=$train_data_dir/en-${lang}/train.$src_lang\n",
        "\ttrain_infname_tgt=$train_data_dir/en-${lang}/train.$tgt_lang\n",
        "\ttrain_outfname_src=$train_norm_dir/train.$src_lang\n",
        "\ttrain_outfname_tgt=$train_norm_dir/train.$tgt_lang\n",
        "\techo \"Applying normalization and script conversion for train $lang\"\n",
        "\tinput_size=`python scripts/preprocess_translate.py $train_infname_src $train_outfname_src $src_lang true`\n",
        "\tinput_size=`python scripts/preprocess_translate.py $train_infname_tgt $train_outfname_tgt $tgt_lang true`\n",
        "\techo \"Number of sentences in train $lang: $input_size\"\n",
        "\n",
        "\t# dev preprocessing\n",
        "\tdev_infname_src=$dev_data_dir/dev.$src_lang\n",
        "\tdev_infname_tgt=$dev_data_dir/dev.$tgt_lang\n",
        "\tdev_outfname_src=$devtest_norm_dir/dev.$src_lang\n",
        "\tdev_outfname_tgt=$devtest_norm_dir/dev.$tgt_lang\n",
        "\techo \"Applying normalization and script conversion for dev $lang\"\n",
        "\tinput_size=`python scripts/preprocess_translate.py $dev_infname_src $dev_outfname_src $src_lang true`\n",
        "\tinput_size=`python scripts/preprocess_translate.py $dev_infname_tgt $dev_outfname_tgt $tgt_lang true`\n",
        "\techo \"Number of sentences in dev $lang: $input_size\"\n",
        "\n",
        "\t# test preprocessing\n",
        "\ttest_infname_src=$test_data_dir/test.$src_lang\n",
        "\ttest_infname_tgt=$test_data_dir/test.$tgt_lang\n",
        "\ttest_outfname_src=$devtest_norm_dir/test.$src_lang\n",
        "\ttest_outfname_tgt=$devtest_norm_dir/test.$tgt_lang\n",
        "\techo \"Applying normalization and script conversion for test $lang\"\n",
        "\tinput_size=`python scripts/preprocess_translate.py $test_infname_src $test_outfname_src $src_lang true`\n",
        "\tinput_size=`python scripts/preprocess_translate.py $test_infname_tgt $test_outfname_tgt $tgt_lang true`\n",
        "\techo \"Number of sentences in test $lang: $input_size\"\n",
        "done\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Now that we have preprocessed all the data, we can now merge these different text files into one\n",
        "# ie. for en-as, we have train.en and corresponding train.as, similarly for en-bn, we have train.en and corresponding train.bn\n",
        "# now we will concatenate all this into en-X where train.SRC will have all the en (src) training data and train.TGT will have all the concatenated indic lang data\n",
        "\n",
        "python scripts/concat_joint_data.py $exp_dir/norm $exp_dir/data $src_lang $tgt_lang 'train'\n",
        "python scripts/concat_joint_data.py $exp_dir/norm $exp_dir/data $src_lang $tgt_lang 'dev'\n",
        "python scripts/concat_joint_data.py $exp_dir/norm $exp_dir/data $src_lang $tgt_lang 'test'\n",
        "\n",
        "# use the vocab from downloaded dir\n",
        "cp -r $download_dir/vocab $exp_dir\n",
        "\n",
        "\n",
        "echo \"Applying bpe to the new finetuning data\"\n",
        "bash apply_single_bpe_traindevtest_notag.sh $exp_dir\n",
        "\n",
        "mkdir -p $exp_dir/final\n",
        "\n",
        "# We also add special tags to indicate the source and target language in the inputs\n",
        "#  Eg: to translate a sentence from english to hindi , the input would be   __src__en__   __tgt__hi__ <en bpe tokens>\n",
        "\n",
        "echo \"Adding language tags\"\n",
        "python scripts/add_joint_tags_translate.py $exp_dir 'train'\n",
        "python scripts/add_joint_tags_translate.py $exp_dir 'dev'\n",
        "python scripts/add_joint_tags_translate.py $exp_dir 'test'\n",
        "\n",
        "\n",
        "\n",
        "data_dir=$exp_dir/final\n",
        "out_data_dir=$exp_dir/final_bin\n",
        "\n",
        "rm -rf $out_data_dir\n",
        "\n",
        "# binarizing the new data (train, dev and test) using dictionary from the download dir\n",
        "\n",
        " num_workers=`python -c \"import multiprocessing; print(multiprocessing.cpu_count())\"`\n",
        "\n",
        "data_dir=$exp_dir/final\n",
        "out_data_dir=$exp_dir/final_bin\n",
        "\n",
        "# rm -rf $out_data_dir\n",
        "\n",
        "echo \"Binarizing data. This will take some time depending on the size of finetuning data\"\n",
        "fairseq-preprocess --source-lang SRC --target-lang TGT \\\n",
        " --trainpref $data_dir/train --validpref $data_dir/dev --testpref $data_dir/test \\\n",
        " --destdir $out_data_dir --workers $num_workers \\\n",
        " --srcdict $download_dir/final_bin/dict.SRC.txt --tgtdict $download_dir/final_bin/dict.TGT.txt --thresholdtgt 5 --thresholdsrc 5  "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running experiment ../dataset on en to indic\n",
            "Applying normalization and script conversion for train mr\n",
            "100% 20933/20933 [00:04<00:00, 5153.30it/s]\n",
            "100% 20933/20933 [00:02<00:00, 10402.85it/s]\n",
            "Number of sentences in train mr: 20933\n",
            "Applying normalization and script conversion for dev mr\n",
            "100% 500/500 [00:00<00:00, 1038.28it/s]\n",
            "100% 500/500 [00:00<00:00, 4430.11it/s]\n",
            "Number of sentences in dev mr: 500\n",
            "Applying normalization and script conversion for test mr\n",
            "100% 500/500 [00:00<00:00, 1069.13it/s]\n",
            "100% 500/500 [00:00<00:00, 4363.76it/s]\n",
            "Number of sentences in test mr: 500\n",
            "\n",
            "../dataset/data/train.SRC\n",
            "../dataset/data/train.TGT\n",
            "  0% 0/11 [00:00<?, ?it/s]src: en, tgt:as\n",
            "src: en, tgt:bn\n",
            "src: en, tgt:gu\n",
            "src: en, tgt:hi\n",
            "src: en, tgt:kn\n",
            "src: en, tgt:ml\n",
            "src: en, tgt:mr\n",
            "../dataset/norm/en-mr/train.en\n",
            "../dataset/norm/en-mr/train.mr\n",
            "src: en, tgt:or\n",
            "src: en, tgt:pa\n",
            "src: en, tgt:ta\n",
            "src: en, tgt:te\n",
            "100% 11/11 [00:00<00:00, 687.09it/s]\n",
            "  0% 0/11 [00:00<?, ?it/s]src: en, tgt:as\n",
            "src: en, tgt:bn\n",
            "src: en, tgt:gu\n",
            "src: en, tgt:hi\n",
            "src: en, tgt:kn\n",
            "src: en, tgt:ml\n",
            "src: en, tgt:mr\n",
            "../dataset/norm/en-mr/train.en\n",
            "src: en, tgt:or\n",
            "src: en, tgt:pa\n",
            "src: en, tgt:ta\n",
            "src: en, tgt:te\n",
            "100% 11/11 [00:00<00:00, 2289.24it/s]\n",
            "\n",
            "../dataset/data/dev.SRC\n",
            "../dataset/data/dev.TGT\n",
            "  0% 0/11 [00:00<?, ?it/s]src: en, tgt:as\n",
            "src: en, tgt:bn\n",
            "src: en, tgt:gu\n",
            "src: en, tgt:hi\n",
            "src: en, tgt:kn\n",
            "src: en, tgt:ml\n",
            "src: en, tgt:mr\n",
            "../dataset/norm/en-mr/dev.en\n",
            "../dataset/norm/en-mr/dev.mr\n",
            "src: en, tgt:or\n",
            "src: en, tgt:pa\n",
            "src: en, tgt:ta\n",
            "src: en, tgt:te\n",
            "100% 11/11 [00:00<00:00, 1095.22it/s]\n",
            "  0% 0/11 [00:00<?, ?it/s]src: en, tgt:as\n",
            "src: en, tgt:bn\n",
            "src: en, tgt:gu\n",
            "src: en, tgt:hi\n",
            "src: en, tgt:kn\n",
            "src: en, tgt:ml\n",
            "src: en, tgt:mr\n",
            "../dataset/norm/en-mr/dev.en\n",
            "src: en, tgt:or\n",
            "src: en, tgt:pa\n",
            "src: en, tgt:ta\n",
            "src: en, tgt:te\n",
            "100% 11/11 [00:00<00:00, 16120.67it/s]\n",
            "\n",
            "../dataset/data/test.SRC\n",
            "../dataset/data/test.TGT\n",
            "  0% 0/11 [00:00<?, ?it/s]src: en, tgt:as\n",
            "src: en, tgt:bn\n",
            "src: en, tgt:gu\n",
            "src: en, tgt:hi\n",
            "src: en, tgt:kn\n",
            "src: en, tgt:ml\n",
            "src: en, tgt:mr\n",
            "../dataset/norm/en-mr/test.en\n",
            "../dataset/norm/en-mr/test.mr\n",
            "src: en, tgt:or\n",
            "src: en, tgt:pa\n",
            "src: en, tgt:ta\n",
            "src: en, tgt:te\n",
            "100% 11/11 [00:00<00:00, 1103.37it/s]\n",
            "  0% 0/11 [00:00<?, ?it/s]src: en, tgt:as\n",
            "src: en, tgt:bn\n",
            "src: en, tgt:gu\n",
            "src: en, tgt:hi\n",
            "src: en, tgt:kn\n",
            "src: en, tgt:ml\n",
            "src: en, tgt:mr\n",
            "../dataset/norm/en-mr/test.en\n",
            "src: en, tgt:or\n",
            "src: en, tgt:pa\n",
            "src: en, tgt:ta\n",
            "src: en, tgt:te\n",
            "100% 11/11 [00:00<00:00, 19938.35it/s]\n",
            "Applying bpe to the new finetuning data\n",
            "train\n",
            "Apply to SRC corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "Apply to TGT corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "dev\n",
            "Apply to SRC corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "Apply to TGT corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "test\n",
            "Apply to SRC corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "Apply to TGT corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "Adding language tags\n",
            "20933it [00:00, 227003.72it/s]\n",
            "500it [00:00, 144850.95it/s]\n",
            "500it [00:00, 157455.66it/s]\n",
            "Binarizing data. This will take some time depending on the size of finetuning data\n",
            "2021-06-05 09:24:35 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='../dataset/final_bin', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='SRC', srcdict='../en-indic/final_bin/dict.SRC.txt', suppress_crashes=False, target_lang='TGT', task='translation', tensorboard_logdir=None, testpref='../dataset/final/test', tgtdict='../en-indic/final_bin/dict.TGT.txt', threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer=None, tpu=False, trainpref='../dataset/final/train', use_plasma_view=False, user_dir=None, validpref='../dataset/final/dev', wandb_project=None, workers=2)\n",
            "2021-06-05 09:24:35 | INFO | fairseq_cli.preprocess | [SRC] Dictionary: 32104 types\n",
            "2021-06-05 09:24:37 | INFO | fairseq_cli.preprocess | [SRC] ../dataset/final/train.SRC: 20933 sents, 503773 tokens, 0.0994% replaced by <unk>\n",
            "2021-06-05 09:24:37 | INFO | fairseq_cli.preprocess | [SRC] Dictionary: 32104 types\n",
            "2021-06-05 09:24:37 | INFO | fairseq_cli.preprocess | [SRC] ../dataset/final/dev.SRC: 500 sents, 17331 tokens, 0.144% replaced by <unk>\n",
            "2021-06-05 09:24:37 | INFO | fairseq_cli.preprocess | [SRC] Dictionary: 32104 types\n",
            "2021-06-05 09:24:37 | INFO | fairseq_cli.preprocess | [SRC] ../dataset/final/test.SRC: 500 sents, 17331 tokens, 0.144% replaced by <unk>\n",
            "2021-06-05 09:24:37 | INFO | fairseq_cli.preprocess | [TGT] Dictionary: 35848 types\n",
            "2021-06-05 09:24:40 | INFO | fairseq_cli.preprocess | [TGT] ../dataset/final/train.TGT: 20933 sents, 564942 tokens, 0.0453% replaced by <unk>\n",
            "2021-06-05 09:24:40 | INFO | fairseq_cli.preprocess | [TGT] Dictionary: 35848 types\n",
            "2021-06-05 09:24:40 | INFO | fairseq_cli.preprocess | [TGT] ../dataset/final/dev.TGT: 500 sents, 22527 tokens, 0.04% replaced by <unk>\n",
            "2021-06-05 09:24:40 | INFO | fairseq_cli.preprocess | [TGT] Dictionary: 35848 types\n",
            "2021-06-05 09:24:40 | INFO | fairseq_cli.preprocess | [TGT] ../dataset/final/test.TGT: 500 sents, 22527 tokens, 0.04% replaced by <unk>\n",
            "2021-06-05 09:24:40 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ../dataset/final_bin\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz6tzbe2tcs7",
        "outputId": "21946650-b6a7-4916-9a6a-1074baf8c89c"
      },
      "source": [
        "# Finetuning the model\n",
        "\n",
        "# pls refer to fairseq documentaion to know more about each of these options (https://fairseq.readthedocs.io/en/latest/command_line_tools.html)\n",
        "\n",
        "\n",
        "# some notable args:\n",
        "# --max-update=1000     -> for this example, to demonstrate how to finetune we are only training for 1000 steps, incrase this if needed\n",
        "# --arch=transformer_4x -> we use a custom transformer model and name it transformer_4x (4 times the parameter size of transformer  base)\n",
        "# --user_dir            -> we define the custom transformer arch in model_configs folder and pass it as an argument to user_dir for fairseq to register this architechture\n",
        "# --lr                  -> learning rate. From our limited experiments, we find that lower learning rates like 3e-5 works best for finetuning.\n",
        "# --restore-file        -> reload the pretrained checkpoint and start training from here (change this path for indic-en. Currently its is set to en-indic)\n",
        "# --reset-*             -> reset and not use lr scheduler, dataloader, optimizer etc of the older checkpoint\n",
        "# --max_tokns           -> this is max tokens per batch\n",
        "\n",
        "\n",
        "!( fairseq-train ../dataset/final_bin \\\n",
        "--max-source-positions=210 \\\n",
        "--max-target-positions=210 \\\n",
        "--max-update=100000 \\\n",
        "--save-interval=1 \\\n",
        "--arch=transformer_4x \\\n",
        "--criterion=label_smoothed_cross_entropy \\\n",
        "--source-lang=SRC \\\n",
        "--max-epoch=3 \\\n",
        "--lr-scheduler=inverse_sqrt \\\n",
        "--target-lang=TGT \\\n",
        "--label-smoothing=0.1 \\\n",
        "--optimizer adam \\\n",
        "--adam-betas \"(0.9, 0.98)\" \\\n",
        "--clip-norm 1.0 \\\n",
        "--warmup-init-lr 1e-07 \\\n",
        "--warmup-updates 4000 \\\n",
        "--dropout 0.2 \\\n",
        "--tensorboard-logdir ../dataset/tensorboard-wandb \\\n",
        "--save-dir ../dataset/model \\\n",
        "--keep-last-epochs 5 \\\n",
        "--patience 5 \\\n",
        "--skip-invalid-size-inputs-valid-test \\\n",
        "--fp16 \\\n",
        "--no-last-checkpoints \\\n",
        "--user-dir model_configs \\\n",
        "--update-freq=2 \\\n",
        "--distributed-world-size 1 \\\n",
        "--max-tokens 4096 \\\n",
        "--lr 3e-5 \\\n",
        "--restore-file ../en-indic/model/checkpoint_best.pt \\\n",
        "--reset-lr-scheduler \\\n",
        "--reset-meters \\\n",
        "--reset-dataloader \\\n",
        "--reset-optimizer)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-05 09:25:18 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': '../dataset/tensorboard-wandb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'model_configs', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 3, 'max_update': 100000, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../dataset/model', 'restore_file': '../en-indic/model/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 5, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_4x', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_4x', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../dataset/final_bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=16, decoder_embed_dim=1536, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1536, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1536, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1536, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[3e-05], lr_scheduler='inverse_sqrt', max_epoch=3, max_source_positions=210, max_target_positions=210, max_tokens=4096, max_tokens_valid=4096, max_update=100000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=True, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=5, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='../en-indic/model/checkpoint_best.pt', save_dir='../dataset/model', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='SRC', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='TGT', task='translation', tensorboard_logdir='../dataset/tensorboard-wandb', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[2], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir='model_configs', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': '../dataset/final_bin', 'source_lang': 'SRC', 'target_lang': 'TGT', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 210, 'max_target_positions': 210, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}\n",
            "2021-06-05 09:25:18 | INFO | fairseq.tasks.translation | [SRC] dictionary: 32104 types\n",
            "2021-06-05 09:25:18 | INFO | fairseq.tasks.translation | [TGT] dictionary: 35848 types\n",
            "2021-06-05 09:25:24 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(32104, 1536, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(35848, 1536, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=1536, out_features=35848, bias=False)\n",
            "  )\n",
            ")\n",
            "2021-06-05 09:25:24 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2021-06-05 09:25:24 | INFO | fairseq_cli.train | model: TransformerModel\n",
            "2021-06-05 09:25:24 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2021-06-05 09:25:24 | INFO | fairseq_cli.train | num. shared model params: 480,571,392 (num. trained: 480,571,392)\n",
            "2021-06-05 09:25:24 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-06-05 09:25:24 | INFO | fairseq.data.data_utils | loaded 500 examples from: ../dataset/final_bin/valid.SRC-TGT.SRC\n",
            "2021-06-05 09:25:24 | INFO | fairseq.data.data_utils | loaded 500 examples from: ../dataset/final_bin/valid.SRC-TGT.TGT\n",
            "2021-06-05 09:25:24 | INFO | fairseq.tasks.translation | ../dataset/final_bin valid SRC-TGT 500 examples\n",
            "2021-06-05 09:25:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-06-05 09:25:36 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n",
            "2021-06-05 09:25:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-06-05 09:25:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-06-05 09:25:36 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None\n",
            "2021-06-05 09:25:36 | INFO | fairseq.trainer | Preparing to load checkpoint ../en-indic/model/checkpoint_best.pt\n",
            "tcmalloc: large alloc 1922285568 bytes == 0x56513c316000 @  0x7f6a56815b6b 0x7f6a56835379 0x7f69f509f25e 0x7f69f50a09d2 0x7f6a330c9e7d 0x7f6a43cc4120 0x7f6a43902bd9 0x5650309ef8a8 0x565030a62fd5 0x565030a5d7ad 0x5650309f03ea 0x565030a5e3b5 0x565030a5d7ad 0x5650309f0003 0x5650309efb09 0x565030b3728d 0x565030aa61db 0x5650309eebb1 0x565030adffed 0x565030a62988 0x565030a5d7ad 0x56503092fe2c 0x565030a5fbb5 0x565030a5d4ae 0x5650309f03ea 0x565030a5f32a 0x565030a5d4ae 0x5650309f03ea 0x565030a5f32a 0x565030a5d4ae 0x5650309f03ea\n",
            "tcmalloc: large alloc 1922285568 bytes == 0x5651af452000 @  0x7f6a56815b6b 0x7f6a56835379 0x7f69f509f25e 0x7f69f50a09d2 0x7f6a330c9e7d 0x7f6a43cc4120 0x7f6a43902bd9 0x5650309ef8a8 0x565030a62fd5 0x565030a5d7ad 0x5650309f03ea 0x565030a5e3b5 0x565030a5d7ad 0x5650309f0003 0x5650309efb09 0x565030b3728d 0x565030aa61db 0x5650309eebb1 0x565030adffed 0x565030a62988 0x565030a5d7ad 0x56503092fe2c 0x565030a5fbb5 0x565030a5d4ae 0x5650309f03ea 0x565030a5f32a 0x565030a5d4ae 0x5650309f03ea 0x565030a5f32a 0x565030a5d4ae 0x5650309f03ea\n",
            "2021-06-05 09:28:10 | INFO | fairseq.trainer | Loaded checkpoint ../en-indic/model/checkpoint_best.pt (epoch 20 @ 0 updates)\n",
            "2021-06-05 09:28:10 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-06-05 09:28:10 | INFO | fairseq.data.data_utils | loaded 20,933 examples from: ../dataset/final_bin/train.SRC-TGT.SRC\n",
            "2021-06-05 09:28:10 | INFO | fairseq.data.data_utils | loaded 20,933 examples from: ../dataset/final_bin/train.SRC-TGT.TGT\n",
            "2021-06-05 09:28:10 | INFO | fairseq.tasks.translation | ../dataset/final_bin train SRC-TGT 20933 examples\n",
            "2021-06-05 09:28:10 | WARNING | fairseq.tasks.fairseq_task | 2 samples have invalid sizes and will be skipped, max_positions=(210, 210), first few sample ids=[5744, 18025]\n",
            "epoch 001:   0% 0/101 [00:00<?, ?it/s]2021-06-05 09:28:10 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2021-06-05 09:28:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-06-05 09:28:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "epoch 001:   1% 1/101 [00:01<02:24,  1.44s/it]2021-06-05 09:28:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "epoch 001:   3% 3/101 [00:03<02:02,  1.25s/it]2021-06-05 09:28:14 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 552.00 MiB (GPU 0; 14.76 GiB total capacity; 12.81 GiB already allocated; 447.75 MiB free; 13.29 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:28:14 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12563 MB |   13115 MB |   95604 MB |   83041 MB |\n",
            "|       from large pool |   12560 MB |   13112 MB |   95560 MB |   82999 MB |\n",
            "|       from small pool |       2 MB |       3 MB |      44 MB |      41 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12563 MB |   13115 MB |   95604 MB |   83041 MB |\n",
            "|       from large pool |   12560 MB |   13112 MB |   95560 MB |   82999 MB |\n",
            "|       from small pool |       2 MB |       3 MB |      44 MB |      41 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13608 MB |   13632 MB |   28838 MB |   15230 MB |\n",
            "|       from large pool |   13604 MB |   13628 MB |   28826 MB |   15222 MB |\n",
            "|       from small pool |       4 MB |       4 MB |      12 MB |       8 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |  503939 KB |    2578 MB |   60572 MB |   60080 MB |\n",
            "|       from large pool |  502795 KB |    2577 MB |   60519 MB |   60028 MB |\n",
            "|       from small pool |    1144 KB |       2 MB |      53 MB |      52 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |   11455    |   10631    |\n",
            "|       from large pool |     440    |     443    |    7212    |    6772    |\n",
            "|       from small pool |     384    |     388    |    4243    |    3859    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |   11455    |   10631    |\n",
            "|       from large pool |     440    |     443    |    7212    |    6772    |\n",
            "|       from small pool |     384    |     388    |    4243    |    3859    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |     107    |     109    |     448    |     341    |\n",
            "|       from large pool |     105    |     107    |     442    |     337    |\n",
            "|       from small pool |       2    |       2    |       6    |       4    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      89    |     123    |    5372    |    5283    |\n",
            "|       from large pool |      53    |      83    |    3951    |    3898    |\n",
            "|       from small pool |      36    |      42    |    1421    |    1385    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:28:14 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:   9% 9/101 [00:09<01:38,  1.07s/it]2021-06-05 09:28:20 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 552.00 MiB (GPU 0; 14.76 GiB total capacity; 13.13 GiB already allocated; 109.75 MiB free; 13.62 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:28:20 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 2            |        cudaMalloc retries: 2         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12889 MB |   13441 MB |  231086 MB |  218196 MB |\n",
            "|       from large pool |   12887 MB |   13438 MB |  230790 MB |  217902 MB |\n",
            "|       from small pool |       2 MB |       3 MB |     296 MB |     293 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12889 MB |   13441 MB |  231086 MB |  218196 MB |\n",
            "|       from large pool |   12887 MB |   13438 MB |  230790 MB |  217902 MB |\n",
            "|       from small pool |       2 MB |       3 MB |     296 MB |     293 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13946 MB |   14016 MB |   30002 MB |   16056 MB |\n",
            "|       from large pool |   13940 MB |   13952 MB |   29930 MB |   15990 MB |\n",
            "|       from small pool |       6 MB |      64 MB |      72 MB |      66 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1056 MB |    2206 MB |  211419 MB |  210363 MB |\n",
            "|       from large pool |    1052 MB |    2202 MB |  211072 MB |  210019 MB |\n",
            "|       from small pool |       3 MB |       5 MB |     347 MB |     344 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     825    |     830    |   28794    |   27969    |\n",
            "|       from large pool |     440    |     443    |   17742    |   17302    |\n",
            "|       from small pool |     385    |     389    |   11052    |   10667    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     825    |     830    |   28794    |   27969    |\n",
            "|       from large pool |     440    |     443    |   17742    |   17302    |\n",
            "|       from small pool |     385    |     389    |   11052    |   10667    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      95    |     125    |     480    |     385    |\n",
            "|       from large pool |      92    |      93    |     444    |     352    |\n",
            "|       from small pool |       3    |      32    |      36    |      33    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |     113    |     117    |   13972    |   13859    |\n",
            "|       from large pool |      71    |      71    |    9732    |    9661    |\n",
            "|       from small pool |      42    |      50    |    4240    |    4198    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:28:20 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  13% 13/101 [00:13<01:25,  1.03it/s]2021-06-05 09:28:24 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 548.00 MiB (GPU 0; 14.76 GiB total capacity; 12.67 GiB already allocated; 345.75 MiB free; 13.39 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:28:24 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 3            |        cudaMalloc retries: 3         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12427 MB |   12974 MB |  316413 MB |  303986 MB |\n",
            "|       from large pool |   12424 MB |   12971 MB |  315994 MB |  303569 MB |\n",
            "|       from small pool |       2 MB |       3 MB |     419 MB |     416 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12427 MB |   12974 MB |  316413 MB |  303986 MB |\n",
            "|       from large pool |   12424 MB |   12971 MB |  315994 MB |  303569 MB |\n",
            "|       from small pool |       2 MB |       3 MB |     419 MB |     416 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13710 MB |   13744 MB |   30016 MB |   16306 MB |\n",
            "|       from large pool |   13704 MB |   13724 MB |   29930 MB |   16226 MB |\n",
            "|       from small pool |       6 MB |      20 MB |      86 MB |      80 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1282 MB |    2061 MB |  308784 MB |  307502 MB |\n",
            "|       from large pool |    1279 MB |    2057 MB |  308295 MB |  307016 MB |\n",
            "|       from small pool |       3 MB |       6 MB |     488 MB |     485 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |   40223    |   39399    |\n",
            "|       from large pool |     440    |     443    |   24811    |   24371    |\n",
            "|       from small pool |     384    |     388    |   15412    |   15028    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |   40223    |   39399    |\n",
            "|       from large pool |     440    |     443    |   24811    |   24371    |\n",
            "|       from small pool |     384    |     388    |   15412    |   15028    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      80    |      88    |     487    |     407    |\n",
            "|       from large pool |      77    |      78    |     444    |     367    |\n",
            "|       from small pool |       3    |      10    |      43    |      40    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      86    |     117    |   19323    |   19237    |\n",
            "|       from large pool |      43    |      73    |   13464    |   13421    |\n",
            "|       from small pool |      43    |      49    |    5859    |    5816    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:28:24 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  16% 16/101 [00:16<01:26,  1.01s/it]2021-06-05 09:28:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n",
            "epoch 001:  19% 19/101 [00:19<01:25,  1.05s/it]2021-06-05 09:28:30 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 542.00 MiB (GPU 0; 14.76 GiB total capacity; 12.65 GiB already allocated; 371.75 MiB free; 13.36 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:28:30 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 4            |        cudaMalloc retries: 4         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12413 MB |   12954 MB |  459446 MB |  447033 MB |\n",
            "|       from large pool |   12410 MB |   12951 MB |  458965 MB |  446554 MB |\n",
            "|       from small pool |       2 MB |       3 MB |     481 MB |     478 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12413 MB |   12954 MB |  459446 MB |  447033 MB |\n",
            "|       from large pool |   12410 MB |   12951 MB |  458965 MB |  446554 MB |\n",
            "|       from small pool |       2 MB |       3 MB |     481 MB |     478 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13684 MB |   13690 MB |   30020 MB |   16336 MB |\n",
            "|       from large pool |   13680 MB |   13680 MB |   29930 MB |   16250 MB |\n",
            "|       from small pool |       4 MB |      10 MB |      90 MB |      86 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1270 MB |    1843 MB |  478898 MB |  477628 MB |\n",
            "|       from large pool |    1269 MB |    1841 MB |  478342 MB |  477073 MB |\n",
            "|       from small pool |       1 MB |       3 MB |     556 MB |     555 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     825    |     830    |   57824    |   56999    |\n",
            "|       from large pool |     440    |     443    |   35904    |   35464    |\n",
            "|       from small pool |     385    |     389    |   21920    |   21535    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     825    |     830    |   57824    |   56999    |\n",
            "|       from large pool |     440    |     443    |   35904    |   35464    |\n",
            "|       from small pool |     385    |     389    |   21920    |   21535    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      77    |      80    |     489    |     412    |\n",
            "|       from large pool |      75    |      75    |     444    |     369    |\n",
            "|       from small pool |       2    |       5    |      45    |      43    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |     102    |     105    |   27228    |   27126    |\n",
            "|       from large pool |      73    |      73    |   19229    |   19156    |\n",
            "|       from small pool |      29    |      40    |    7999    |    7970    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:28:30 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  20% 20/101 [00:20<01:14,  1.08it/s]2021-06-05 09:28:31 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 530.00 MiB (GPU 0; 14.76 GiB total capacity; 12.71 GiB already allocated; 503.75 MiB free; 13.23 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:28:31 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 5            |        cudaMalloc retries: 5         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12483 MB |   13013 MB |  477264 MB |  464781 MB |\n",
            "|       from large pool |   12480 MB |   13010 MB |  476777 MB |  464296 MB |\n",
            "|       from small pool |       2 MB |       3 MB |     487 MB |     484 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12483 MB |   13013 MB |  477264 MB |  464781 MB |\n",
            "|       from large pool |   12480 MB |   13010 MB |  476777 MB |  464296 MB |\n",
            "|       from small pool |       2 MB |       3 MB |     487 MB |     484 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13552 MB |   13690 MB |   30020 MB |   16468 MB |\n",
            "|       from large pool |   13548 MB |   13680 MB |   29930 MB |   16382 MB |\n",
            "|       from small pool |       4 MB |      10 MB |      90 MB |      86 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1068 MB |    2342 MB |  501439 MB |  500371 MB |\n",
            "|       from large pool |    1067 MB |    2341 MB |  500877 MB |  499810 MB |\n",
            "|       from small pool |       1 MB |       3 MB |     561 MB |     560 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     830    |   59822    |   58998    |\n",
            "|       from large pool |     440    |     443    |   37232    |   36792    |\n",
            "|       from small pool |     384    |     389    |   22590    |   22206    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     830    |   59822    |   58998    |\n",
            "|       from large pool |     440    |     443    |   37232    |   36792    |\n",
            "|       from small pool |     384    |     389    |   22590    |   22206    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      66    |      80    |     489    |     423    |\n",
            "|       from large pool |      64    |      75    |     444    |     380    |\n",
            "|       from small pool |       2    |       5    |      45    |      43    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      91    |     106    |   28140    |   28049    |\n",
            "|       from large pool |      49    |      74    |   19909    |   19860    |\n",
            "|       from small pool |      42    |      52    |    8231    |    8189    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:28:31 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  22% 22/101 [00:21<01:13,  1.08it/s]2021-06-05 09:28:32 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 554.00 MiB (GPU 0; 14.76 GiB total capacity; 12.87 GiB already allocated; 539.75 MiB free; 13.20 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:28:32 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 6            |        cudaMalloc retries: 6         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12629 MB |   13183 MB |  519105 MB |  506475 MB |\n",
            "|       from large pool |   12626 MB |   13180 MB |  518604 MB |  505977 MB |\n",
            "|       from small pool |       2 MB |       3 MB |     501 MB |     498 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12629 MB |   13183 MB |  519105 MB |  506475 MB |\n",
            "|       from large pool |   12626 MB |   13180 MB |  518604 MB |  505977 MB |\n",
            "|       from small pool |       2 MB |       3 MB |     501 MB |     498 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13516 MB |   13516 MB |   30020 MB |   16504 MB |\n",
            "|       from large pool |   13512 MB |   13512 MB |   29930 MB |   16418 MB |\n",
            "|       from small pool |       4 MB |       4 MB |      90 MB |      86 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |     886 MB |    2579 MB |  552628 MB |  551742 MB |\n",
            "|       from large pool |     885 MB |    2577 MB |  552052 MB |  551167 MB |\n",
            "|       from small pool |       1 MB |       2 MB |     575 MB |     574 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |   64969    |   64145    |\n",
            "|       from large pool |     440    |     443    |   40537    |   40097    |\n",
            "|       from small pool |     384    |     388    |   24432    |   24048    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |   64969    |   64145    |\n",
            "|       from large pool |     440    |     443    |   40537    |   40097    |\n",
            "|       from small pool |     384    |     388    |   24432    |   24048    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      63    |      63    |     489    |     426    |\n",
            "|       from large pool |      61    |      61    |     444    |     383    |\n",
            "|       from small pool |       2    |       2    |      45    |      43    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      97    |     106    |   30552    |   30455    |\n",
            "|       from large pool |      56    |      58    |   21591    |   21535    |\n",
            "|       from small pool |      41    |      49    |    8961    |    8920    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:28:32 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  26% 26/101 [00:25<01:18,  1.05s/it]2021-06-05 09:28:36 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 548.00 MiB (GPU 0; 14.76 GiB total capacity; 12.89 GiB already allocated; 17.75 MiB free; 13.71 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:28:36 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 7            |        cudaMalloc retries: 7         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12654 MB |   13201 MB |  607228 MB |  594573 MB |\n",
            "|       from large pool |   12651 MB |   13198 MB |  606673 MB |  594021 MB |\n",
            "|       from small pool |       2 MB |      14 MB |     554 MB |     551 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12654 MB |   13201 MB |  607228 MB |  594573 MB |\n",
            "|       from large pool |   12651 MB |   13198 MB |  606673 MB |  594021 MB |\n",
            "|       from small pool |       2 MB |      14 MB |     554 MB |     551 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   14038 MB |   14052 MB |   30568 MB |   16530 MB |\n",
            "|       from large pool |   14034 MB |   14034 MB |   30464 MB |   16430 MB |\n",
            "|       from small pool |       4 MB |      18 MB |     104 MB |     100 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1383 MB |    2104 MB |  656932 MB |  655548 MB |\n",
            "|       from large pool |    1382 MB |    2102 MB |  656298 MB |  654916 MB |\n",
            "|       from small pool |       1 MB |       5 MB |     633 MB |     631 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |   76366    |   75542    |\n",
            "|       from large pool |     440    |     443    |   47724    |   47284    |\n",
            "|       from small pool |     384    |     388    |   28642    |   28258    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |   76366    |   75542    |\n",
            "|       from large pool |     440    |     443    |   47724    |   47284    |\n",
            "|       from small pool |     384    |     388    |   28642    |   28258    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      63    |      70    |     497    |     434    |\n",
            "|       from large pool |      61    |      61    |     445    |     384    |\n",
            "|       from small pool |       2    |       9    |      52    |      50    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      77    |     106    |   35701    |   35624    |\n",
            "|       from large pool |      45    |      61    |   25202    |   25157    |\n",
            "|       from small pool |      32    |      45    |   10499    |   10467    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:28:36 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  33% 33/101 [00:33<01:16,  1.12s/it]2021-06-05 09:28:44 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 536.00 MiB (GPU 0; 14.76 GiB total capacity; 12.99 GiB already allocated; 17.75 MiB free; 13.71 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:28:44 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 8            |        cudaMalloc retries: 8         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12769 MB |   13304 MB |  775850 MB |  763080 MB |\n",
            "|       from large pool |   12766 MB |   13301 MB |  775172 MB |  762405 MB |\n",
            "|       from small pool |       2 MB |       3 MB |     677 MB |     674 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12769 MB |   13304 MB |  775850 MB |  763080 MB |\n",
            "|       from large pool |   12766 MB |   13301 MB |  775172 MB |  762405 MB |\n",
            "|       from small pool |       2 MB |       3 MB |     677 MB |     674 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   14038 MB |   14052 MB |   30582 MB |   16544 MB |\n",
            "|       from large pool |   14034 MB |   14034 MB |   30464 MB |   16430 MB |\n",
            "|       from small pool |       4 MB |      18 MB |     118 MB |     114 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1268 MB |    1997 MB |     831 GB |     830 GB |\n",
            "|       from large pool |    1267 MB |    1995 MB |     830 GB |     829 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       0 GB |       0 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     825    |     830    |   97156    |   96331    |\n",
            "|       from large pool |     440    |     443    |   60733    |   60293    |\n",
            "|       from small pool |     385    |     389    |   36423    |   36038    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     825    |     830    |   97156    |   96331    |\n",
            "|       from large pool |     440    |     443    |   60733    |   60293    |\n",
            "|       from small pool |     385    |     389    |   36423    |   36038    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      63    |      70    |     504    |     441    |\n",
            "|       from large pool |      61    |      61    |     445    |     384    |\n",
            "|       from small pool |       2    |       9    |      59    |      57    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      92    |     102    |   45194    |   45102    |\n",
            "|       from large pool |      54    |      57    |   31776    |   31722    |\n",
            "|       from small pool |      38    |      46    |   13418    |   13380    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:28:44 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  35% 35/101 [00:35<01:11,  1.08s/it]2021-06-05 09:28:46 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 14.76 GiB total capacity; 12.99 GiB already allocated; 57.75 MiB free; 13.67 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:28:46 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 9            |        cudaMalloc retries: 9         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12738 MB |   13298 MB |     802 GB |     789 GB |\n",
            "|       from large pool |   12735 MB |   13295 MB |     801 GB |     789 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       0 GB |       0 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12738 MB |   13298 MB |     802 GB |     789 GB |\n",
            "|       from large pool |   12735 MB |   13295 MB |     801 GB |     789 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       0 GB |       0 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13998 MB |   13998 MB |   30582 MB |   16584 MB |\n",
            "|       from large pool |   13994 MB |   13994 MB |   30464 MB |   16470 MB |\n",
            "|       from small pool |       4 MB |       4 MB |     118 MB |     114 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1259 MB |    2947 MB |     884 GB |     883 GB |\n",
            "|       from large pool |    1258 MB |    2945 MB |     883 GB |     882 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       0 GB |       0 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  102271    |  101447    |\n",
            "|       from large pool |     440    |     443    |   64010    |   63570    |\n",
            "|       from small pool |     384    |     388    |   38261    |   37877    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  102271    |  101447    |\n",
            "|       from large pool |     440    |     443    |   64010    |   63570    |\n",
            "|       from small pool |     384    |     388    |   38261    |   37877    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      61    |      61    |     504    |     443    |\n",
            "|       from large pool |      59    |      59    |     445    |     386    |\n",
            "|       from small pool |       2    |       2    |      59    |      57    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |     101    |     106    |   47482    |   47381    |\n",
            "|       from large pool |      59    |      62    |   33305    |   33246    |\n",
            "|       from small pool |      42    |      47    |   14177    |   14135    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:28:46 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  43% 43/101 [00:43<01:04,  1.12s/it]2021-06-05 09:28:54 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 554.00 MiB (GPU 0; 14.76 GiB total capacity; 12.87 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:28:54 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 10           |        cudaMalloc retries: 10        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12620 MB |   13174 MB |     987 GB |     975 GB |\n",
            "|       from large pool |   12617 MB |   13171 MB |     986 GB |     974 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       0 GB |       0 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12620 MB |   13174 MB |     987 GB |     975 GB |\n",
            "|       from large pool |   12617 MB |   13171 MB |     986 GB |     974 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       0 GB |       0 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13980 MB |   30596 MB |   16630 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      18 MB |     132 MB |     128 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1345 MB |    2522 MB |    1096 GB |    1095 GB |\n",
            "|       from large pool |    1344 MB |    2520 MB |    1095 GB |    1094 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       0 GB |       0 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  126056    |  125232    |\n",
            "|       from large pool |     440    |     443    |   78886    |   78446    |\n",
            "|       from small pool |     384    |     388    |   47170    |   46786    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  126056    |  125232    |\n",
            "|       from large pool |     440    |     443    |   78886    |   78446    |\n",
            "|       from small pool |     384    |     388    |   47170    |   46786    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      66    |     511    |     452    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       9    |      66    |      64    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      96    |     109    |   57944    |   57848    |\n",
            "|       from large pool |      58    |      67    |   40401    |   40343    |\n",
            "|       from small pool |      38    |      43    |   17543    |   17505    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:28:54 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  44% 44/101 [00:44<00:56,  1.01it/s]2021-06-05 09:28:55 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 558.00 MiB (GPU 0; 14.76 GiB total capacity; 12.97 GiB already allocated; 87.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:28:55 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 11           |        cudaMalloc retries: 11        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12721 MB |   13279 MB |    1000 GB |     988 GB |\n",
            "|       from large pool |   12718 MB |   13276 MB |     999 GB |     987 GB |\n",
            "|       from small pool |       2 MB |      18 MB |       0 GB |       0 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12721 MB |   13279 MB |    1000 GB |     988 GB |\n",
            "|       from large pool |   12718 MB |   13276 MB |     999 GB |     987 GB |\n",
            "|       from small pool |       2 MB |      18 MB |       0 GB |       0 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13968 MB |   13982 MB |   30612 MB |   16644 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       6 MB |      20 MB |     148 MB |     142 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1246 MB |    2544 MB |    1114 GB |    1113 GB |\n",
            "|       from large pool |    1243 MB |    2542 MB |    1113 GB |    1112 GB |\n",
            "|       from small pool |       3 MB |       4 MB |       0 GB |       0 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  128070    |  127246    |\n",
            "|       from large pool |     440    |     443    |   80131    |   79691    |\n",
            "|       from small pool |     384    |     388    |   47939    |   47555    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  128070    |  127246    |\n",
            "|       from large pool |     440    |     443    |   80131    |   79691    |\n",
            "|       from small pool |     384    |     388    |   47939    |   47555    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      60    |      67    |     519    |     459    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       3    |      10    |      74    |      71    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      65    |     109    |   58880    |   58815    |\n",
            "|       from large pool |      29    |      67    |   41076    |   41047    |\n",
            "|       from small pool |      36    |      43    |   17804    |   17768    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:28:55 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  55% 56/101 [00:58<00:54,  1.22s/it]2021-06-05 09:29:09 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 532.00 MiB (GPU 0; 14.76 GiB total capacity; 12.80 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:29:09 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 12           |        cudaMalloc retries: 12        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12574 MB |   13105 MB |    1290 GB |    1278 GB |\n",
            "|       from large pool |   12571 MB |   13103 MB |    1289 GB |    1277 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12574 MB |   13105 MB |    1290 GB |    1278 GB |\n",
            "|       from large pool |   12571 MB |   13103 MB |    1289 GB |    1277 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13980 MB |   30626 MB |   16660 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      18 MB |     162 MB |     158 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1391 MB |    2860 MB |    1441 GB |    1440 GB |\n",
            "|       from large pool |    1390 MB |    2858 MB |    1440 GB |    1439 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  164395    |  163571    |\n",
            "|       from large pool |     440    |     443    |  102816    |  102376    |\n",
            "|       from small pool |     384    |     388    |   61579    |   61195    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  164395    |  163571    |\n",
            "|       from large pool |     440    |     443    |  102816    |  102376    |\n",
            "|       from small pool |     384    |     388    |   61579    |   61195    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      66    |     526    |     467    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       9    |      81    |      79    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      83    |      99    |   74910    |   74827    |\n",
            "|       from large pool |      53    |      58    |   51836    |   51783    |\n",
            "|       from small pool |      30    |      42    |   23074    |   23044    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:29:09 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  57% 58/101 [01:00<00:47,  1.10s/it]2021-06-05 09:29:10 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 548.00 MiB (GPU 0; 14.76 GiB total capacity; 12.84 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:29:10 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 13           |        cudaMalloc retries: 13        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12597 MB |   13145 MB |    1331 GB |    1319 GB |\n",
            "|       from large pool |   12595 MB |   13142 MB |    1330 GB |    1318 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12597 MB |   13145 MB |    1331 GB |    1319 GB |\n",
            "|       from large pool |   12595 MB |   13142 MB |    1330 GB |    1318 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13966 MB |   30626 MB |   16660 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |       4 MB |     162 MB |     158 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1368 MB |    2500 MB |    1490 GB |    1488 GB |\n",
            "|       from large pool |    1366 MB |    2498 MB |    1488 GB |    1487 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  169543    |  168719    |\n",
            "|       from large pool |     440    |     443    |  106121    |  105681    |\n",
            "|       from small pool |     384    |     388    |   63422    |   63038    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  169543    |  168719    |\n",
            "|       from large pool |     440    |     443    |  106121    |  105681    |\n",
            "|       from small pool |     384    |     388    |   63422    |   63038    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      59    |     526    |     467    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       2    |      81    |      79    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      86    |      99    |   77137    |   77051    |\n",
            "|       from large pool |      47    |      57    |   53481    |   53434    |\n",
            "|       from small pool |      39    |      45    |   23656    |   23617    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:29:10 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  61% 62/101 [01:04<00:41,  1.07s/it]2021-06-05 09:29:15 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 556.00 MiB (GPU 0; 14.76 GiB total capacity; 12.94 GiB already allocated; 87.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:29:15 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 14           |        cudaMalloc retries: 14        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12692 MB |   13246 MB |    1419 GB |    1406 GB |\n",
            "|       from large pool |   12689 MB |   13243 MB |    1418 GB |    1405 GB |\n",
            "|       from small pool |       2 MB |      16 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12692 MB |   13246 MB |    1419 GB |    1406 GB |\n",
            "|       from large pool |   12689 MB |   13243 MB |    1418 GB |    1405 GB |\n",
            "|       from small pool |       2 MB |      16 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13968 MB |   13980 MB |   30640 MB |   16672 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       6 MB |      18 MB |     176 MB |     170 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1275 MB |    2947 MB |    1587 GB |    1586 GB |\n",
            "|       from large pool |    1272 MB |    2946 MB |    1586 GB |    1585 GB |\n",
            "|       from small pool |       3 MB |       4 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  180972    |  180148    |\n",
            "|       from large pool |     440    |     443    |  113282    |  112842    |\n",
            "|       from small pool |     384    |     388    |   67690    |   67306    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  180972    |  180148    |\n",
            "|       from large pool |     440    |     443    |  113282    |  112842    |\n",
            "|       from small pool |     384    |     388    |   67690    |   67306    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      60    |      66    |     533    |     473    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       3    |       9    |      88    |      85    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      38    |      82    |   82104    |   82066    |\n",
            "|       from large pool |      15    |      55    |   56998    |   56983    |\n",
            "|       from small pool |      23    |      29    |   25106    |   25083    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:29:15 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  63% 64/101 [01:05<00:38,  1.04s/it]2021-06-05 09:29:17 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 552.00 MiB (GPU 0; 14.76 GiB total capacity; 12.95 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:29:17 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 15           |        cudaMalloc retries: 15        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12711 MB |   13263 MB |    1462 GB |    1449 GB |\n",
            "|       from large pool |   12708 MB |   13260 MB |    1461 GB |    1448 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12711 MB |   13263 MB |    1462 GB |    1449 GB |\n",
            "|       from large pool |   12708 MB |   13260 MB |    1461 GB |    1448 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13968 MB |   30640 MB |   16674 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |       6 MB |     176 MB |     172 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1254 MB |    2977 MB |    1637 GB |    1635 GB |\n",
            "|       from large pool |    1253 MB |    2975 MB |    1635 GB |    1634 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  186103    |  185279    |\n",
            "|       from large pool |     440    |     443    |  116573    |  116133    |\n",
            "|       from small pool |     384    |     388    |   69530    |   69146    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  186103    |  185279    |\n",
            "|       from large pool |     440    |     443    |  116573    |  116133    |\n",
            "|       from small pool |     384    |     388    |   69530    |   69146    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      60    |     533    |     474    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       3    |      88    |      86    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      72    |      89    |   84361    |   84289    |\n",
            "|       from large pool |      47    |      54    |   58686    |   58639    |\n",
            "|       from small pool |      25    |      38    |   25675    |   25650    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:29:17 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  65% 66/101 [01:08<00:38,  1.09s/it]2021-06-05 09:29:19 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 554.00 MiB (GPU 0; 14.76 GiB total capacity; 12.86 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:29:19 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 16           |        cudaMalloc retries: 16        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12617 MB |   13170 MB |    1506 GB |    1494 GB |\n",
            "|       from large pool |   12614 MB |   13167 MB |    1505 GB |    1492 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12617 MB |   13170 MB |    1506 GB |    1494 GB |\n",
            "|       from large pool |   12614 MB |   13167 MB |    1505 GB |    1492 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13966 MB |   30640 MB |   16674 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |       4 MB |     176 MB |     172 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1348 MB |    2458 MB |    1689 GB |    1688 GB |\n",
            "|       from large pool |    1347 MB |    2456 MB |    1688 GB |    1687 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  191218    |  190394    |\n",
            "|       from large pool |     440    |     443    |  119850    |  119410    |\n",
            "|       from small pool |     384    |     388    |   71368    |   70984    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  191218    |  190394    |\n",
            "|       from large pool |     440    |     443    |  119850    |  119410    |\n",
            "|       from small pool |     384    |     388    |   71368    |   70984    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      59    |     533    |     474    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       2    |      88    |      86    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      79    |     103    |   86686    |   86607    |\n",
            "|       from large pool |      43    |      66    |   60217    |   60174    |\n",
            "|       from small pool |      36    |      41    |   26469    |   26433    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:29:19 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  77% 78/101 [01:22<00:28,  1.23s/it]2021-06-05 09:29:33 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 552.00 MiB (GPU 0; 14.76 GiB total capacity; 12.86 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:29:33 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 17           |        cudaMalloc retries: 17        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12619 MB |   13170 MB |    1798 GB |    1785 GB |\n",
            "|       from large pool |   12616 MB |   13167 MB |    1796 GB |    1784 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12619 MB |   13170 MB |    1798 GB |    1785 GB |\n",
            "|       from large pool |   12616 MB |   13167 MB |    1796 GB |    1784 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13982 MB |   30656 MB |   16690 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      20 MB |     192 MB |     188 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1346 MB |    2368 MB |    2025 GB |    2024 GB |\n",
            "|       from large pool |    1345 MB |    2366 MB |    2023 GB |    2022 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  227581    |  226757    |\n",
            "|       from large pool |     440    |     443    |  142552    |  142112    |\n",
            "|       from small pool |     384    |     388    |   85029    |   84645    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  227581    |  226757    |\n",
            "|       from large pool |     440    |     443    |  142552    |  142112    |\n",
            "|       from small pool |     384    |     388    |   85029    |   84645    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      67    |     541    |     482    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |      10    |      96    |      94    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      68    |      94    |  102862    |  102794    |\n",
            "|       from large pool |      39    |      60    |   71425    |   71386    |\n",
            "|       from small pool |      29    |      35    |   31437    |   31408    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:29:33 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  79% 80/101 [01:24<00:22,  1.09s/it]2021-06-05 09:29:35 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 542.00 MiB (GPU 0; 14.76 GiB total capacity; 12.86 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:29:35 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 18           |        cudaMalloc retries: 18        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12626 MB |   13166 MB |    1838 GB |    1826 GB |\n",
            "|       from large pool |   12623 MB |   13163 MB |    1837 GB |    1825 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12626 MB |   13166 MB |    1838 GB |    1826 GB |\n",
            "|       from large pool |   12623 MB |   13163 MB |    1837 GB |    1825 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13980 MB |   30670 MB |   16704 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      18 MB |     206 MB |     202 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1339 MB |    2464 MB |    2072 GB |    2070 GB |\n",
            "|       from large pool |    1338 MB |    2462 MB |    2070 GB |    2069 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  232728    |  231904    |\n",
            "|       from large pool |     440    |     443    |  145815    |  145375    |\n",
            "|       from small pool |     384    |     388    |   86913    |   86529    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  232728    |  231904    |\n",
            "|       from large pool |     440    |     443    |  145815    |  145375    |\n",
            "|       from small pool |     384    |     388    |   86913    |   86529    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      66    |     548    |     489    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       9    |     103    |     101    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      88    |      93    |  105250    |  105162    |\n",
            "|       from large pool |      60    |      62    |   73024    |   72964    |\n",
            "|       from small pool |      28    |      44    |   32226    |   32198    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:29:35 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  85% 86/101 [01:31<00:19,  1.30s/it]2021-06-05 09:29:43 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 14.76 GiB total capacity; 12.99 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:29:43 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 19           |        cudaMalloc retries: 19        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12739 MB |   13299 MB |    1991 GB |    1978 GB |\n",
            "|       from large pool |   12736 MB |   13296 MB |    1989 GB |    1977 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12739 MB |   13299 MB |    1991 GB |    1978 GB |\n",
            "|       from large pool |   12736 MB |   13296 MB |    1989 GB |    1977 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13966 MB |   30670 MB |   16704 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |       4 MB |     206 MB |     202 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1226 MB |    2730 MB |    2247 GB |    2246 GB |\n",
            "|       from large pool |    1225 MB |    2728 MB |    2246 GB |    2244 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  250359    |  249535    |\n",
            "|       from large pool |     440    |     443    |  156930    |  156490    |\n",
            "|       from small pool |     384    |     388    |   93429    |   93045    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  250359    |  249535    |\n",
            "|       from large pool |     440    |     443    |  156930    |  156490    |\n",
            "|       from small pool |     384    |     388    |   93429    |   93045    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      59    |     548    |     489    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       2    |     103    |     101    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      53    |     104    |  113054    |  113001    |\n",
            "|       from large pool |      33    |      63    |   78306    |   78273    |\n",
            "|       from small pool |      20    |      42    |   34748    |   34728    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:29:43 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  86% 87/101 [01:32<00:15,  1.10s/it]2021-06-05 09:29:43 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 558.00 MiB (GPU 0; 14.76 GiB total capacity; 12.83 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:29:43 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 20           |        cudaMalloc retries: 20        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12576 MB |   13299 MB |    2009 GB |    1996 GB |\n",
            "|       from large pool |   12573 MB |   13296 MB |    2007 GB |    1995 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12576 MB |   13299 MB |    2009 GB |    1996 GB |\n",
            "|       from large pool |   12573 MB |   13296 MB |    2007 GB |    1995 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13966 MB |   30670 MB |   16704 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |       4 MB |     206 MB |     202 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1389 MB |    2730 MB |    2270 GB |    2269 GB |\n",
            "|       from large pool |    1388 MB |    2728 MB |    2268 GB |    2267 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  252357    |  251533    |\n",
            "|       from large pool |     440    |     443    |  158258    |  157818    |\n",
            "|       from small pool |     384    |     388    |   94099    |   93715    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  252357    |  251533    |\n",
            "|       from large pool |     440    |     443    |  158258    |  157818    |\n",
            "|       from small pool |     384    |     388    |   94099    |   93715    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      59    |     548    |     489    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       2    |     103    |     101    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      78    |     104    |  114007    |  113929    |\n",
            "|       from large pool |      50    |      63    |   79011    |   78961    |\n",
            "|       from small pool |      28    |      42    |   34996    |   34968    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:29:43 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  87% 88/101 [01:33<00:13,  1.03s/it]2021-06-05 09:29:44 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 14.76 GiB total capacity; 12.95 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:29:44 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 21           |        cudaMalloc retries: 21        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12700 MB |   13299 MB |    2027 GB |    2014 GB |\n",
            "|       from large pool |   12697 MB |   13296 MB |    2025 GB |    2013 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12700 MB |   13299 MB |    2027 GB |    2014 GB |\n",
            "|       from large pool |   12697 MB |   13296 MB |    2025 GB |    2013 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13966 MB |   30670 MB |   16704 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |       4 MB |     206 MB |     202 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1265 MB |    2730 MB |    2292 GB |    2291 GB |\n",
            "|       from large pool |    1264 MB |    2728 MB |    2291 GB |    2290 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  254355    |  253531    |\n",
            "|       from large pool |     440    |     443    |  159586    |  159146    |\n",
            "|       from small pool |     384    |     388    |   94769    |   94385    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  254355    |  253531    |\n",
            "|       from large pool |     440    |     443    |  159586    |  159146    |\n",
            "|       from small pool |     384    |     388    |   94769    |   94385    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      59    |     548    |     489    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       2    |     103    |     101    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      93    |     104    |  114892    |  114799    |\n",
            "|       from large pool |      55    |      63    |   79660    |   79605    |\n",
            "|       from small pool |      38    |      42    |   35232    |   35194    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:29:44 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  93% 94/101 [01:40<00:08,  1.19s/it]2021-06-05 09:29:51 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 540.00 MiB (GPU 0; 14.76 GiB total capacity; 13.12 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:29:51 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 22           |        cudaMalloc retries: 22        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12894 MB |   13432 MB |    2167 GB |    2155 GB |\n",
            "|       from large pool |   12891 MB |   13429 MB |    2166 GB |    2153 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12894 MB |   13432 MB |    2167 GB |    2155 GB |\n",
            "|       from large pool |   12891 MB |   13429 MB |    2166 GB |    2153 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13974 MB |   30678 MB |   16712 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      12 MB |     214 MB |     210 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1071 MB |    1983 MB |    2456 GB |    2455 GB |\n",
            "|       from large pool |    1070 MB |    1982 MB |    2454 GB |    2453 GB |\n",
            "|       from small pool |       1 MB |       3 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     825    |     830    |  271867    |  271042    |\n",
            "|       from large pool |     440    |     443    |  170536    |  170096    |\n",
            "|       from small pool |     385    |     389    |  101331    |  100946    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     825    |     830    |  271867    |  271042    |\n",
            "|       from large pool |     440    |     443    |  170536    |  170096    |\n",
            "|       from small pool |     385    |     389    |  101331    |  100946    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      63    |     552    |     493    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       6    |     107    |     105    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      94    |     100    |  122784    |  122690    |\n",
            "|       from large pool |      64    |      64    |   85175    |   85111    |\n",
            "|       from small pool |      30    |      42    |   37609    |   37579    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:29:51 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  97% 98/101 [01:45<00:03,  1.22s/it]2021-06-05 09:29:56 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 552.00 MiB (GPU 0; 14.76 GiB total capacity; 12.92 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:29:56 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 23           |        cudaMalloc retries: 23        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12676 MB |   13228 MB |    2260 GB |    2248 GB |\n",
            "|       from large pool |   12673 MB |   13225 MB |    2259 GB |    2246 GB |\n",
            "|       from small pool |       2 MB |      17 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12676 MB |   13228 MB |    2260 GB |    2248 GB |\n",
            "|       from large pool |   12673 MB |   13225 MB |    2259 GB |    2246 GB |\n",
            "|       from small pool |       2 MB |      17 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13982 MB |   30694 MB |   16728 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      20 MB |     230 MB |     226 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1289 MB |    2461 MB |    2566 GB |    2564 GB |\n",
            "|       from large pool |    1288 MB |    2459 MB |    2564 GB |    2563 GB |\n",
            "|       from small pool |       1 MB |       4 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  283197    |  282373    |\n",
            "|       from large pool |     440    |     443    |  177675    |  177235    |\n",
            "|       from small pool |     384    |     388    |  105522    |  105138    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  283197    |  282373    |\n",
            "|       from large pool |     440    |     443    |  177675    |  177235    |\n",
            "|       from small pool |     384    |     388    |  105522    |  105138    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      67    |     560    |     501    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |      10    |     115    |     113    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      46    |      87    |  128102    |  128056    |\n",
            "|       from large pool |      19    |      53    |   88804    |   88785    |\n",
            "|       from small pool |      27    |      35    |   39298    |   39271    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:29:56 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 001:  99% 100/101 [01:46<00:01,  1.06s/it]2021-06-05 09:29:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 1/10 [00:00<00:02,  3.56it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  20% 2/10 [00:00<00:01,  4.05it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 3/10 [00:00<00:01,  4.61it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  40% 4/10 [00:00<00:01,  4.99it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  50% 5/10 [00:00<00:00,  5.23it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  60% 6/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 7/10 [00:01<00:00,  5.29it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 9/10 [00:01<00:00,  6.35it/s]\u001b[A\n",
            "                                                                       \u001b[A2021-06-05 09:30:02.343163: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-05 09:30:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 3.941 | nll_loss 2.219 | ppl 4.66 | wps 15101.4 | wpb 2252.7 | bsz 50 | num_updates 75\n",
            "2021-06-05 09:30:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 75 updates\n",
            "2021-06-05 09:30:07 | INFO | fairseq.trainer | Saving checkpoint to ../dataset/model/checkpoint1.pt\n",
            "tcmalloc: large alloc 1922285568 bytes == 0x56510330a000 @  0x7f6a56815b6b 0x7f6a56835379 0x7f69f509f25e 0x7f69f50a09d2 0x7f6a32967853 0x7f6a321ef043 0x7f6a326f07d7 0x7f6a326bfda0 0x7f6a3251a679 0x7f6a321e1d08 0x7f6a327ee1aa 0x7f6a3295ae62 0x7f6a32932bb2 0x7f6a437bd7de 0x7f6a438e985e 0x5650309eecc0 0x565030adffed 0x565030a62988 0x565030a5d4ae 0x5650309f03ea 0x565030a5e3b5 0x565030a5d7ad 0x5650309f03ea 0x565030a5e3b5 0x565030a5d7ad 0x5650309f03ea 0x565030a5e3b5 0x565030a5d7ad 0x5650309f03ea 0x565030a5e3b5 0x565030a5d7ad\n",
            "tcmalloc: large alloc 1922285568 bytes == 0x5651ea86a000 @  0x7f6a56815b6b 0x7f6a56835379 0x7f69f509f25e 0x7f69f50a09d2 0x7f6a32967853 0x7f6a321ef043 0x7f6a326f07d7 0x7f6a326bfda0 0x7f6a3251a679 0x7f6a321e1d08 0x7f6a327ee1aa 0x7f6a3295ae62 0x7f6a32932bb2 0x7f6a437bd7de 0x7f6a438e985e 0x5650309eecc0 0x565030adffed 0x565030a62988 0x565030a5d4ae 0x5650309f03ea 0x565030a5e3b5 0x565030a5d7ad 0x5650309f03ea 0x565030a5e3b5 0x565030a5d7ad 0x5650309f03ea 0x565030a5e3b5 0x565030a5d7ad 0x5650309f03ea 0x565030a5e3b5 0x565030a5d7ad\n",
            "tcmalloc: large alloc 1922293760 bytes == 0x56525d1a6000 @  0x7f6a568331e7 0x565030a20e68 0x5650309eb637 0x7f6a43cc3937 0x7f6a330c9915 0x7f6a330c5e7a 0x7f6a330ca329 0x7f6a43cc3ebe 0x7f6a43902bd9 0x5650309ef8a8 0x565030a62fd5 0x565030a5d7ad 0x5650309f03ea 0x565030a5e3b5 0x565030a5d4ae 0x5650309f03ea 0x565030a627f0 0x5650309f030a 0x565030a5e3b5 0x565030a5d4ae 0x5650309f03ea 0x565030a5f32a 0x5650309f030a 0x565030a5e60e 0x565030a5d7ad 0x5650309f03ea 0x565030a627f0 0x5650309f030a 0x565030a5e3b5 0x56503092fd14 0x565030a5fbb5\n",
            "2021-06-05 09:32:05 | INFO | fairseq.trainer | Finished saving checkpoint to ../dataset/model/checkpoint1.pt\n",
            "2021-06-05 09:34:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../dataset/model/checkpoint1.pt (epoch 1 @ 75 updates, score 3.941) (writing took 283.5043208610002 seconds)\n",
            "2021-06-05 09:34:50 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2021-06-05 09:34:50 | INFO | train | epoch 001 | loss 3.938 | nll_loss 2.273 | ppl 4.83 | wps 1000.7 | ups 0.19 | wpb 5376.6 | bsz 190.2 | num_updates 75 | lr 6.60625e-07 | gnorm 1.981 | clip 100 | loss_scale 16 | train_wall 91 | gb_free 2.4 | wall 554\n",
            "epoch 002:   0% 0/101 [00:00<?, ?it/s]2021-06-05 09:34:50 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2021-06-05 09:34:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-06-05 09:34:51 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 552.00 MiB (GPU 0; 14.76 GiB total capacity; 12.84 GiB already allocated; 87.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:34:51 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 24           |        cudaMalloc retries: 24        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12594 MB |   13145 MB |    2346 GB |    2334 GB |\n",
            "|       from large pool |   12591 MB |   13142 MB |    2345 GB |    2332 GB |\n",
            "|       from small pool |       2 MB |       4 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12594 MB |   13145 MB |    2346 GB |    2334 GB |\n",
            "|       from large pool |   12591 MB |   13142 MB |    2345 GB |    2332 GB |\n",
            "|       from small pool |       2 MB |       4 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13968 MB |   13982 MB |   30710 MB |   16742 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       6 MB |      20 MB |     246 MB |     240 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1373 MB |    2468 MB |    2658 GB |    2656 GB |\n",
            "|       from large pool |    1370 MB |    2462 MB |    2656 GB |    2655 GB |\n",
            "|       from small pool |       3 MB |       7 MB |       1 GB |       1 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     824    |     829    |  294455    |  293631    |\n",
            "|       from large pool |     440    |     443    |  184908    |  184468    |\n",
            "|       from small pool |     384    |     388    |  109547    |  109163    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     824    |     829    |  294455    |  293631    |\n",
            "|       from large pool |     440    |     443    |  184908    |  184468    |\n",
            "|       from small pool |     384    |     388    |  109547    |  109163    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      60    |      67    |     568    |     508    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       3    |      10    |     123    |     120    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      90    |     103    |  133396    |  133306    |\n",
            "|       from large pool |      42    |      57    |   92608    |   92566    |\n",
            "|       from small pool |      48    |      53    |   40788    |   40740    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:34:51 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  25% 25/101 [00:30<01:41,  1.33s/it]2021-06-05 09:35:22 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 558.00 MiB (GPU 0; 14.76 GiB total capacity; 12.83 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:35:22 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 25           |        cudaMalloc retries: 25        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12579 MB |   13137 MB |    2958 GB |    2945 GB |\n",
            "|       from large pool |   12576 MB |   13134 MB |    2955 GB |    2943 GB |\n",
            "|       from small pool |       2 MB |       8 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12579 MB |   13137 MB |    2958 GB |    2945 GB |\n",
            "|       from large pool |   12576 MB |   13134 MB |    2955 GB |    2943 GB |\n",
            "|       from small pool |       2 MB |       8 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13982 MB |   30724 MB |   16758 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      20 MB |     260 MB |     256 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1386 MB |    2419 MB |    3348 GB |    3347 GB |\n",
            "|       from large pool |    1385 MB |    2417 MB |    3346 GB |    3345 GB |\n",
            "|       from small pool |       1 MB |       4 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  371223    |  370395    |\n",
            "|       from large pool |     440    |     443    |  232765    |  232325    |\n",
            "|       from small pool |     388    |     392    |  138458    |  138070    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  371223    |  370395    |\n",
            "|       from large pool |     440    |     443    |  232765    |  232325    |\n",
            "|       from small pool |     388    |     392    |  138458    |  138070    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      67    |     575    |     516    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |      10    |     130    |     128    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      90    |     100    |  168633    |  168543    |\n",
            "|       from large pool |      46    |      49    |  116205    |  116159    |\n",
            "|       from small pool |      44    |      52    |   52428    |   52384    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:35:22 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  30% 30/101 [00:35<01:22,  1.16s/it, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:35:27 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 554.00 MiB (GPU 0; 14.76 GiB total capacity; 12.98 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:35:27 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 26           |        cudaMalloc retries: 26        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12742 MB |   13295 MB |    3068 GB |    3055 GB |\n",
            "|       from large pool |   12739 MB |   13292 MB |    3065 GB |    3053 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12742 MB |   13295 MB |    3068 GB |    3055 GB |\n",
            "|       from large pool |   12739 MB |   13292 MB |    3065 GB |    3053 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13972 MB |   30730 MB |   16764 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      10 MB |     266 MB |     262 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1223 MB |    2522 MB |    3474 GB |    3472 GB |\n",
            "|       from large pool |    1222 MB |    2520 MB |    3471 GB |    3470 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  385760    |  384932    |\n",
            "|       from large pool |     440    |     443    |  241903    |  241463    |\n",
            "|       from small pool |     388    |     392    |  143857    |  143469    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  385760    |  384932    |\n",
            "|       from large pool |     440    |     443    |  241903    |  241463    |\n",
            "|       from small pool |     388    |     392    |  143857    |  143469    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      62    |     578    |     519    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       5    |     133    |     131    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      88    |      97    |  175276    |  175188    |\n",
            "|       from large pool |      46    |      51    |  120838    |  120792    |\n",
            "|       from small pool |      42    |      47    |   54438    |   54396    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:35:27 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  34% 34/101 [00:39<01:12,  1.08s/it, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:35:31 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 548.00 MiB (GPU 0; 14.76 GiB total capacity; 12.84 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:35:31 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 27           |        cudaMalloc retries: 27        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12597 MB |   13144 MB |    3153 GB |    3141 GB |\n",
            "|       from large pool |   12594 MB |   13141 MB |    3151 GB |    3139 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12597 MB |   13144 MB |    3153 GB |    3141 GB |\n",
            "|       from large pool |   12594 MB |   13141 MB |    3151 GB |    3139 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13980 MB |   30744 MB |   16778 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      18 MB |     280 MB |     276 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1368 MB |    2480 MB |    3572 GB |    3570 GB |\n",
            "|       from large pool |    1367 MB |    2479 MB |    3569 GB |    3568 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  397018    |  396190    |\n",
            "|       from large pool |     440    |     443    |  248934    |  248494    |\n",
            "|       from small pool |     388    |     392    |  148084    |  147696    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  397018    |  396190    |\n",
            "|       from large pool |     440    |     443    |  248934    |  248494    |\n",
            "|       from small pool |     388    |     392    |  148084    |  147696    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      66    |     585    |     526    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       9    |     140    |     138    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      86    |     101    |  180330    |  180244    |\n",
            "|       from large pool |      47    |      58    |  124411    |  124364    |\n",
            "|       from small pool |      39    |      45    |   55919    |   55880    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:35:31 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  44% 44/101 [00:51<01:07,  1.18s/it, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:35:43 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 552.00 MiB (GPU 0; 14.76 GiB total capacity; 12.91 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:35:43 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 28           |        cudaMalloc retries: 28        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12669 MB |   13220 MB |    3391 GB |    3378 GB |\n",
            "|       from large pool |   12666 MB |   13217 MB |    3388 GB |    3376 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12669 MB |   13220 MB |    3391 GB |    3378 GB |\n",
            "|       from large pool |   12666 MB |   13217 MB |    3388 GB |    3376 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13982 MB |   30760 MB |   16794 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      20 MB |     296 MB |     292 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1296 MB |    2001 MB |    3840 GB |    3839 GB |\n",
            "|       from large pool |    1295 MB |    1999 MB |    3837 GB |    3836 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  427082    |  426254    |\n",
            "|       from large pool |     440    |     443    |  267735    |  267295    |\n",
            "|       from small pool |     388    |     392    |  159347    |  158959    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  427082    |  426254    |\n",
            "|       from large pool |     440    |     443    |  267735    |  267295    |\n",
            "|       from small pool |     388    |     392    |  159347    |  158959    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      67    |     593    |     534    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |      10    |     148    |     146    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      74    |     109    |  193817    |  193743    |\n",
            "|       from large pool |      36    |      66    |  134009    |  133973    |\n",
            "|       from small pool |      38    |      44    |   59808    |   59770    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:35:43 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  45% 45/101 [00:52<00:56,  1.01s/it, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:35:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n",
            "epoch 002:  60% 61/101 [01:12<00:51,  1.29s/it, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:36:03 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 552.00 MiB (GPU 0; 14.76 GiB total capacity; 13.12 GiB already allocated; 87.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:36:03 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 29           |        cudaMalloc retries: 29        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12886 MB |   13438 MB |    3817 GB |    3805 GB |\n",
            "|       from large pool |   12883 MB |   13435 MB |    3815 GB |    3802 GB |\n",
            "|       from small pool |       2 MB |       7 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12886 MB |   13438 MB |    3817 GB |    3805 GB |\n",
            "|       from large pool |   12883 MB |   13435 MB |    3815 GB |    3802 GB |\n",
            "|       from small pool |       2 MB |       7 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13968 MB |   13982 MB |   30776 MB |   16808 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       6 MB |      20 MB |     312 MB |     306 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1081 MB |    2874 MB |    4322 GB |    4321 GB |\n",
            "|       from large pool |    1078 MB |    2872 MB |    4319 GB |    4318 GB |\n",
            "|       from small pool |       3 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     829    |     834    |  479050    |  478221    |\n",
            "|       from large pool |     440    |     443    |  300235    |  299795    |\n",
            "|       from small pool |     389    |     393    |  178815    |  178426    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     829    |     834    |  479050    |  478221    |\n",
            "|       from large pool |     440    |     443    |  300235    |  299795    |\n",
            "|       from small pool |     389    |     393    |  178815    |  178426    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      60    |      67    |     601    |     541    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       3    |      10    |     156    |     153    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      97    |      99    |  216937    |  216840    |\n",
            "|       from large pool |      55    |      55    |  149843    |  149788    |\n",
            "|       from small pool |      42    |      48    |   67094    |   67052    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:36:03 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  64% 65/101 [01:16<00:43,  1.20s/it, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:36:08 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 532.00 MiB (GPU 0; 14.76 GiB total capacity; 12.79 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:36:08 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 30           |        cudaMalloc retries: 30        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12568 MB |   13100 MB |    3914 GB |    3902 GB |\n",
            "|       from large pool |   12565 MB |   13097 MB |    3911 GB |    3899 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12568 MB |   13100 MB |    3914 GB |    3902 GB |\n",
            "|       from large pool |   12565 MB |   13097 MB |    3911 GB |    3899 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13974 MB |   30782 MB |   16816 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      12 MB |     318 MB |     314 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1397 MB |    2989 MB |    4434 GB |    4433 GB |\n",
            "|       from large pool |    1396 MB |    2987 MB |    4431 GB |    4430 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  490463    |  489635    |\n",
            "|       from large pool |     440    |     443    |  307424    |  306984    |\n",
            "|       from small pool |     388    |     392    |  183039    |  182651    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  490463    |  489635    |\n",
            "|       from large pool |     440    |     443    |  307424    |  306984    |\n",
            "|       from small pool |     388    |     392    |  183039    |  182651    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      63    |     604    |     545    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       6    |     159    |     157    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      96    |     101    |  222042    |  221946    |\n",
            "|       from large pool |      56    |      58    |  153484    |  153428    |\n",
            "|       from small pool |      40    |      45    |   68558    |   68518    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:36:08 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  68% 69/101 [01:21<00:37,  1.16s/it, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:36:12 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 552.00 MiB (GPU 0; 14.76 GiB total capacity; 12.94 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:36:12 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 31           |        cudaMalloc retries: 31        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12698 MB |   13250 MB |    4006 GB |    3993 GB |\n",
            "|       from large pool |   12695 MB |   13247 MB |    4003 GB |    3991 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12698 MB |   13250 MB |    4006 GB |    3993 GB |\n",
            "|       from large pool |   12695 MB |   13247 MB |    4003 GB |    3991 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13966 MB |   30782 MB |   16816 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |       4 MB |     318 MB |     314 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1267 MB |    2479 MB |    4541 GB |    4539 GB |\n",
            "|       from large pool |    1266 MB |    2477 MB |    4538 GB |    4536 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  501860    |  501032    |\n",
            "|       from large pool |     440    |     443    |  314641    |  314201    |\n",
            "|       from small pool |     388    |     392    |  187219    |  186831    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  501860    |  501032    |\n",
            "|       from large pool |     440    |     443    |  314641    |  314201    |\n",
            "|       from small pool |     388    |     392    |  187219    |  186831    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      59    |     604    |     545    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       2    |     159    |     157    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |     100    |     106    |  227197    |  227097    |\n",
            "|       from large pool |      68    |      68    |  157012    |  156944    |\n",
            "|       from small pool |      32    |      45    |   70185    |   70153    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:36:12 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  72% 73/101 [01:25<00:33,  1.21s/it, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:36:17 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 542.00 MiB (GPU 0; 14.76 GiB total capacity; 12.85 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:36:17 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 32           |        cudaMalloc retries: 32        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12617 MB |   13158 MB |    4102 GB |    4089 GB |\n",
            "|       from large pool |   12615 MB |   13155 MB |    4099 GB |    4087 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12617 MB |   13158 MB |    4102 GB |    4089 GB |\n",
            "|       from large pool |   12615 MB |   13155 MB |    4099 GB |    4087 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13966 MB |   30782 MB |   16816 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |       4 MB |     318 MB |     314 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1348 MB |    2423 MB |    4652 GB |    4650 GB |\n",
            "|       from large pool |    1346 MB |    2421 MB |    4649 GB |    4647 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  513209    |  512381    |\n",
            "|       from large pool |     440    |     443    |  321816    |  321376    |\n",
            "|       from small pool |     388    |     392    |  191393    |  191005    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  513209    |  512381    |\n",
            "|       from large pool |     440    |     443    |  321816    |  321376    |\n",
            "|       from small pool |     388    |     392    |  191393    |  191005    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      59    |     604    |     545    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       2    |     159    |     157    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      96    |     101    |  232134    |  232038    |\n",
            "|       from large pool |      58    |      60    |  160365    |  160307    |\n",
            "|       from small pool |      38    |      42    |   71769    |   71731    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:36:17 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  80% 81/101 [01:34<00:24,  1.22s/it, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:36:26 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 548.00 MiB (GPU 0; 14.76 GiB total capacity; 12.89 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:36:26 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 33           |        cudaMalloc retries: 33        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12648 MB |   13195 MB |    4292 GB |    4280 GB |\n",
            "|       from large pool |   12645 MB |   13192 MB |    4289 GB |    4277 GB |\n",
            "|       from small pool |       2 MB |       8 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12648 MB |   13195 MB |    4292 GB |    4280 GB |\n",
            "|       from large pool |   12645 MB |   13192 MB |    4289 GB |    4277 GB |\n",
            "|       from small pool |       2 MB |       8 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13980 MB |   30796 MB |   16830 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      18 MB |     332 MB |     328 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1317 MB |    2512 MB |    4868 GB |    4867 GB |\n",
            "|       from large pool |    1316 MB |    2510 MB |    4865 GB |    4863 GB |\n",
            "|       from small pool |       1 MB |       3 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  537026    |  536198    |\n",
            "|       from large pool |     440    |     443    |  336648    |  336208    |\n",
            "|       from small pool |     388    |     392    |  200378    |  199990    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  537026    |  536198    |\n",
            "|       from large pool |     440    |     443    |  336648    |  336208    |\n",
            "|       from small pool |     388    |     392    |  200378    |  199990    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      66    |     611    |     552    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       9    |     166    |     164    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      95    |      99    |  242744    |  242649    |\n",
            "|       from large pool |      57    |      60    |  167858    |  167801    |\n",
            "|       from small pool |      38    |      45    |   74886    |   74848    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:36:26 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  81% 82/101 [01:35<00:19,  1.04s/it, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:36:26 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 14.76 GiB total capacity; 12.98 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:36:26 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 34           |        cudaMalloc retries: 34        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12734 MB |   13294 MB |    4307 GB |    4295 GB |\n",
            "|       from large pool |   12731 MB |   13292 MB |    4305 GB |    4292 GB |\n",
            "|       from small pool |       2 MB |       8 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12734 MB |   13294 MB |    4307 GB |    4295 GB |\n",
            "|       from large pool |   12731 MB |   13292 MB |    4305 GB |    4292 GB |\n",
            "|       from small pool |       2 MB |       8 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13980 MB |   30796 MB |   16830 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      18 MB |     332 MB |     328 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1231 MB |    2512 MB |    4887 GB |    4886 GB |\n",
            "|       from large pool |    1230 MB |    2510 MB |    4884 GB |    4882 GB |\n",
            "|       from small pool |       1 MB |       3 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  539040    |  538212    |\n",
            "|       from large pool |     440    |     443    |  337990    |  337550    |\n",
            "|       from small pool |     388    |     392    |  201050    |  200662    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  539040    |  538212    |\n",
            "|       from large pool |     440    |     443    |  337990    |  337550    |\n",
            "|       from small pool |     388    |     392    |  201050    |  200662    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      66    |     611    |     552    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       9    |     166    |     164    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      64    |      99    |  243698    |  243634    |\n",
            "|       from large pool |      27    |      60    |  168573    |  168546    |\n",
            "|       from small pool |      37    |      45    |   75125    |   75088    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:36:26 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  82% 83/101 [01:36<00:15,  1.13it/s, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:36:27 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 554.00 MiB (GPU 0; 14.76 GiB total capacity; 12.87 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:36:27 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 35           |        cudaMalloc retries: 35        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12621 MB |   13294 MB |    4325 GB |    4313 GB |\n",
            "|       from large pool |   12618 MB |   13292 MB |    4322 GB |    4310 GB |\n",
            "|       from small pool |       2 MB |       8 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12621 MB |   13294 MB |    4325 GB |    4313 GB |\n",
            "|       from large pool |   12618 MB |   13292 MB |    4322 GB |    4310 GB |\n",
            "|       from small pool |       2 MB |       8 MB |       2 GB |       2 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13980 MB |   30796 MB |   16830 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      18 MB |     332 MB |     328 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1344 MB |    2512 MB |    4910 GB |    4909 GB |\n",
            "|       from large pool |    1343 MB |    2510 MB |    4907 GB |    4906 GB |\n",
            "|       from small pool |       1 MB |       3 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  541038    |  540210    |\n",
            "|       from large pool |     440    |     443    |  339318    |  338878    |\n",
            "|       from small pool |     388    |     392    |  201720    |  201332    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  541038    |  540210    |\n",
            "|       from large pool |     440    |     443    |  339318    |  338878    |\n",
            "|       from small pool |     388    |     392    |  201720    |  201332    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      66    |     611    |     552    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       9    |     166    |     164    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      77    |      99    |  244665    |  244588    |\n",
            "|       from large pool |      45    |      60    |  169291    |  169246    |\n",
            "|       from small pool |      32    |      45    |   75374    |   75342    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:36:27 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  84% 85/101 [01:37<00:14,  1.10it/s, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:36:29 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 14.76 GiB total capacity; 12.86 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:36:29 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 36           |        cudaMalloc retries: 36        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12613 MB |   13173 MB |    4360 GB |    4348 GB |\n",
            "|       from large pool |   12610 MB |   13170 MB |    4357 GB |    4345 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12613 MB |   13173 MB |    4360 GB |    4348 GB |\n",
            "|       from large pool |   12610 MB |   13170 MB |    4357 GB |    4345 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   14026 MB |   30856 MB |   16890 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      64 MB |     392 MB |     388 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1352 MB |    2938 MB |    4951 GB |    4950 GB |\n",
            "|       from large pool |    1351 MB |    2937 MB |    4948 GB |    4947 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  546007    |  545179    |\n",
            "|       from large pool |     440    |     443    |  342162    |  341722    |\n",
            "|       from small pool |     388    |     392    |  203845    |  203457    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  546007    |  545179    |\n",
            "|       from large pool |     440    |     443    |  342162    |  341722    |\n",
            "|       from small pool |     388    |     392    |  203845    |  203457    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      89    |     641    |     582    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |      32    |     196    |     194    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      98    |     103    |  246996    |  246898    |\n",
            "|       from large pool |      54    |      55    |  170684    |  170630    |\n",
            "|       from small pool |      44    |      49    |   76312    |   76268    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:36:29 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  95% 96/101 [01:50<00:06,  1.23s/it, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:36:42 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 14.76 GiB total capacity; 12.95 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:36:42 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 37           |        cudaMalloc retries: 37        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12703 MB |   13263 MB |    4626 GB |    4614 GB |\n",
            "|       from large pool |   12700 MB |   13260 MB |    4623 GB |    4611 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12703 MB |   13263 MB |    4626 GB |    4614 GB |\n",
            "|       from large pool |   12700 MB |   13260 MB |    4623 GB |    4611 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13982 MB |   30872 MB |   16906 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      20 MB |     408 MB |     404 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1262 MB |    2502 MB |    5256 GB |    5255 GB |\n",
            "|       from large pool |    1261 MB |    2500 MB |    5252 GB |    5251 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  579268    |  578440    |\n",
            "|       from large pool |     440    |     443    |  362879    |  362439    |\n",
            "|       from small pool |     388    |     392    |  216389    |  216001    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  579268    |  578440    |\n",
            "|       from large pool |     440    |     443    |  362879    |  362439    |\n",
            "|       from small pool |     388    |     392    |  216389    |  216001    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      67    |     649    |     590    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |      10    |     204    |     202    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      94    |     109    |  262019    |  261925    |\n",
            "|       from large pool |      56    |      63    |  180791    |  180735    |\n",
            "|       from small pool |      38    |      46    |   81228    |   81190    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:36:42 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 002:  99% 100/101 [01:54<00:01,  1.13s/it, loss=3.926, nll_loss=2.26, ppl=4.79, wps=1252.3, ups=0.23, wpb=5435.5, bsz=194.2, num_updates=100, lr=8.475e-07, gnorm=1.936, clip=100, loss_scale=16, train_wall=122, gb_free=1.8, wall=587]2021-06-05 09:36:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  10% 1/10 [00:00<00:02,  3.93it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  20% 2/10 [00:00<00:01,  4.36it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  30% 3/10 [00:00<00:01,  4.86it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  40% 4/10 [00:00<00:01,  5.17it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  50% 5/10 [00:00<00:00,  5.31it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  60% 6/10 [00:01<00:00,  5.03it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  70% 7/10 [00:01<00:00,  5.30it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  90% 9/10 [00:01<00:00,  6.35it/s]\u001b[A\n",
            "                                                                       \u001b[A2021-06-05 09:36:48 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 3.882 | nll_loss 2.153 | ppl 4.45 | wps 14804.2 | wpb 2252.7 | bsz 50 | num_updates 161 | best_loss 3.882\n",
            "2021-06-05 09:36:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 161 updates\n",
            "2021-06-05 09:36:48 | INFO | fairseq.trainer | Saving checkpoint to ../dataset/model/checkpoint2.pt\n",
            "2021-06-05 09:38:45 | INFO | fairseq.trainer | Finished saving checkpoint to ../dataset/model/checkpoint2.pt\n",
            "2021-06-05 09:41:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../dataset/model/checkpoint2.pt (epoch 2 @ 161 updates, score 3.882) (writing took 282.18224599600035 seconds)\n",
            "2021-06-05 09:41:30 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2021-06-05 09:41:30 | INFO | train | epoch 002 | loss 3.864 | nll_loss 2.19 | ppl 4.56 | wps 1197 | ups 0.22 | wpb 5557.5 | bsz 201.9 | num_updates 161 | lr 1.30348e-06 | gnorm 1.725 | clip 100 | loss_scale 8 | train_wall 105 | gb_free 3.3 | wall 954\n",
            "epoch 003:   0% 0/101 [00:00<?, ?it/s]2021-06-05 09:41:30 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2021-06-05 09:41:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 003:   2% 2/101 [00:02<02:13,  1.35s/it]2021-06-05 09:41:33 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 14.76 GiB total capacity; 12.99 GiB already allocated; 85.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:41:33 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 38           |        cudaMalloc retries: 38        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12745 MB |   13305 MB |    4806 GB |    4794 GB |\n",
            "|       from large pool |   12742 MB |   13302 MB |    4803 GB |    4791 GB |\n",
            "|       from small pool |       2 MB |      12 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12745 MB |   13305 MB |    4806 GB |    4794 GB |\n",
            "|       from large pool |   12742 MB |   13302 MB |    4803 GB |    4791 GB |\n",
            "|       from small pool |       2 MB |      12 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13970 MB |   13984 MB |   30890 MB |   16920 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       8 MB |      22 MB |     426 MB |     418 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1224 MB |    2991 MB |    5460 GB |    5458 GB |\n",
            "|       from large pool |    1219 MB |    2987 MB |    5456 GB |    5454 GB |\n",
            "|       from small pool |       5 MB |       5 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  603045    |  602217    |\n",
            "|       from large pool |     440    |     443    |  377778    |  377338    |\n",
            "|       from small pool |     388    |     392    |  225267    |  224879    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  603045    |  602217    |\n",
            "|       from large pool |     440    |     443    |  377778    |  377338    |\n",
            "|       from small pool |     388    |     392    |  225267    |  224879    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      61    |      68    |     658    |     597    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       4    |      11    |     213    |     209    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      65    |      89    |  272661    |  272596    |\n",
            "|       from large pool |      42    |      52    |  188146    |  188104    |\n",
            "|       from small pool |      23    |      37    |   84515    |   84492    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:41:33 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  15% 15/101 [00:17<01:49,  1.28s/it]2021-06-05 09:41:48 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 556.00 MiB (GPU 0; 14.76 GiB total capacity; 12.95 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:41:48 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 39           |        cudaMalloc retries: 39        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12702 MB |   13257 MB |    5124 GB |    5111 GB |\n",
            "|       from large pool |   12699 MB |   13254 MB |    5120 GB |    5107 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12702 MB |   13257 MB |    5124 GB |    5111 GB |\n",
            "|       from large pool |   12699 MB |   13254 MB |    5120 GB |    5107 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       3 GB |       3 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   14026 MB |   30946 MB |   16980 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      64 MB |     482 MB |     478 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1263 MB |    2731 MB |    5815 GB |    5814 GB |\n",
            "|       from large pool |    1262 MB |    2729 MB |    5811 GB |    5810 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  642394    |  641566    |\n",
            "|       from large pool |     440    |     443    |  402038    |  401598    |\n",
            "|       from small pool |     388    |     392    |  240356    |  239968    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  642394    |  641566    |\n",
            "|       from large pool |     440    |     443    |  402038    |  401598    |\n",
            "|       from small pool |     388    |     392    |  240356    |  239968    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      89    |     686    |     627    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |      32    |     241    |     239    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      66    |     106    |  290988    |  290922    |\n",
            "|       from large pool |      26    |      62    |  200259    |  200233    |\n",
            "|       from small pool |      40    |      45    |   90729    |   90689    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:41:48 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  35% 35/101 [00:41<01:23,  1.27s/it]2021-06-05 09:42:12 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 530.00 MiB (GPU 0; 14.76 GiB total capacity; 12.74 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:42:12 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 40           |        cudaMalloc retries: 40        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12520 MB |   13050 MB |    5596 GB |    5583 GB |\n",
            "|       from large pool |   12518 MB |   13047 MB |    5591 GB |    5579 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12520 MB |   13050 MB |    5596 GB |    5583 GB |\n",
            "|       from large pool |   12518 MB |   13047 MB |    5591 GB |    5579 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13982 MB |   30962 MB |   16996 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      20 MB |     498 MB |     494 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1445 MB |    3095 MB |    6352 GB |    6351 GB |\n",
            "|       from large pool |    1443 MB |    3093 MB |    6347 GB |    6346 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     829    |     834    |  703605    |  702776    |\n",
            "|       from large pool |     440    |     443    |  440121    |  439681    |\n",
            "|       from small pool |     389    |     393    |  263484    |  263095    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     829    |     834    |  703605    |  702776    |\n",
            "|       from large pool |     440    |     443    |  440121    |  439681    |\n",
            "|       from small pool |     389    |     393    |  263484    |  263095    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      67    |     694    |     635    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |      10    |     249    |     247    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      99    |     102    |  319083    |  318984    |\n",
            "|       from large pool |      56    |      65    |  219665    |  219609    |\n",
            "|       from small pool |      43    |      50    |   99418    |   99375    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:42:12 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  40% 40/101 [00:47<01:15,  1.23s/it]2021-06-05 09:42:18 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 548.00 MiB (GPU 0; 14.76 GiB total capacity; 12.84 GiB already allocated; 79.75 MiB free; 13.65 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:42:18 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 41           |        cudaMalloc retries: 41        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12602 MB |   13149 MB |    5714 GB |    5702 GB |\n",
            "|       from large pool |   12599 MB |   13146 MB |    5710 GB |    5697 GB |\n",
            "|       from small pool |       2 MB |      17 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12602 MB |   13149 MB |    5714 GB |    5702 GB |\n",
            "|       from large pool |   12599 MB |   13146 MB |    5710 GB |    5697 GB |\n",
            "|       from small pool |       2 MB |      17 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13976 MB |   13980 MB |   30976 MB |   17000 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |      14 MB |      18 MB |     512 MB |     498 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1373 MB |    2975 MB |    6489 GB |    6487 GB |\n",
            "|       from large pool |    1362 MB |    2973 MB |    6484 GB |    6482 GB |\n",
            "|       from small pool |      11 MB |      11 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |  718087    |  717259    |\n",
            "|       from large pool |     440    |     443    |  449229    |  448789    |\n",
            "|       from small pool |     388    |     392    |  268858    |  268470    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |  718087    |  717259    |\n",
            "|       from large pool |     440    |     443    |  449229    |  448789    |\n",
            "|       from small pool |     388    |     392    |  268858    |  268470    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      64    |      66    |     701    |     637    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       7    |       9    |     256    |     249    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      96    |     117    |  325354    |  325258    |\n",
            "|       from large pool |      42    |      61    |  224133    |  224091    |\n",
            "|       from small pool |      54    |      58    |  101221    |  101167    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:42:18 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  51% 52/101 [01:01<01:00,  1.23s/it, loss=3.843, nll_loss=2.166, ppl=4.49, wps=1321.6, ups=0.24, wpb=5517.4, bsz=198.1, num_updates=200, lr=1.595e-06, gnorm=1.617, clip=100, loss_scale=8, train_wall=122, gb_free=1.5, wall=1004]2021-06-05 09:42:32 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 14.76 GiB total capacity; 12.86 GiB already allocated; 87.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:42:32 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 42           |        cudaMalloc retries: 42        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12612 MB |   13172 MB |    6009 GB |    5997 GB |\n",
            "|       from large pool |   12609 MB |   13169 MB |    6005 GB |    5992 GB |\n",
            "|       from small pool |       2 MB |      15 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12612 MB |   13172 MB |    6009 GB |    5997 GB |\n",
            "|       from large pool |   12609 MB |   13169 MB |    6005 GB |    5992 GB |\n",
            "|       from small pool |       2 MB |      15 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13968 MB |   13982 MB |   30988 MB |   17020 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       6 MB |      20 MB |     524 MB |     518 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1355 MB |    2434 MB |    6822 GB |    6820 GB |\n",
            "|       from large pool |    1352 MB |    2432 MB |    6817 GB |    6815 GB |\n",
            "|       from small pool |       3 MB |       5 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |     754 K  |     753 K  |\n",
            "|       from large pool |     440    |     443    |     471 K  |     471 K  |\n",
            "|       from small pool |     388    |     392    |     282 K  |     282 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |     754 K  |     753 K  |\n",
            "|       from large pool |     440    |     443    |     471 K  |     471 K  |\n",
            "|       from small pool |     388    |     392    |     282 K  |     282 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      60    |      67    |     707    |     647    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       3    |      10    |     262    |     259    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      73    |     101    |  341789    |  341716    |\n",
            "|       from large pool |      48    |      57    |  235499    |  235451    |\n",
            "|       from small pool |      25    |      44    |  106290    |  106265    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:42:32 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  55% 56/101 [01:05<00:52,  1.16s/it, loss=3.843, nll_loss=2.166, ppl=4.49, wps=1321.6, ups=0.24, wpb=5517.4, bsz=198.1, num_updates=200, lr=1.595e-06, gnorm=1.617, clip=100, loss_scale=8, train_wall=122, gb_free=1.5, wall=1004]2021-06-05 09:42:36 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 554.00 MiB (GPU 0; 14.76 GiB total capacity; 12.92 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:42:36 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 43           |        cudaMalloc retries: 43        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12677 MB |   13230 MB |    6101 GB |    6089 GB |\n",
            "|       from large pool |   12674 MB |   13227 MB |    6097 GB |    6084 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12677 MB |   13230 MB |    6101 GB |    6089 GB |\n",
            "|       from large pool |   12674 MB |   13227 MB |    6097 GB |    6084 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13972 MB |   30992 MB |   17026 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      10 MB |     528 MB |     524 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1288 MB |    2608 MB |    6926 GB |    6925 GB |\n",
            "|       from large pool |    1287 MB |    2606 MB |    6921 GB |    6920 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |     765 K  |     764 K  |\n",
            "|       from large pool |     440    |     443    |     479 K  |     478 K  |\n",
            "|       from small pool |     388    |     392    |     286 K  |     286 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |     765 K  |     764 K  |\n",
            "|       from large pool |     440    |     443    |     479 K  |     478 K  |\n",
            "|       from small pool |     388    |     392    |     286 K  |     286 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      62    |     709    |     650    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       5    |     264    |     262    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      84    |     100    |  346916    |  346832    |\n",
            "|       from large pool |      42    |      59    |  239017    |  238975    |\n",
            "|       from small pool |      42    |      47    |  107899    |  107857    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:42:36 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  60% 61/101 [01:11<00:47,  1.18s/it, loss=3.843, nll_loss=2.166, ppl=4.49, wps=1321.6, ups=0.24, wpb=5517.4, bsz=198.1, num_updates=200, lr=1.595e-06, gnorm=1.617, clip=100, loss_scale=8, train_wall=122, gb_free=1.5, wall=1004]2021-06-05 09:42:42 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 554.00 MiB (GPU 0; 14.76 GiB total capacity; 12.87 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:42:42 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 44           |        cudaMalloc retries: 44        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12620 MB |   13174 MB |    6221 GB |    6208 GB |\n",
            "|       from large pool |   12617 MB |   13171 MB |    6216 GB |    6204 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12620 MB |   13174 MB |    6221 GB |    6208 GB |\n",
            "|       from large pool |   12617 MB |   13171 MB |    6216 GB |    6204 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13974 MB |   31000 MB |   17034 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      12 MB |     536 MB |     532 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1345 MB |    3171 MB |    7062 GB |    7061 GB |\n",
            "|       from large pool |    1344 MB |    3169 MB |    7057 GB |    7055 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |     780 K  |     779 K  |\n",
            "|       from large pool |     440    |     443    |     488 K  |     487 K  |\n",
            "|       from small pool |     388    |     392    |     292 K  |     291 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |     780 K  |     779 K  |\n",
            "|       from large pool |     440    |     443    |     488 K  |     487 K  |\n",
            "|       from small pool |     388    |     392    |     292 K  |     291 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      63    |     713    |     654    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       6    |     268    |     266    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      83    |      93    |  353491    |  353408    |\n",
            "|       from large pool |      51    |      58    |  243398    |  243347    |\n",
            "|       from small pool |      32    |      46    |  110093    |  110061    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:42:42 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  66% 67/101 [01:17<00:37,  1.10s/it, loss=3.843, nll_loss=2.166, ppl=4.49, wps=1321.6, ups=0.24, wpb=5517.4, bsz=198.1, num_updates=200, lr=1.595e-06, gnorm=1.617, clip=100, loss_scale=8, train_wall=122, gb_free=1.5, wall=1004]2021-06-05 09:42:48 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 552.00 MiB (GPU 0; 14.76 GiB total capacity; 12.94 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:42:48 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 45           |        cudaMalloc retries: 45        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12699 MB |   13250 MB |    6357 GB |    6344 GB |\n",
            "|       from large pool |   12696 MB |   13247 MB |    6352 GB |    6340 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12699 MB |   13250 MB |    6357 GB |    6344 GB |\n",
            "|       from large pool |   12696 MB |   13247 MB |    6352 GB |    6340 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13980 MB |   31014 MB |   17048 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      18 MB |     550 MB |     546 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1266 MB |    2938 MB |    7218 GB |    7217 GB |\n",
            "|       from large pool |    1265 MB |    2937 MB |    7212 GB |    7211 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |     797 K  |     796 K  |\n",
            "|       from large pool |     440    |     443    |     499 K  |     498 K  |\n",
            "|       from small pool |     388    |     392    |     298 K  |     298 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |     797 K  |     796 K  |\n",
            "|       from large pool |     440    |     443    |     499 K  |     498 K  |\n",
            "|       from small pool |     388    |     392    |     298 K  |     298 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      66    |     720    |     661    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       9    |     275    |     273    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      95    |      96    |  361181    |  361086    |\n",
            "|       from large pool |      63    |      63    |  248812    |  248749    |\n",
            "|       from small pool |      32    |      42    |  112369    |  112337    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:42:48 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  69% 70/101 [01:20<00:31,  1.03s/it, loss=3.843, nll_loss=2.166, ppl=4.49, wps=1321.6, ups=0.24, wpb=5517.4, bsz=198.1, num_updates=200, lr=1.595e-06, gnorm=1.617, clip=100, loss_scale=8, train_wall=122, gb_free=1.5, wall=1004]2021-06-05 09:42:51 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 14.76 GiB total capacity; 12.95 GiB already allocated; 83.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:42:51 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 46           |        cudaMalloc retries: 46        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12700 MB |   13260 MB |    6420 GB |    6408 GB |\n",
            "|       from large pool |   12697 MB |   13257 MB |    6416 GB |    6403 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12700 MB |   13260 MB |    6420 GB |    6408 GB |\n",
            "|       from large pool |   12697 MB |   13257 MB |    6416 GB |    6403 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13972 MB |   13982 MB |   31030 MB |   17058 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |      10 MB |      20 MB |     566 MB |     556 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1271 MB |    2481 MB |    7292 GB |    7291 GB |\n",
            "|       from large pool |    1264 MB |    2473 MB |    7287 GB |    7286 GB |\n",
            "|       from small pool |       7 MB |       8 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |     805 K  |     805 K  |\n",
            "|       from large pool |     440    |     443    |     504 K  |     503 K  |\n",
            "|       from small pool |     388    |     392    |     301 K  |     301 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |     805 K  |     805 K  |\n",
            "|       from large pool |     440    |     443    |     504 K  |     503 K  |\n",
            "|       from small pool |     388    |     392    |     301 K  |     301 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      62    |      67    |     728    |     666    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       5    |      10    |     283    |     278    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      97    |     104    |  365125    |  365028    |\n",
            "|       from large pool |      55    |      57    |  251455    |  251400    |\n",
            "|       from small pool |      42    |      48    |  113670    |  113628    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:42:51 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  71% 72/101 [01:22<00:30,  1.06s/it, loss=3.843, nll_loss=2.166, ppl=4.49, wps=1321.6, ups=0.24, wpb=5517.4, bsz=198.1, num_updates=200, lr=1.595e-06, gnorm=1.617, clip=100, loss_scale=8, train_wall=122, gb_free=1.5, wall=1004]2021-06-05 09:42:53 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 542.00 MiB (GPU 0; 14.76 GiB total capacity; 12.85 GiB already allocated; 87.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:42:53 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 47           |        cudaMalloc retries: 47        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12613 MB |   13154 MB |    6464 GB |    6452 GB |\n",
            "|       from large pool |   12610 MB |   13151 MB |    6459 GB |    6447 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12613 MB |   13154 MB |    6464 GB |    6452 GB |\n",
            "|       from large pool |   12610 MB |   13151 MB |    6459 GB |    6447 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13968 MB |   13972 MB |   31030 MB |   17062 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       6 MB |      10 MB |     566 MB |     560 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1354 MB |    2499 MB |    7344 GB |    7343 GB |\n",
            "|       from large pool |    1351 MB |    2495 MB |    7339 GB |    7338 GB |\n",
            "|       from small pool |       3 MB |       7 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |     811 K  |     810 K  |\n",
            "|       from large pool |     440    |     443    |     507 K  |     507 K  |\n",
            "|       from small pool |     388    |     392    |     303 K  |     303 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |     811 K  |     810 K  |\n",
            "|       from large pool |     440    |     443    |     507 K  |     507 K  |\n",
            "|       from small pool |     388    |     392    |     303 K  |     303 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      60    |      62    |     728    |     668    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       3    |       5    |     283    |     280    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      98    |     102    |  367356    |  367258    |\n",
            "|       from large pool |      65    |      65    |  253123    |  253058    |\n",
            "|       from small pool |      33    |      48    |  114233    |  114200    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:42:53 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  75% 76/101 [01:27<00:30,  1.20s/it, loss=3.843, nll_loss=2.166, ppl=4.49, wps=1321.6, ups=0.24, wpb=5517.4, bsz=198.1, num_updates=200, lr=1.595e-06, gnorm=1.617, clip=100, loss_scale=8, train_wall=122, gb_free=1.5, wall=1004]2021-06-05 09:42:58 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 554.00 MiB (GPU 0; 14.76 GiB total capacity; 12.98 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:42:58 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 48           |        cudaMalloc retries: 48        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12734 MB |   13287 MB |    6559 GB |    6547 GB |\n",
            "|       from large pool |   12731 MB |   13284 MB |    6555 GB |    6542 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12734 MB |   13287 MB |    6559 GB |    6547 GB |\n",
            "|       from large pool |   12731 MB |   13284 MB |    6555 GB |    6542 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13968 MB |   31030 MB |   17064 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |       6 MB |     566 MB |     562 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1231 MB |    2730 MB |    7455 GB |    7454 GB |\n",
            "|       from large pool |    1230 MB |    2728 MB |    7450 GB |    7449 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |     822 K  |     821 K  |\n",
            "|       from large pool |     440    |     443    |     514 K  |     514 K  |\n",
            "|       from small pool |     388    |     392    |     307 K  |     307 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |     822 K  |     821 K  |\n",
            "|       from large pool |     440    |     443    |     514 K  |     514 K  |\n",
            "|       from small pool |     388    |     392    |     307 K  |     307 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      60    |     728    |     669    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       3    |     283    |     281    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      93    |      98    |  372365    |  372272    |\n",
            "|       from large pool |      52    |      55    |  256716    |  256664    |\n",
            "|       from small pool |      41    |      47    |  115649    |  115608    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:42:58 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  92% 93/101 [01:47<00:10,  1.28s/it, loss=3.843, nll_loss=2.166, ppl=4.49, wps=1321.6, ups=0.24, wpb=5517.4, bsz=198.1, num_updates=200, lr=1.595e-06, gnorm=1.617, clip=100, loss_scale=8, train_wall=122, gb_free=1.5, wall=1004]2021-06-05 09:43:18 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 548.00 MiB (GPU 0; 14.76 GiB total capacity; 12.92 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:43:18 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 49           |        cudaMalloc retries: 49        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12681 MB |   13228 MB |    6975 GB |    6963 GB |\n",
            "|       from large pool |   12679 MB |   13226 MB |    6970 GB |    6958 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12681 MB |   13228 MB |    6975 GB |    6963 GB |\n",
            "|       from large pool |   12679 MB |   13226 MB |    6970 GB |    6958 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13982 MB |   31046 MB |   17080 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |      20 MB |     582 MB |     578 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1284 MB |    3032 MB |    7926 GB |    7925 GB |\n",
            "|       from large pool |    1282 MB |    3030 MB |    7920 GB |    7919 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |     874 K  |     873 K  |\n",
            "|       from large pool |     440    |     443    |     547 K  |     546 K  |\n",
            "|       from small pool |     388    |     392    |     327 K  |     326 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |     874 K  |     873 K  |\n",
            "|       from large pool |     440    |     443    |     547 K  |     546 K  |\n",
            "|       from small pool |     388    |     392    |     327 K  |     326 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      67    |     736    |     677    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |      10    |     291    |     289    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      86    |     106    |  395473    |  395387    |\n",
            "|       from large pool |      41    |      57    |  272827    |  272786    |\n",
            "|       from small pool |      45    |      52    |  122646    |  122601    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:43:18 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  95% 96/101 [01:50<00:06,  1.23s/it, loss=3.843, nll_loss=2.166, ppl=4.49, wps=1321.6, ups=0.24, wpb=5517.4, bsz=198.1, num_updates=200, lr=1.595e-06, gnorm=1.617, clip=100, loss_scale=8, train_wall=122, gb_free=1.5, wall=1004]2021-06-05 09:43:21 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 542.00 MiB (GPU 0; 14.76 GiB total capacity; 12.86 GiB already allocated; 89.75 MiB free; 13.64 GiB reserved in total by PyTorch)\n",
            "2021-06-05 09:43:21 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 50           |        cudaMalloc retries: 50        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   12626 MB |   13166 MB |    7045 GB |    7033 GB |\n",
            "|       from large pool |   12623 MB |   13163 MB |    7040 GB |    7028 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   12626 MB |   13166 MB |    7045 GB |    7033 GB |\n",
            "|       from large pool |   12623 MB |   13163 MB |    7040 GB |    7028 GB |\n",
            "|       from small pool |       2 MB |       3 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   13966 MB |   13966 MB |   31046 MB |   17080 MB |\n",
            "|       from large pool |   13962 MB |   13962 MB |   30464 MB |   16502 MB |\n",
            "|       from small pool |       4 MB |       4 MB |     582 MB |     578 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    1339 MB |    2981 MB |    8009 GB |    8008 GB |\n",
            "|       from large pool |    1338 MB |    2979 MB |    8003 GB |    8002 GB |\n",
            "|       from small pool |       1 MB |       2 MB |       5 GB |       5 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     828    |     833    |     882 K  |     881 K  |\n",
            "|       from large pool |     440    |     443    |     552 K  |     552 K  |\n",
            "|       from small pool |     388    |     392    |     330 K  |     329 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     828    |     833    |     882 K  |     881 K  |\n",
            "|       from large pool |     440    |     443    |     552 K  |     552 K  |\n",
            "|       from small pool |     388    |     392    |     330 K  |     329 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      59    |      59    |     736    |     677    |\n",
            "|       from large pool |      57    |      57    |     445    |     388    |\n",
            "|       from small pool |       2    |       2    |     291    |     289    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      82    |      91    |  398963    |  398881    |\n",
            "|       from large pool |      46    |      54    |  275350    |  275304    |\n",
            "|       from small pool |      36    |      44    |  123613    |  123577    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-06-05 09:43:21 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "epoch 003:  99% 100/101 [01:55<00:01,  1.18s/it, loss=3.843, nll_loss=2.166, ppl=4.49, wps=1321.6, ups=0.24, wpb=5517.4, bsz=198.1, num_updates=200, lr=1.595e-06, gnorm=1.617, clip=100, loss_scale=8, train_wall=122, gb_free=1.5, wall=1004]2021-06-05 09:43:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  10% 1/10 [00:00<00:02,  3.95it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  20% 2/10 [00:00<00:01,  4.35it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  30% 3/10 [00:00<00:01,  4.83it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  40% 4/10 [00:00<00:01,  5.12it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  50% 5/10 [00:00<00:00,  5.14it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  60% 6/10 [00:01<00:00,  4.94it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  70% 7/10 [00:01<00:00,  5.26it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  90% 9/10 [00:01<00:00,  6.32it/s]\u001b[A\n",
            "                                                                       \u001b[A2021-06-05 09:43:27 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 3.83 | nll_loss 2.098 | ppl 4.28 | wps 14628.8 | wpb 2252.7 | bsz 50 | num_updates 249 | best_loss 3.83\n",
            "2021-06-05 09:43:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 249 updates\n",
            "2021-06-05 09:43:27 | INFO | fairseq.trainer | Saving checkpoint to ../dataset/model/checkpoint3.pt\n",
            "2021-06-05 09:45:46 | INFO | fairseq.trainer | Finished saving checkpoint to ../dataset/model/checkpoint3.pt\n",
            "2021-06-05 09:48:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../dataset/model/checkpoint3.pt (epoch 3 @ 249 updates, score 3.83) (writing took 303.1846322020001 seconds)\n",
            "2021-06-05 09:48:31 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2021-06-05 09:48:31 | INFO | train | epoch 003 | loss 3.814 | nll_loss 2.133 | ppl 4.39 | wps 1135 | ups 0.21 | wpb 5427.9 | bsz 198 | num_updates 249 | lr 1.96128e-06 | gnorm 1.495 | clip 100 | loss_scale 8 | train_wall 106 | gb_free 2.9 | wall 1375\n",
            "2021-06-05 09:48:31 | INFO | fairseq_cli.train | done training in 1220.7 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpPsT1e7vuO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a5fbdd4-1633-4eff-e919-8dbf99dc1a81"
      },
      "source": [
        "# To test the models after training, you can use joint_translate.sh\n",
        "\n",
        "\n",
        "\n",
        "# joint_translate takes src_file, output_fname, src_lang, tgt_lang, model_folder as inputs\n",
        "# src_file -> input text file to be translated\n",
        "# output_fname -> name of the output file (will get created) containing the model predictions\n",
        "# src_lang -> source lang code of the input text ( in this case we are using en-indic model and hence src_lang would be 'en')\n",
        "# tgt_lang -> target lang code of the input text ( tgt lang for en-indic model would be any of the 11 indic langs we trained on:\n",
        "#              as, bn, hi, gu, kn, ml, mr, or, pa, ta, te)\n",
        "# supported languages are:\n",
        "#              as - assamese, bn - bengali, gu - gujarathi, hi - hindi, kn - kannada, \n",
        "#              ml - malayalam, mr - marathi, or - oriya, pa - punjabi, ta - tamil, te - telugu\n",
        "\n",
        "# model_dir -> the directory containing the model and the vocab files\n",
        "\n",
        "# Note: if the translation is taking a lot of time, please tune the buffer_size and batch_size parameter for fairseq-interactive defined inside this joint_translate script\n",
        "\n",
        "\n",
        "# here we are translating the english sentences to hindi\n",
        "!bash /content/finetuning/indicTrans/joint_translate.sh /content/finetuning/dataset/test/test.en en_mr_outputs.txt 'en' 'mr' /content/finetuning/dataset"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun 5 10:23:52 UTC 2021\n",
            "Applying normalization and script conversion\n",
            "100% 500/500 [00:00<00:00, 1099.70it/s]\n",
            "Number of sentences in input: 500\n",
            "Applying BPE\n",
            "Decoding\n",
            "Extracting translations, script conversion and detokenization\n",
            "Translation completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yEoqL1OlxZ1",
        "outputId": "a9c65627-36c8-4d43-fede-aa67755cb85f"
      },
      "source": [
        "!cat en_mr_outputs.txt"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "गंभीर तीव्र श्वसन सिंड्रोम कोरोनाव्हायरस 2 (SARS-CoV-2) हा एक नवीन विषाणू आहे, जो पहिल्यांदा वुहानमधील श्वसनाच्या गंभीर आजाराच्या रुग्णांच्या समूहाशी संबंधित न्युमोनियाच्या तीन लोकांपासून वेगळा करण्यात आला.\n",
            "जॉन्स हॉपकिन्स युनिव्हर्सिटीच्या आकडेवारीनुसार गुरुवारी जगभरात SARS-CoV-2 कोरोना व्हायरसची लागण झालेल्यांची एकूण संख्या दहा लाखांच्या पुढे गेली आहे.\n",
            "HCoV-229E स्ट्रेन B814 च्या पहिल्या अलगीकरणापूर्वी सामान्य सर्दी झालेल्या रुग्णांच्या नाकातून बाहेर पडण्यापूर्वी, टर्की, उंदीर, गाय, डुक्कर, मांजर आणि कुत्रा यासह विविध संसर्गित प्राण्यांमध्ये वेगवेगळ्या CoV वेगळे करण्यात आले होते.\n",
            "फेलिन कोरोनाव्हायरस (एफसीओव्ही) मांजरांमध्ये सौम्य आंत्रशोथ तसेच गंभीर फेलिन संसर्गजन्य पेरिटोनिटिस (एकाच विषाणूचे इतर प्रकार) निर्माण करतो.\n",
            "चिनी सरकारचे वरिष्ठ वैद्यकीय सल्लागार झोंग नानशान यांनी असा युक्तिवाद केला की, जर विषाणूचा प्रसार रोखण्याच्या उपायांवरील WHO च्या सल्ल्याचे पालन करण्यासाठी सर्व देशांना एकत्रित केले जाऊ शकते तर हे जूनपर्यंत संपू शकते.\n",
            "COVID-19 देखरेखीमुळे साथीच्या रोगाच्या प्रवृत्तीवर लक्ष ठेवणे, नवीन रुग्णांची वेगाने ओळख पटवणे आणि या माहितीवर आधारित, धोक्याचे मूल्यांकन करण्यासाठी आणि रोगाच्या तयारीला मार्गदर्शन करण्यासाठी साथीच्या रोगाची माहिती प्रदान करणे अपेक्षित आहे.\n",
            "आतापर्यंत प्राप्त झालेल्या वैद्यकीय अभ्यासांच्या आधारे, कोविड-19 रूग्णांच्या आजाराच्या अंदाजावर खालील घटक परिणाम करू शकतात किंवा त्याच्याशी संबंधित असू शकतात (सारणी 33):\n",
            "COVID-19 वरील संशोधनातील जलद प्रगती पाहता, अनेक महत्वाचे मुद्दे सोडवणे बाकी आहे, जे खालीलप्रमाणे आहेतः\n",
            "13 मार्च रोजी त्यांनी राष्ट्रीय आणीबाणी जाहीर केली, ज्यामुळे संकटाला प्रतिसाद देण्यासाठी संघीय निधी उपलब्ध झाला.\n",
            "वुहान आणि शेनझेन येथील चिनी क्लिनिकल चाचण्यांमध्ये फॅविपिराविर स्पष्टपणे प्रभावी असल्याचा दावा करण्यात आला आहे.\n",
            "युरोपियन युनियनमधील इटलीचे राजदूत मॉरिझिओ मस्सारी म्हणाले, \"केवळ चीनने द्विपक्षीय प्रतिसाद दिला.\n",
            "काही संसर्ग झालेल्यांपैकी 30% पेक्षा जास्त लोकांचा मृत्यू होऊ शकतो, जसे की MERS-CoV, आणि काही तुलनेने हानीकारक नसतात, जसे की सामान्य सर्दी.\n",
            "\"डोनाल्ड ट्रम्प यांच्या अमेरिकन प्रशासनाने कोरोना विषाणूला\" \"चिनी विषाणू\" \"किंवा\" \"वुहान विषाणू\" \"असे संबोधले आहे, असे म्हणत चीनच्या सेन्सरशिपमुळे एक विषाणू जो आता जागतिक साथीच्या रोगात रूपांतरित झाला आहे,\" \"ज्याची काही टीकाकारांनी टीका केली आहे.\"\n",
            "खालच्या श्वसन मार्गात प्रतिकृती करण्याव्यतिरिक्त, SARS-CoV-2 वरील श्वसन मार्गात कार्यक्षमतेने प्रतिकृती करू शकतो आणि संसर्गाच्या सुरुवातीच्या टप्प्यात सौम्य किंवा कोणतीही लक्षणे निर्माण करू शकतो, ज्यामुळे सामान्य सर्दी-खोकला होतो.\n",
            "सहसा एकाच कुटुंबात किंवा एकाच मेळाव्यातून किंवा क्रूझ जहाजासारख्या वाहनातून क्लस्टरयुक्त सुरवात होते.\n",
            "जगभरातील अधिकाऱ्यांनी प्रवासावरील निर्बंध, विलगीकरण, कर्फ्यू, कामाच्या ठिकाणी धोक्याचे नियंत्रण आणि सुविधा बंद करून प्रतिसाद दिला आहे.\n",
            "वर वर्णन केल्याप्रमाणे अलीकडील अभ्यासानुसार, 8,866 रुग्णांच्या लोकसंख्येवर आधारित उष्मायन कालावधी 4.8 (3.0-7.2) दिवस होता.\n",
            "गंभीर प्रकरणांमध्ये, रुग्णांना तीव्र श्वसन सिंड्रोम, सेप्टिक शॉक, चयापचय अॅसिडोसिस आणि कोगलोपॅथी विकसित करण्यासाठी लवकर प्रगती झाली.\n",
            "दमन पसंत केले जाऊ शकते परंतु जोपर्यंत मानवी लोकसंख्येत विषाणू फिरत आहे तोपर्यंत (किंवा लस उपलब्ध होईपर्यंत, जर ती प्रथम आली तर), अन्यथा उपाययोजना शिथिल केल्यावर संसर्गाचा लवकर प्रतिकार होतो.\n",
            "बहुधा, ते आधीपासूनच मानवांच्या जवळच्या आणखी एका यजमानाशी जुळवून घेण्यात आले आहे.\n",
            "या अभ्यासात, आम्ही प्रत्येक युरोपियन युनियन/युरोपियन इकॉनॉमिक एरिया (ईयू/ईईए) देश आणि युनायटेड किंग्डम (यूके) मधील COVID-19 च्या संचयी घटनांमधील ट्रेंडचे मूल्यांकन करतो आणि त्यांची तुलना चीनच्या हुबेई प्रांताशी करतो.\n",
            "दोन प्रकारचे कॅनाइन कोरोनाव्हायरस (सीसीओव्ही) (एक आतड्यांचा आजार आणि दुसरा श्वसनाच्या आजारांमध्ये आढळतो).\n",
            "लॉकडाऊन लागू झाल्यानंतर दोन महिन्यांनंतर हुबेईमध्ये हुबेई व्यतिरिक्त प्रवासावरील निर्बंध शिथिल करण्यात आले होते. चीनच्या परराष्ट्र मंत्रालयाने 26 मार्च 2020 रोजी घोषणा केली की 28 मार्चपासून व्हिसा किंवा निवासी परवाना धारकांसाठी प्रवेश स्थगित केला जाईल, ज्यात हे धोरण केव्हा संपणार याविषयी कोणतीही विशिष्ट माहिती देण्यात आलेली नाही.\n",
            "जागतिक अर्थव्यवस्थेचे नुकसान चीनमध्ये जाणवले आहेः 16 मार्चच्या एका मीडिया अहवालानुसार, विषाणूचा प्रसार रोखण्यासाठी सरकारने केलेल्या उपायांमुळे 2020 च्या पहिल्या दोन महिन्यात चीनची अर्थव्यवस्था खूप कठीण झाली आणि किरकोळ विक्री 20.5% खाली आली.\n",
            "2019 च्या नोवेल एचसीओव्ही (2019-एनसीओव्ही), ज्याचे नंतर सार्स-सीओव्ही-2 असे नामकरण करण्यात आले, हे सध्या सुरू असलेल्या कोरोना व्हायरस रोग 2019 (कोविड-19) च्या साथीचे कारण आहे, ज्याने 3 मार्च 2020 पर्यंत 3,120 पेक्षा जास्त लोकांचा बळी घेतला आहे आणि 91,000 हून अधिक लोकांना संसर्ग झाला आहे.\n",
            "बहुधा, SARS-CoV-2 चे मध्यवर्ती प्राणी यजमान हे हुआनान सीफूड होलसेल मार्केटमध्ये विकलेल्या आणि मारल्या गेलेल्या वन्यजीव प्रजातींपैकी असले पाहिजेत, ज्याशी COVID-19 ची सुरुवातीची अनेक प्रकरणे संबंधित होती, जी संभाव्य प्राणी-ते-मानव संक्रमणाची घटना दर्शवते.\n",
            "संपूर्ण शहरांना क्वारंटाईन न करूनही दक्षिण कोरियाचा हा कार्यक्रम प्रादुर्भाव रोखण्यात यशस्वी ठरला आहे. या संकटाला राष्ट्रपती मून जे-इन यांनी दिलेल्या प्रतिसादामुळे दक्षिण कोरियाचा समाज सुरुवातीला ध्रुवीकृत झाला होता.\n",
            "तरीही, SARS-CoV-2 ची वैशिष्ट्ये, ज्यात संक्रमणक्षमता, रोगजनकता आणि मानवांमधील परिच्छेदानंतर सातत्यपूर्ण प्रसार समाविष्ट आहेत, COVID-19 च्या चालू उद्रेकाच्या अंतिम नियतीवर प्रभाव पाडेल.\n",
            "शिवाय, वटवाघळांच्या उच्च चयापचय क्रियाकलापातून तयार झालेल्या प्रतिक्रियाशील ऑक्सिजन प्रजातींची (आरओएस) उच्च पातळी सीओव्ही प्रतिकृती रोखू शकते आणि एक्सोरिबोन्यूक्लियज द्वारे प्रूफरीडिंगवर परिणाम करू शकते, अशा प्रकारे नवीन यजमानामध्ये दाखल झाल्यावर विषाणूच्या निर्मितीसाठी निवड दबाव प्रदान करतो.\n",
            "अनेक रेल्वे स्थानके आणि बंदरे बंद करण्यात आली आहेत.\n",
            "कोरोना विषाणू जोखीम घटकांमध्ये लक्षणीयरित्या बदलतात.\n",
            "स्पष्टतेसाठी, ज्ञात एचसीओव्हीच्या प्राण्यांच्या उगमाविषयीचे सध्याचे ज्ञान चित्र १ आणि तक्ता २ मध्ये सारांशित केले आहे.\n",
            "दोन्ही प्रकरणांमध्ये, यजमान नैसर्गिकरित्या संक्रमित असतात आणि एचसीओव्ही किंवा त्याच्या पालक विषाणूचे नैसर्गिक यजमान असतात.\n",
            "त्याच दिवशी, 215 कॅनेडियन (पहिल्या विमानातून 176, आणि अमेरिकन सरकारने भाड्याने घेतलेल्या दुसऱ्या विमानातून 39) यांना वुहानमधून सीएफबी ट्रेन्टन येथे दोन आठवड्यांसाठी विलगीकरणात ठेवण्यात आले.\n",
            "पॉलिप्रोटीनचे स्वतःचे प्रोटीज असतात जे पॉलिप्रोटीनला अनेक नॉनस्ट्रक्चरल प्रोटीनमध्ये विभाजित करतात.\n",
            "पश्चिम बंगालमधील भारतीय जनता पक्षाचे प्रदेशाध्यक्ष दिलीप घोष म्हणाले की, चिनी लोकांनी निसर्गाचा नाश केला आणि त्यामुळेच देवाने त्यांचा सूड घेतला.\n",
            "अभ्यासातून असे आढळले आहे की उघड्या खोकल्यामुळे 4.5 मीटर (15 फूट) ते 8.2 मीटर (27 फूट) पर्यंतचे ड्रॉपलेट्स येऊ शकतात.\n",
            "कोंबड्यांमध्ये, संसर्गजन्य ब्रोंकायटिस विषाणू (आयबीव्ही), एक कोरोना विषाणू, केवळ श्वसनाच्या नळीच नव्हे तर युरोजेनिटल ट्रॅक्टलाही लक्ष्य करतो.\n",
            "मनोरंजक गोष्ट म्हणजे, न्यूक्लियोटाइड अॅनालॉग रेमडेसिविर हे या एक्सोरिबोन्यूक्लियज आणि आरएनए-आश्रित आरएनए पॉलिमरेजच्या प्रतिबंधाद्वारे सीओव्ही प्रतिकृती दाबण्यासाठी ओळखले जाते.\n",
            "ओव्हर-द-काउंटर थंड औषधे, पेय आणि विश्रांती घेतल्याने लक्षणे कमी होण्यास मदत होऊ शकते.\n",
            "त्यामुळे गरज पडल्यास कमी डोस आणि कोविड-19 रूग्णांमध्ये थोड्या काळासाठी स्टेरॉईडचा वापर करावा.\n",
            "सप्टेंबर 2012 मध्ये, नवीन प्रकारचा कोरोनाव्हायरस ओळखला गेला, सुरुवातीला त्याला नोव्हेल कोरोनाव्हायरस 2012 असे नाव देण्यात आले आणि आता अधिकृतपणे मिडल ईस्ट रेस्पिरेटरी सिंड्रोम कोरोनाव्हायरस (MERS-CoV) असे नाव देण्यात आले.\n",
            "सीएनएनच्या अहवालात असे सूचित करण्यात आले आहे की इटलीची मोठी वृद्ध लोकसंख्या आणि आजपर्यंत विषाणूचा संसर्ग असलेल्या सर्वांची चाचणी करण्यास असमर्थता हे उच्च मृत्यूदरात योगदान देऊ शकतात.\n",
            "20 जानेवारीला, आरोग्य सेवा पुरवठादारांचा संसर्ग झाल्याची नोंद करण्यात आली, ज्यात असे सुचवण्यात आले की मनुष्यातून मनुष्यामध्ये संसर्ग होऊ शकतो.\n",
            "संसर्ग झालेल्या लोकांसाठी सर्जिकल मास्कची शिफारस केली जाते, कारण मास्क घालणे बोलताना, शिंकताना आणि खोकताना श्वसनाच्या थेंबांचे प्रमाण आणि प्रवास अंतर मर्यादित करू शकते.\n",
            "एचसीओव्ही उत्क्रांतीच्या ट्रेंडचाही आम्ही आढावा घेतो ज्यामध्ये संसर्गाच्या वाढीमुळे सहसा रोगजनकता कमी होते.\n",
            "ईयू/ईईए (EEA) देश आणि युके (UK) मधील काही प्रदेशांमध्ये आतापर्यंत केसेस क्लस्टर झाल्या असल्याने आणि रुग्णालये आणि इंटेन्सिव्ह केअर युनिट्स सामान्यतः परिभाषित प्रादेशिक पाणलोट लोकसंख्येची सेवा करतात, त्यामुळे केसेस आणि इंटेन्सिव्ह केअर बेड्सची माहिती आकडेवारी 2 (NUTS-2) स्तरावरील प्रादेशिक युनिटच्या नामपद्धतीवर उपलब्ध करून देण्यात यावी.\n",
            "त्यामुळे वटवाघळांना एचसीओव्ही-२२९ई थेट माणसांना संसर्ग होऊ शकतो यात आश्चर्य वाटण्यासारखं काही नाही.\n",
            "COVID-19 साठी तीन प्रमुख जोखीम घटक सेक्स (पुरुष), वय (60) आणि गंभीर न्युमोनिया होते.\n",
            "मानवी स्वयंसेवकांच्या अभ्यासानुसार, HCoV-229E चा संसर्ग झालेल्या निरोगी व्यक्तींना सौम्य सामान्य सर्दी झाली.\n",
            "काही कलाकारांनी पारंपारिक थेट सादरीकरणाला पर्याय म्हणून इंटरनेटवर काम तयार करणे आणि सामायिक करणे सुरू ठेवण्याचे मार्ग शोधले आहेत, जसे की लाईव्ह स्ट्रीमिंग कॉन्सर्ट किंवा कलाकारांसाठी त्यांच्या कामाचे प्रदर्शन, वितरण आणि प्रचार करण्यासाठी वेब-आधारित 'फेस्टिव्हल' तयार करणे.\n",
            "18 फेब्रुवारी 2020 रोजी, बोली झांग आणि सहकाऱ्यांनी एकट्या पाश्चिमात्य औषधोपचार (डब्ल्यूएम) आणि डब्ल्यूएम आणि टीसीएम यांच्या एकत्रित उपचारांची तुलना करण्यासाठी एक अभ्यास प्रकाशित केला.\n",
            "बहुतांश प्रकरणांचे संबंध हुआनान सीफूड होलसेल मार्केटशी होते आणि त्यामुळे विषाणूचे मूळ प्राणी असल्याचे मानले जाते.\n",
            "उदाहरणार्थ, एक्सोरिबोन्यूक्लियज नॉन-स्ट्रक्चरल प्रथिने, प्रूफरीडिंग फंक्शन प्रदान करून प्रतिकृतीला अतिरिक्त निष्ठा प्रदान करतात जे आरएनए-निर्भर आरएनए पॉलिमरेज कमतरता आहे. संकुलाचे एक मुख्य कार्य म्हणजे विषाणू जनुकाची प्रतिकृती करणे.\n",
            "मलेरियावर उपचार करण्यासाठी आधीपासूनच मंजूर करण्यात आलेल्या पुनर्वापर केलेल्या औषधांचे सात चाचण्या मूल्यांकन करत होत्या, ज्यामध्ये हायड्रॉक्सीक्लोरोक्वीन किंवा क्लोरोक्वीन फॉस्फेटवरील चार अभ्यासांचा समावेश होता.\n",
            "उदयोन्मुख रोगावर प्रकाशनांची संख्या झपाट्याने वाढत असल्यामुळे या लेखात वेगाने विकसित होणाऱ्या संशोधन विषयाचा समयोचित आणि सर्वसमावेशक आढावा घेण्याचा प्रयत्न करण्यात आला आहे.\n",
            "हे आरएनए स्ट्रॅंडमधून आरएनएच्या प्रतिकृती आणि प्रतिलिपीत थेट गुंतलेले आहे.\n",
            "सार्स साथीच्या आजारामुळे 8,096 रुग्णांची नोंद झाली आणि 774 मृत्यू झाले, जे अनेक देश आणि खंडांमध्ये पसरले.\n",
            "बहुतेक एचसीओव्ही वटवाघळांपासून उद्भवतात जिथे ते रोगजनक नसतात.\n",
            "MERS-CoV, जरी अनेक वटवाघळांच्या कोरोना विषाणूंच्या प्रजातींशी संबंधित असला तरी, अनेक शतकांपूर्वी या प्रजातींपासून वेगळे झालेले दिसते.\n",
            "संसर्ग रोखण्यासाठी शारीरिक अंतराच्या उपायांची देखील शिफारस करण्यात आली आहे. अनेक सरकारांनी या उद्रेकामुळे प्रभावित झालेले देश आणि प्रदेशांमधून येणाऱ्या आणि येणाऱ्या सर्व अनावश्यक प्रवासावर निर्बंध घातले आहेत किंवा त्यांना सल्ला दिला आहे.\n",
            "परिस्थिती झपाट्याने बदलत असताना, उद्रेकाची अंतिम व्याप्ती आणि तीव्रता निश्चित करणे बाकी आहे.\n",
            "अमेरिकेत 244 हजारांहून अधिक कोरोनाबाधितांची नोंद झाली असून किमान 5,900 जणांचा मृत्यू झाला आहे.\n",
            "याच्या अगदी उलट, SARS-CoV-2 आणि RATG13 च्या RBD अधिक वेगळ्या आहेत, जरी अनुक्रम होमोलॉजी जिनोम-वाईडची उच्च पातळी.\n",
            "एप्रिल 2020 च्या सुरुवातीला, 103 उमेदवार उपचार प्री-क्लिनिकल किंवा पहिल्या-चौथ्या टप्प्यातील विकासाच्या टप्प्यात होते, एप्रिल महिन्यात 29 औषध उमेदवारांसाठी चाचणी परिणाम अपेक्षित होते.\n",
            "बॅट CoV-HKU4 आणि MERS-CoV विषाणू प्रवेशासाठी एकाच होस्ट रिसेप्टर, डिपेप्टिडाईल पेप्टिडेस 4 (DPP4) चा वापर करतात.\n",
            "तथापि, सीओव्ही टी पेशींच्या अपोप्टोसिसला प्रेरित करून टी पेशींचे कार्य रोखू शकतो.\n",
            "ते सकारात्मक-सेन्स सिंगल-स्ट्रॅंडेड आरएनए जीनोम आणि हेलिकल समरूपतेचा न्यूक्लियोकॅप्सिड असलेल्या विषाणूंना झाकून ठेवतात.\n",
            "या विषाणूमुळे एका दिवसात झालेल्या मृत्यूंची ही सर्वाधिक संख्या आहे.\n",
            "आजपर्यंतचा पुरावा असा आहे की COVID-19 असलेल्या 80% व्यक्तींना सौम्य आजार आहे, म्हणजे न्युमोनियासह किंवा नसलेला श्वसन मार्गाचा संसर्ग, आणि त्यापैकी बहुतांश बरे होतात.\n",
            "\"14 फेब्रुवारीला, चीनमधील स्थानिक व्यवस्थापनात मदत करण्यासाठी आणि प्रमुख राष्ट्रीय-स्तरीय संस्थांसोबत कार्यशाळा आणि बैठका आयोजित करून\" \"रोगाची तीव्रता आणि संक्रमणक्षमता\" \"चे मूल्यांकन करण्यासाठी आणि\" \"शहरी आणि ग्रामीण परिस्थितीसह प्रांतीय आणि काउंटी पातळीवर प्रतिसादाच्या क्रियाकलापांच्या परिणामाचे मूल्यांकन करण्यासाठी\" \"आंतरराष्ट्रीय आणि डब्ल्यूएचओ-च्या नेतृत्वाखालील संयुक्त मिशन टीम चीनसह सक्रिय करण्यात आली.\"\n",
            "प्रकरणांमध्ये वेगाने वाढ होऊ लागली, ज्यामुळे इटालियन सरकारला चीनला येणारी आणि तिथून येणारी सर्व विमाने रद्द करावी लागली आणि आणीबाणी घोषित करावी लागली.\n",
            "विविध प्रकारच्या झूनोटिक सीओव्ही जंगलात फिरत आहेत.\n",
            "इटलीच्या अनुभवाच्या आधारे, देश, रुग्णालये आणि अतिदक्षता विभागांनी कोविड-19 च्या वाढत्या रुग्णांची तयारी वाढवावी ज्यांना आरोग्यसेवेची गरज असेल आणि विशेषतः अतिदक्षता विभागात.\n",
            "शेवटी, आम्हाला आशा आहे की अधिक थेट पुरावे समोर येतील आणि वाचकांना त्यांच्या टिप्पण्या देण्यासाठी आवाहन करतील.\n",
            "व्यक्ती घरीच राहून, प्रवास मर्यादित करून, गर्दीचे ठिकाण टाळून, नो-कॉन्टॅक्ट ग्रीटिंग वापरून आणि स्वतःस इतरांपासून शारीरिक अंतर राखून सोशल डिस्टन्सिंग पद्धती लागू करू शकतात.\n",
            "पुष्टी झालेल्या प्रकरणाचे निदान संशयास्पद प्रकरणाच्या कोणत्याही एका घटकासह रोगजनक किंवा सेरोलॉजिकल पुराव्याच्या आधारावर केले पाहिजेः (1) सार्स-सीओव्ही-2 साठी रिअल-टाईम पीसीआर चाचणी पॉझिटिव्ह (2) व्हायरस संपूर्ण जीनोम सिक्वेंसिंग ज्ञात नोवेल कोरोना विषाणूंशी उच्च एकरूपता दर्शविते (3) सीरम चाचणीमध्ये विशिष्ट आयजीएम अँटीबॉडी आणि सार्स-सीओव्ही-2 साठी आयजीजी अँटीबॉडी पॉझिटिव्ह किंवा सार्स-सीओव्ही-2-विशिष्ट आयजीजी अँटीबॉडीमध्ये बदल नकारात्मक ते पॉझिटिव्ह, किंवा तीव्र टप्प्यात वरील रिकव्हरी टप्प्यात 4 पट वाढ.\n",
            "यापैकी ली वेनलियांगसह आठ डॉक्टरांना खोट्या अफवा पसरवल्याबद्दल पोलिसांनी ताकीद दिली, आणि आणखी एका आय फेनला तिच्या वरिष्ठांनी इशारा दिल्याबद्दल फटकारले.\n",
            "त्याच दिवशी WHO ला याची माहिती देण्यात आली.\n",
            "छातीत दुखणं कधी सुरू झालं?\n",
            "16 मार्च 2020 पर्यंत कोम येथील शिया मंदिरे भाविकांसाठी खुली होती. फेब्रुवारी महिन्यात चीननंतर इराण विषाणूच्या प्रसाराचे केंद्र बनले.\n",
            "साथीचा प्रादुर्भाव रोखण्यासाठी दीर्घकालीन हस्तक्षेपामुळे सामाजिक आणि आर्थिक खर्च होतो.\n",
            "छातीतील या वेदनेबद्दल मला खूप काळजी वाटते\n",
            "अमेरिकन अधिकाऱ्यांवर इतर देशांना मिळणारी मदत त्यांच्या देशात वळवल्याचा आरोपही करण्यात आला आहे.\n",
            "रिव्हर्स-ट्रान्स्क्रिप्टेज पॉलिमरेज चेन रिअॅक्शन (RT-PCR) द्वारे SARS-CoV-2 RNA चा शोध कोविड-19 च्या निदानासाठी प्रमुख निकष म्हणून वापरला गेला.\n",
            "उदयोन्मुख संसर्गजन्य आजार-उदयोन्मुख रोगजनकाचा संसर्गजन्य आजार, बहुतेकदा त्याच्या उदयोन्मुख श्रेणी किंवा संचरण मोडमध्ये नवीन\n",
            "किम्बर्ली-क्लार्क, जो क्लिनेक्स टॉयलेट टिश्यू बनवतो आणि सोलारिस पेपर जो सोरबेंट बनवतो, यांनी पुरवठा राखण्यासाठी 24/7 काम करत असल्यावर भर दिला, असे न्यूज. com. au च्या अहवालात म्हटले आहे.\n",
            "ऑस्ट्रिया सरकारने किराणा दुकानामध्ये येणाऱ्या प्रत्येकाने मास्क वापरणं अनिवार्य केलं आहे.\n",
            "या आधारावर, SARS-CoV-2 संसर्ग झालेल्या व्यक्तींवर दोन चाचण्या करण्यासाठी गिलियडने चीनला कंपाऊंड पुरवले आहे आणि त्याचे परिणाम अतिशय अपेक्षित आहेत.\n",
            "22 फेब्रुवारीपर्यंत, चर्चच्या 9,336 अनुयायांपैकी 1,261 किंवा सुमारे 13% लोकांनी लक्षणे नोंदवली. दक्षिण कोरियाने 23 फेब्रुवारी 2020 रोजी सर्वोच्च पातळीचा इशारा जाहीर केला.\n",
            "जागतिकीकरण आणि आजार-जागतिकीकरण आणि रोगाच्या संक्रमणाचा आढावा\n",
            "17 मार्चपर्यंत या आजाराने किमान 12 विद्यमान किंवा माजी इराणी राजकारणी आणि सरकारी अधिकाऱ्यांचा मृत्यू झाला होता.\n",
            "त्यामुळे सार्स-सीओव्ही आणि सार्स-सीओव्ही-2 चा प्रसार रोखण्यासाठी चीनमध्ये जंगली पशू बाजारात जे केले गेले त्याप्रमाणे मर्सच्या नियंत्रणासाठी सर्व उंट बळी देणे अशक्य आहे.\n",
            "याचे कारण म्हणजे मानवी शरीराच्या बाहेर हा विषाणू घरगुती साबणाने मारला जातो, जो त्याचा संरक्षक बुलबुला फोडतो.\n",
            "सीडीसीने लोकांना किमान वीस सेकंदांसाठी साबण आणि पाण्याने हात धुण्याची शिफारस केली आहे, विशेषतः शौचालयात गेल्यानंतर किंवा खाण्यापूर्वी आणि नाक, खोकणे किंवा शिंकण्यानंतर हात स्पष्टपणे घाणेरडे असल्यास.\n",
            "युरोपियन युनियन/युरोपियन इकॉनॉमिक एरिया आणि युनायटेड किंग्डममध्ये 1 जानेवारी ते 15 मार्च 2020 पर्यंत कोरोनाव्हायरस रोगाच्या (COVID-19) संचित घटनांमध्ये वेगाने वाढ\n",
            "अनेक क्लिनिकल प्रयोगशाळांमधील उच्च-थ्रोपुट स्वयंचलित प्रणाली हे मूल्यांकन करू शकतील परंतु त्यांची उपलब्धता प्रत्येक प्रणालीसाठी उत्पादनाच्या दरावर अवलंबून असेल.\n",
            "सुरवातीपासून मृत्यूपर्यंत सरासरी वेळ 9.5 (4.8-13) दिवस होती.\n",
            "लक्षणे दिसू लागण्याच्या तीन दिवसांपूर्वी लोकांनी या आजाराची चाचणी पॉझिटिव्ह केली असून लक्षणे दिसण्यापूर्वी संप्रेषण शक्य असल्याचे सुचवले आहे.\n",
            "हा विषाणू कोंबडीच्या विविध अवयवांमध्ये पसरू शकतो.\n",
            "हुशेनशान रुग्णालय हे तात्पुरते रुग्णालय 10 दिवसात पूर्ण झाल्याची घोषणाही अधिकाऱ्यांनी केली.\n",
            "आश्चर्याची गोष्ट म्हणजे, SARS च्या बरे झालेल्या रुग्णांची सीरा WIV1 ला निष्क्रिय करण्यास सक्षम होती.\n",
            "कमतरता दूर करण्यासाठी, कोल्स यांनी पुरवठादारांकडून मोठ्या पॅकेजेसची ऑर्डर दिली आणि वितरण वारंवारता वाढवली, वूलवर्थने अतिरिक्त साठ्याची ऑर्डर दिली, तर एएलडीआयने नियोजित बुधवारी विशेष साठा लवकर उपलब्ध करून दिला.\n",
            "Canine Coronavirus (CCoV) चे दोन प्रकार आहेत, एक जो सौम्य जठराचा आजार निर्माण करतो आणि दुसरा जो श्वसनाचा आजार निर्माण करतो.\n",
            "एचसीओव्ही-२२९ई शी संबंधित बॅट आणि उंट विषाणूंमध्ये अखंड ओआरएफ४ पाहू शकता, तर अल्पाका अल्फा-सीओव्ही एकल न्यूक्लियोटाइड अंतर्भुत दर्शवितो, ज्यामुळे फ्रेमशिफ्ट निर्माण होते.\n",
            "आफ्रिकेतील काही देशांमध्येही चीनविरोधी भावना वाढल्याचे दिसून आले आहे.\n",
            "हे उंट वाहतुकीसाठी एक महत्त्वाचे साधन म्हणून तसेच मांस, दूध, चामडे आणि लोकर उत्पादनांचा स्थानिक लोकांसाठी मुख्य स्रोत म्हणून काम करतात.\n",
            "तथापि, कोविड-19 (चाचणी-सातव्या आवृत्ती) आणि अलीकडील अभ्यासांसाठी नवीन निदान आणि उपचार मार्गदर्शक तत्त्वांनुसार त्यांच्या कामालाही अद्ययावत करण्याची आवश्यकता आहे.\n",
            "कोरोना विषाणूंमुळे ताप, घसा खवखवणे यांसारख्या प्रमुख लक्षणांसह सर्दी होऊ शकते.\n",
            "युनायटेड स्टेट्स सेंटर फॉर डिसीज कंट्रोल अँड प्रिव्हेन्शनने प्रकाशित केलेल्या एका अभ्यासातून असे निष्पन्न झाले आहे की ती ५. ७ असू शकते.\n",
            "तथापि, हे समुदाय-अधिग्रहीत एचसीओव्हीपेक्षा जास्त रोगजनक आहे आणि सार्स-सीओव्ही किंवा मर्स-सीओव्हीपेक्षा कमी रोगजनक आहे.\n",
            "कोरोनामुळे होणाऱ्या COVID-19 या आजारामुळे किमान 52 हजार लोकांचा मृत्यू झाला आहे.\n",
            "यापैकी चार कोरोनाव्हायरस मानवी लोकसंख्येत सतत पसरतात आणि जगभरातील प्रौढ आणि मुलांमध्ये सर्दीची सामान्यतः सौम्य लक्षणे निर्माण करतातः-OC43,-HKU1,-HCoV-229E,-NL63.\n",
            "मार्च 2020 च्या उत्तरार्धात युरोइमून मेडिकल लॅबोरेटरी डायग्नोस्टिक्स आणि एपिटोप डायग्नोस्टिक्स यांना त्यांच्या चाचणी किटसाठी युरोपियन मान्यता मिळाली, जी रक्त नमुन्यांमध्ये विषाणूविरुद्ध आयजीजी आणि आयजीए अँटीबॉडीज शोधू शकते.\n",
            "मानवी कोरोना विषाणूंचा उगम\n",
            "कुटुंबातील कोणालाही हृदयविकाराचा आजार आहे-उच्च कोलेस्ट्रॉलचा उच्च रक्तदाब\n",
            "मला या प्रतिमेवर दाखवा जेथे तुम्हाला वेदना जाणवतात\n",
            "या सर्वांना जिवंत जन्म गर्भधारणा झाली होती आणि गंभीर नवजात श्वासोच्छ्वास आढळला नव्हता.\n",
            "याउलट, अत्यंत रोगजनक SARS-CoV आणि MERS-CoV यांनी मानवांशी नीट जुळवून घेतले नाही आणि मानवांमध्ये त्यांचा प्रसार टिकू शकत नाही.\n",
            "बी-कोरोना विषाणू हे संबंधित विषाणूंचा एक गट आहे जे सस्तन प्राणी आणि पक्ष्यांमध्ये आजार निर्माण करतात.\n",
            "रुग्णापासून दूर राहण्यासाठी तीन फूट हे योग्य अंतर मानले जाते.\n",
            "दुसर्या दृष्टीकोनातून, हे देखील खरे असू शकते की मानवांना या चार एचसीओव्ही (HCoV) शी चांगलं जुळवून घेण्यात आलं आहे.\n",
            "गुरुवारपर्यंत, असोसिएटेड प्रेसने अहवाल दिला की जगभरात कोविड-19 ची किमान 1,25,000 प्रकरणे आहेत, ज्यामुळे 4,600 पेक्षा जास्त मृत्यू झाले आहेत.\n",
            "सीरिया, व्हेनेझुएला आणि इराणवरील निर्बंध अमेरिकेने मागे घ्यावेत, अशी मागणीही चीनने केली आहे.\n",
            "SARS-CoV-2 या विषाणूंमुळे SARS-CoV आणि MERS-CoV सारखा गंभीर श्वसन संसर्ग होतो.\n",
            "दरम्यान, हा साथीचा आजार वेगाने शेजारच्या शहरांमध्ये, प्रांतांमध्ये आणि देशांमध्ये पसरला.\n",
            "11 मार्च रोजी ट्रम्प यांनी युनायटेड किंग्डम वगळता बहुतांश युरोपसाठी 13 मार्च पासून 30 दिवसांसाठी प्रवासावरील निर्बंधांची घोषणा केली.\n",
            "13 मार्चपर्यंत अंटार्क्टिका वगळता प्रत्येक खंडात चाळीस पेक्षा जास्त देशांनी आणि प्रदेशांनी मृत्यूची नोंद केली होती.\n",
            "इरा लोंगिनी यांनी साथीच्या परिणामाची भविष्यवाणी करण्यासाठी एक मॉडेल स्थापित केले आणि असे सुचवले की SARS-CoV-2 जागतिक लोकसंख्येच्या दोन तृतीयांश लोकसंख्येला संक्रमित करू शकतो.\n",
            "31 डिसेंबर 2019 रोजी, हा उद्रेक कोरोना विषाणूच्या एका नवीन प्रकारात आढळला, ज्याला जागतिक आरोग्य संघटनेने (डब्ल्यूएचओ) 2019-nCoV हे अंतरिम नाव दिले, नंतर विषाणूंच्या वर्गीकरणावरील आंतरराष्ट्रीय समितीने SARS-CoV-2 असे नाव दिले.\n",
            "प्रसूतीनंतर पाठपुरावा केलेल्या चित्रांमध्ये न्युमोनियाची प्रगती दिसून आली नाही. प्रसार माध्यमांच्या वृत्तांनुसार कोविड-19 बाधित 100 हून अधिक महिलांनी प्रसूती केली असावी आणि मार्च 2020 मध्ये एकही मातृमृत्यू झाला नाही.\n",
            "मुख्य भूमी चीन ही एक प्रमुख अर्थव्यवस्था आणि उत्पादन केंद्र असल्याने, व्हायरसचा उद्रेक जागतिक अर्थव्यवस्थेसाठी एक मोठा अस्थिरतेचा धोका असल्याचे दिसून आले आहे.\n",
            "चीनमध्ये, मृत्यू-ते-प्रकरण गुणोत्तर 17.3% (1-10 जानेवारी 2020) पासून 0.7% (1 फेब्रुवारी 2020 नंतर लक्षणे असलेल्या लोकांसाठी) पर्यंत कमी झाले.\n",
            "सध्या, COVID-19 साठी प्रभावी आणि विशिष्ट थेरपीच्या अभावामुळे, टीसीएम कमी ते मध्यम लक्षणे असलेल्या रुग्णांसाठी किंवा गंभीर अवस्थेतून बरे झालेल्यांसाठी प्रमुख पर्यायी उपचारांपैकी एक बनला आहे.\n",
            "थायलंड त्यांच्या विलगीकरणाची अंमलबजावणी करण्यासाठी सर्व प्रवाशांसाठी एक अॅप आणि सिम कार्डचा वापर करत आहे.\n",
            "जसे की अतिसार आणि उलट्या यांसारख्या जठरांत्रिय लक्षणांसह उपस्थित असलेल्या 30% पेक्षा जास्त रुग्ण.\n",
            "विषाणूविषयी चुकीची माहिती ऑनलाइन पसरली आहे, आणि चिनी लोक, पूर्व आणि आग्नेय आशियाई वंशाचे इतर लोक आणि लक्षणीय विषाणूची प्रकरणे असलेल्या प्रदेशांतील इतर लोकांविरुद्ध झेनोफोबिया आणि भेदभावाच्या घटना घडल्या आहेत.\n",
            "उमेदवार उपचारांवर चालू असलेल्या दुसऱ्या-तिसऱ्या टप्प्यातील क्लिनिकल ट्रायल्समधील अनुकूली डिझाइन्स चाचणीचा कालावधी कमी करू शकतात आणि कमी विषयांचा वापर करू शकतात, संभाव्य लवकर समाप्ती किंवा यशासाठी निर्णय घेण्यास गती देऊ शकतात आणि त्याच्या आंतरराष्ट्रीय ठिकाणी विशिष्ट चाचणीसाठी डिझाइन बदलांचे समन्वय करू शकतात.\n",
            "या श्रेणीचा उच्च अंदाज जर्मनीत कोविड-19 साठी पहिली यादृच्छिक चाचणी आणि सीएफआर अंदाजांवर चाचणीच्या परिणामांचे विश्लेषण करणाऱ्या सांख्यिकीय अभ्यासाच्या निकालांशी सुसंगत आहे.\n",
            "इतर देशांनीही विषाणूचा प्रसार मर्यादित करण्याच्या उद्देशाने विविध उपाययोजना केल्या आहेत.\n",
            "काही शास्त्रज्ञांनी BioRxiv सारख्या प्री-प्रिंट सर्व्हरवर त्यांचे परिणाम पटकन सामायिक करण्याचा निर्णय घेतला.\n",
            "युरोपियन युनियन/EEA देश आणि ब्रिटनमध्ये COVID-19 चे रुग्ण\n",
            "दोन्ही औषधांचा प्रिस्क्रिप्शनच्या औषधांबरोबर व्यापक संपर्क असतो, ज्याचा उपचारात्मक डोस आणि आजार कमी करण्यावर परिणाम होतो.\n",
            "जरी वटवाघळांमध्ये विषाणूंच्या प्रसाराला मदत करणारी अनेक वैशिष्ट्ये असली तरी लोकांना त्यांच्यापासून दूर राहण्याचे शिक्षण दिल्यास माणसांना वटवाघळ आणि इतर वन्यजीव प्रजाती यांच्याशी संपर्क साधण्याची संधी कमी होऊ शकते.\n",
            "अखेरीस, अल्पाका अल्फा-सीओव्ही जंगली प्राण्यांमध्ये सापडला नाही.\n",
            "अनेक धर्मांधांनी वृद्ध ख्रिश्चनांना रविवारच्या पूजेला उपस्थित राहण्याऐवजी घरीच राहण्याची शिफारस केली आहे-काही चर्चनी रेडिओ, ऑनलाइन थेट प्रक्षेपण किंवा दूरचित्रवाणी द्वारे चर्च सेवा उपलब्ध करून दिली आहे, तर इतर ड्राइव्ह-इन उपासना देत आहेत.\n",
            "दहा वर्षांनंतर, मिडल ईस्ट रेस्पिरेटरी सिंड्रोम (MERS) च्या उद्रेकामुळे अरबी द्वीपकल्पामध्ये सतत साथीचा आजार पसरला आणि जगाच्या उर्वरित भागात पसरला.\n",
            "प्रयोगशाळेने पुष्टी केलेल्या असिमटोमॅटिक केसेसचे फक्त काही अहवाल अस्तित्वात आहेत, परंतु संपर्क शोध तपासणीदरम्यान काही देशांनी असिमटोमॅटिक ट्रान्समिशन ओळखले आहे.\n",
            "यजमान रिबोसोम विषाणूच्या जनुकाच्या प्रारंभिक ओव्हरलॅपिंग ओपन रीडिंग फ्रेमचे भाषांतर करतो आणि एक लांब पॉलीप्रोटीन तयार करतो.\n",
            "29 मार्च रोजी असे सांगण्यात आले की 1 एप्रिलपासून सर्व नवीन परदेशी प्रवाशांना दोन आठवडे विलगीकरणात ठेवले जाईल.\n",
            "बहुतांश नवीन औषध उमेदवार (एनसीई) औषधाच्या विकासादरम्यान अपयशी ठरतात, एकतर ते अस्वीकार्य विषारी असतात किंवा ते लक्षित आजारावर परिणामकारकता सिद्ध करत नाहीत, जसे कि दुसऱ्या-तिसऱ्या टप्प्यातील क्लिनिकल चाचण्यांमध्ये दाखवले आहे.\n",
            "युरोपियन युनियनचे परराष्ट्र धोरण प्रमुख जोसेप बोरेल यांनी 'स्पिनिंग आणि उदारतेच्या राजकारणाच्या माध्यमातून प्रभावासाठी संघर्षासह एक भौगोलिक-राजकीय घटक आहे' असा इशारा दिला.\n",
            "अनेक देश COVID-19 मध्ये दाखल असलेल्या व्यक्तींच्या उपचारासाठी क्लोरोक्वीन किंवा हायड्रॉक्सीक्लोरोक्वीनचा वापर करत असले तरी मार्च 2020 पर्यंत या औषधाला अमेरिकेत क्लिनिकल चाचण्यांद्वारे अधिकृत मान्यता मिळालेली नाही.\n",
            "तरीपण, श्वसनाचा अपयश आणि अपयश हा रुग्णांसाठी सर्वात मोठा धोका आणि मृत्यूचे मुख्य कारण आहे.\n",
            "सर्वप्रथम, मनुष्यांचा, पण अल्पाकांचा संपर्क एका सामायिक पर्यावरणीय ठिकाणी वटवाघळांशी होऊ शकतो.\n",
            "उत्तर अमेरिकेतील तिरंगी बॅटमध्ये ARCoV. 2 (Appalachian Ridge CoV) नावाच्या एका वटवाघळाचा शोध लागला आहे, ज्याचा HCoV-NL63 शी जवळचा संबंध असल्याचे दिसून आले आहे.\n",
            "COVID-19 साठी आण्विक चाचण्यांचा वापर करून व्हायरोलॉजिकल देखरेख केली जाते.\n",
            "ऑनलाईन आणि ऑफलाईन अशा दोन्ही ठिकाणी चिनी लोकांना आणि विषाणूग्रस्त भागातील लोकांना पाठिंबा मिळाला आहे.\n",
            "विषाणूंचा संसर्ग डोळ्यांद्वारेही होऊ शकतो.\n",
            "20 मार्च रोजी, साथीच्या आजारामुळे अमेरिकेने इराकमधून अंशतः आपले सैन्य माघारी घेण्यास सुरुवात केली.\n",
            "16 मार्च रोजी, पंतप्रधान बोरिस जॉन्सन यांनी सर्व अनावश्यक प्रवास आणि सामाजिक संपर्काविरोधात सल्लामसलत देणारी घोषणा केली, लोकांना शक्य असल्यास घरून काम करण्याचा सल्ला दिला आणि पब, रेस्टॉरंट्स आणि थिएटर्ससारख्या ठिकाणे टाळण्याचा सल्ला दिला.\n",
            "11 मार्च 2020 रोजी, WHO ने COVID-19 ला महामारी म्हणून घोषित केले.\n",
            "उदाहरणार्थ, बीजिंगने शहरात प्रवेश करणाऱ्या सर्व आंतरराष्ट्रीय प्रवाशांना 14 दिवसांचे अनिवार्य विलगीकरण लागू केले आहे.\n",
            "गेल्या दशकांमध्ये, सात एचसीओव्ही ओळखले गेले आहेत.\n",
            "एचसीओव्ही-२२९ई शी जवळून संबंधित बॅट अल्फा-सीओव्ही आढळले आहेत.\n",
            "तथापि, 12 मे 2013 रोजी, फ्रान्समधील मानवी-मानवी संक्रमणाच्या प्रकरणाची पुष्टी फ्रेंच सामाजिक व्यवहार आणि आरोग्य मंत्रालयाने केली.\n",
            "इटालियन रेडिओलॉजिकल सोसायटी पुष्टी झालेल्या प्रकरणांसाठी इमेजिंग निष्कर्षांचा आंतरराष्ट्रीय ऑनलाइन डेटाबेस संकलित करत आहे.\n",
            "28 फेब्रुवारीला, स्कोप रेटिंग्ज जीएमबीएचने चीनच्या सार्वभौम क्रेडिट रेटिंगची पुष्टी केली, परंतु नकारात्मक दृष्टी कायम ठेवली.\n",
            "हा साथीचा रोग चिनी नववर्षाच्या सुट्टीशी संबंधित प्रमुख प्रवास हंगाम, चुनयुनशी जुळला.\n",
            "हा मैलाचा दगड त्याच दिवशी आला ज्यादिवशी मलावीने आपल्या पहिल्या कोरोना विषाणूच्या संसर्गाची पुष्टी केली आणि झांबियामध्ये कोरोनाविषाणूशी संबंधित पहिला मृत्यू झाला.\n",
            "हा उद्रेक घडवून आणणारा विषाणू SARS-CoV-2 म्हणून ओळखला जातो, हा नव्याने शोधला गेलेला विषाणू वटवाघळ कोरोना विषाणू, पॅंगोलिन कोरोना विषाणू आणि SARS-CoV यांच्याशी जवळून संबंधित आहे. लक्षणे असलेली सर्वात पूर्वीची ज्ञात व्यक्ती नंतर 1 डिसेंबर 2019 रोजी आजारी पडल्याचे आढळले आणि त्या व्यक्तीचे नंतरच्या ओल्या मार्केट क्लस्टरशी दृश्य संबंध नव्हते.\n",
            "म्हणून, ते हृदय किंवा यकृताच्या विकारांसाठी पारंपारिक चिन्हे आहेत.\n",
            "जपानमध्ये ट्विटरवर #ChineseDontComeToJapan हा हॅशटॅग ट्रेंड झाला.\n",
            "याव्यतिरिक्त, असे अधिकाधिक पुरावे आहेत जे आपल्याला असामान्य लक्षणे आणि लक्षणे नसलेल्या रुग्णांपासून सावध राहण्याची आठवण करून देतात.\n",
            "त्यानंतर झालेल्या सेरोप्रेव्हॅलेंस तपासात असे दिसून आले की सर्वसामान्य लोकसंख्येच्या तुलनेत पशू व्यापाऱ्यांमध्ये सार्स-कोव्ह-विरोधी आयजीजीचा प्रादुर्भाव जास्त होता.\n",
            "31 डिसेंबर 2019 रोजी, चीनमधील हुबेई प्रांतातील वुहान येथे अज्ञात एटिओलॉजीच्या न्यूमोनियाच्या केसेसचा समूह आढळला.\n",
            "\"WHO ने 2002-2004 च्या SARS उद्रेकातील विरोधाभासाची नोंद केली, जिथे चिनी अधिकाऱ्यांवर प्रतिबंध आणि प्रतिबंधात्मक प्रयत्नांना अडथळा आणणाऱ्या गोपनीयतेचा आरोप करण्यात आला होता आणि सध्याचे संकट जिथे केंद्र सरकारने\" \"चंद्र नववर्षाच्या सुट्टीच्या आधी भीती टाळण्यासाठी नियमितपणे अद्ययावत केले आहे.\"\n",
            "तथापि, COVID-19 आणि SARS यांच्यात काही लक्षणीय फरक आहेत, जे साथीच्या आजारावर नियंत्रण ठेवण्यासाठी आणि रुग्णांवर उपचार करण्यासाठी आवश्यक आहेत.\n",
            "रुग्णांना सहसा असामान्य न्युमोनिया, फुफ्फुसांची गंभीर दुखापत आणि तीव्र श्वसन त्रास सिंड्रोम (एआरडीएस) विकसित होतो.\n",
            "भौतिकदृष्ट्या, माऊस हिपॅटायटीस व्हायरस (मुरीन कोरोना व्हायरस), जो माऊसच्या यकृत आणि केंद्रीय मज्जासंस्थेला संसर्ग करतो, तो मानवी कोरोना व्हायरस OC43 आणि बोवाइन कोरोना व्हायरसशी संबंधित आहे.\n",
            "ऑनलाईन, अनेक कोरोनाव्हायरस-थीम असलेले इंटरनेट मीम्स पसरले आहेत कारण अनेकांनी अनिश्चिततेच्या दरम्यान विनोद आणि विकर्षणाकडे वळले आहेत.\n",
            "संसर्ग झालेले काही लोक लक्षणे नसलेले असू शकतात, कोणतीही क्लिनिकल लक्षणे नसतात, परंतु संसर्गाची पुष्टी करणारे चाचणी परिणाम असतात, म्हणून संशोधकांनी सल्ला दिला आहे की संसर्ग झालेल्या लोकांशी जवळचा संपर्क असलेल्यांनी संसर्ग टाळण्यासाठी बारकाईने निरीक्षण केले पाहिजे आणि तपासले पाहिजे.\n",
            "आणि तापासोबत\n",
            "बिल आणि मेलिंडा गेट्स फाऊंडेशनच्या नेतृत्वाखाली भागीदारांनी 125 दशलक्ष अमेरिकन डॉलर्सची गुंतवणूक केली आणि जागतिक आरोग्य संघटनेशी समन्वय साधून मार्च महिन्यात कोविड-19 थेरप्यूटिक्स अॅक्सलरेटर सुरू करण्यात आले, ज्यामुळे औषध विकास संशोधकांना संभाव्य उपचारांची ओळख पटवणे, मूल्यांकन करणे, विकसित करणे आणि प्रमाण वाढवणे शक्य झाले.\n",
            "COVID-19 मुळे होणाऱ्या खऱ्या मृत्यूंची संख्या खूप जास्त असू शकते, कारण त्यात चाचणीशिवाय मरण पावलेल्या लोकांचा समावेश नाही-उदाहरणार्थ घरी, नर्सिंग होममध्ये इत्यादी.\n",
            "हे नक्कीच युरोपियन एकतेचे चांगले लक्षण नाही.\n",
            "10 कर्करोगविरोधी औषधांच्या विकासासाठी 2015-16 च्या चाचण्यांच्या सरासरी खर्चाचा अंदाज 648 दशलक्ष डॉलर्स होता.\n",
            "याव्यतिरिक्त, उपचारात्मक परिणाम लक्षात घेता, प्लाझमाशी संबंधित काही तोटे काळजीपूर्वक विचारात घेतले पाहिजेत.\n",
            "\"द कॅम्पेन फॉर न्यूक्लियर डिसआर्मामेंट च्या सरचिटणीस केट हडसन यांनी डिफेंडर 2020 कवायतीवर टीका केलीः\" \"सध्याच्या सार्वजनिक-आरोग्य संकटात, यामुळे केवळ अमेरिका आणि अनेक युरोपियन देशांच्या सैन्याचे जीव धोक्यात आले नाहीत तर ज्या देशांमध्ये ते कार्यरत आहेत त्या देशांचे रहिवासी देखील धोक्यात आले आहेत.\" \"इराणी सरकारवर विषाणूचा मोठा परिणाम झाला आहे, ज्यामध्ये सुमारे दोन डझन संसदेच्या सदस्यांना संसर्ग झाला आहे तसेच इतर पंधरा विद्यमान किंवा माजी राजकीय व्यक्तिमत्त्व आहेत.\"\n",
            "एक सामान्य पद्धत म्हणून, विषाणूच्या संपर्कात आलेल्या किंवा संसर्ग झालेल्या व्यक्तींना सामान्यतः 14 दिवस विलगीकरणात ठेवावे लागते.\n",
            "पुनरागमनाचा विषाणू कळपाची रोगप्रतिकारशक्ती आणि उत्परिवर्तनाची व्याप्ती यावर अवलंबून असेल.\n",
            "तथापि, ते न्यूक्लियोटाइड अनुक्रमाच्या पातळीवर सुमारे 90% ओळखसह RaTG13 शी समान प्रमाणात संबंधित आहेत.\n",
            "अमेरिकन विद्यापीठांमधील काही चिनी विद्यार्थी 30 जानेवारीला हुबेई प्रांतातील रुग्णालयांमध्ये 50,000 N95 मास्क पाठवण्याच्या व्यवस्थापनासाठी ग्रेटर शिकागो भागातील संयुक्त गटासह चीनच्या विषाणूग्रस्त भागांना मदत पाठवण्यास मदत करण्यासाठी एकत्र आले.\n",
            "मनुष्यांमध्ये, कोरोना विषाणूंमुळे श्वसनमार्गाचा संसर्ग होतो जो सौम्य ते प्राणघातक असू शकतो.\n",
            "2019 च्या अखेरीस मध्य चीनमध्ये SARS-CoV-2 च्या उद्रेकाने CoVs ला पुन्हा प्रकाशझोतात आणले आणि त्याच्या बहिणीच्या SARS-CoV च्या तुलनेत त्याची उच्च संक्रमण क्षमता परंतु रोगजनकता कमी झाल्याने आपल्याला आश्चर्य वाटले.\n",
            "MERS साठी, जून 2012 मधील लोकसंख्याशास्त्रीय अभ्यासावर आधारित, 2,494 पुष्टी झालेल्या प्रकरणांपैकी 37% मृत्यू होते.\n",
            "काही संशोधकांनी असे सुचवले आहे की ह्युनान सीफूड होलसेल मार्केट हा मानवांना विषाणूचा संसर्ग होण्याचा मूळ स्त्रोत असू शकत नाही. 17 एप्रिल 2020 पर्यंत कोरोना विषाणूच्या निमोनिया साथीच्या आजारामुळे किमान 153,822 लोकांचा मृत्यू झाला आहे आणि 2,240,191 पेक्षा जास्त प्रकरणांची पुष्टी झाली आहे.\n",
            "महत्वाचे म्हणजे, आम्ही विषाणू उत्क्रांती आणि जीनोम रिकॉम्बिनेशनच्या दृष्टीकोनातून वेगवेगळ्या एचसीओव्हीची तुलना आणि तुलना करतो.\n",
            "बॅट CoV ची विविधता नवीन HCoV च्या उदयाला येण्यासाठी भरपूर संधी प्रदान करते.\n",
            "दुसरे म्हणजे, पॅंगोलिन हे मध्यवर्ती प्रवर्धित होस्टपैकी एक असू शकते ज्यामध्ये SARS-CoV-2 संबंधित विषाणू नव्याने सादर करण्यात आला होता.\n",
            "बर्याच वर्षांपासून, चार समुदाय-अधिग्रहीत सीओव्ही मानवी लोकसंख्येत प्रसारित होतात, ज्यामुळे रोगप्रतिकारकशक्ती असलेल्या विषयांमध्ये सामान्य सर्दी होते.\n",
            "एचसीओव्ही-ओसी४३ संसर्गाची वैद्यकीय वैशिष्ट्ये एचसीओव्ही-२२९ई मुळे उद्भवलेल्या लक्षणांसारखीच दिसतात, जी लक्षणांनुसार इन्फ्लुएन्झा ए विषाणू आणि गेंडविषाणू सारख्या श्वसन मार्गाच्या इतर रोगजनकांशी संसर्गापासून वेगळी करता येत नाहीत.\n",
            "SARS रुग्णांमध्ये, असे दिसून आले आहे की ताप (99%-100%), कोरडा खोकला (29%-75%), डिस्प्निया (40%-42%), अतिसार (20-25%) आणि घसा खवखवणे (13-25%) ही प्रमुख लक्षणे होती आणि अंदाजे 14%-20% रुग्णांसाठी हवेशीर सहाय्य आवश्यक होते.\n",
            "व्हायरल आरएनए जीनोम व्हायरल जीनोमच्या प्रतिकृतीनंतर सायटोप्लाझममध्ये सोडला जातो, आवरण ग्लायकोप्रोटीन आणि न्यूक्लियोकॅप्सिड प्रोटीनसह जीनोमिक आरएनए विषाणूयुक्त वेसिकल्स तयार करतात, जे नंतर विषाणूला सोडण्यासाठी प्लाझ्मा झिल्लीसह एकत्र होतात.\n",
            "अमेरिकेच्या नॅशनल इन्स्टिट्यूट ऑफ अॅलर्जी अँड इन्फेक्शियस डिसीजचे संचालक डॉ. अँथनी फौसी यांनी या उद्रेकाविषयी सांगितले, \"सर्वात शेवटी सांगायचे झाल्यास परिस्थिती आणखी बिघडणार आहे.\n",
            "न्यूक्लियोटाइड अनुक्रमाच्या पातळीवर उच्च होमोलॉजीची विभागणी करणाऱ्या जवळच्या पूर्वजाला आश्रय दिल्यास एखादा प्राणी एचसीओव्हीचे उत्क्रांतीवादी यजमान म्हणून कार्य करतो.\n",
            "राष्ट्राच्या आरोग्य एजन्सीने 20 फेब्रुवारीला पुष्टी झालेल्या प्रकरणांमध्ये लक्षणीय वाढ झाल्याचा अहवाल दिला, ज्यासाठी प्रामुख्याने शिंचियोनजी चर्च ऑफ जीसस म्हणून ओळखल्या जाणाऱ्या एका नवीन धार्मिक चळवळीच्या डेगुमध्ये झालेल्या मेळाव्याला जबाबदार ठरवण्यात आले.\n",
            "नवीन एचसीओव्हीचा उदय: ग्राउंड झीरोकडे परत\n",
            "एचसीओव्हीच्या झूनोटिक उत्पत्तीचा शोध घेणे हा नैसर्गिक इतिहास, ड्रायव्हिंग फोर्स आणि प्रजाती उडी मारण्याच्या निर्बंध घटकांना समजून घेण्यासाठी एक चौकट प्रदान करतो.\n",
            "तेथे, एम प्रथिने न्यूक्लियोकॅप्सिडला बांधल्यानंतर विषाणूंच्या जोडणीसाठी आवश्यक बहुतेक प्रथिने-प्रथिने परस्परसंबंध निर्देशित करतात.\n",
            "तेव्हापासून, एचसीओव्ही-२२९ई आणि एचसीओव्ही-ओसी४३ वरील व्यापक अभ्यासाद्वारे अधिक ज्ञान गोळा केले गेले, जे दोन्ही स्व-मर्यादित लक्षणे निर्माण करतात.\n",
            "असे असूनही, विषाणूचा संसर्ग झालेल्या बहुतेक व्यक्ती विषाणूचा संसर्ग करत नसल्याने, विषाणूचा प्रसार मनुष्यापासून मनुष्यापर्यंत होण्यास अडचण निर्माण झाल्याचे दिसते.\n",
            "छातीत दुखण्यासारखा हा दाब\n",
            "मानवांना या विषाणूचा संसर्ग कसाई खाण्याद्वारे आणि मांसाहार करण्याद्वारे होतो.\n",
            "विष्ठेमुळे पसरण्याची चिंता असली तरी हा धोका कमी आहे असे मानले जाते.\n",
            "म्हणूनच, आरोग्य सेवा संस्थांनी त्यांच्या सेवांना प्राधान्य देण्यासाठी, विशेषतः संसाधनांची कमतरता असलेल्या भागात या आजारासाठी एक पूर्वसूचना मॉडेल तयार करणे आवश्यक आहे.\n",
            "व्हायरस इतर अवयवांमध्ये ACE2-व्यक्त करणाऱ्या पेशींना देखील बांधतो का?\n",
            "हा डॉक्टर पोर्टर आहे आपत्कालीन कक्ष ट्रायएज सेंटरमध्ये\n",
            "अमेरिकेमध्ये, सीडीसीने कपड्यांपासून बनवलेल्या नॉन-मेडिकल फेस मास्क वापरण्याची शिफारस केली आहे. चीनने विशेषतः इतर लोकांशी (1 मीटर (3 फूट) किंवा त्यापेक्षा कमी) जवळच्या संपर्कात येताना जनतेच्या निरोगी सदस्यांनी डिस्पोजेबल मेडिकल मास्क वापरण्याची शिफारस केली आहे.\n",
            "दीर्घता, दाट वस्ती, जवळचा सामाजिक संपर्क आणि उड्डाणाची प्रबळ क्षमता ही सर्व वटवाघळांसाठी आदर्श 'व्हायरस स्प्रेडर' होण्यासाठी अनुकूल परिस्थिती आहेत.\n",
            "न्युमोनिया हा सर्वात गंभीर लक्षणांपैकी एक आहे आणि तीव्र श्वसन त्रास सिंड्रोममध्ये वेगाने प्रगती करू शकतो.\n",
            "जानेवारीच्या उत्तरार्धात, चिनी सरकारने एक क्रांतिकारी मोहीम सुरू केली ज्याला नंतर चिनी कम्युनिस्ट पार्टीचे सरचिटणीस शी जिनपिंग यांनी विषाणूचा प्रसार रोखण्यासाठी \"लोकयुद्ध\" असे संबोधले.\n",
            "युक्रेनमधील आंदोलकांनी युक्रेनमधील वुहान येथून नोवी संझारीकडे जाणाऱ्या युक्रेनियन आणि परदेशी नागरिकांना घेऊन जाणाऱ्या बसेसवर हल्ला केला.\n",
            "काल बांगलादेशने कोविड-19 मुळे पाच नवीन मृत्यूंची पुष्टी केली आहे.\n",
            "या मागणीमुळे सामान्य किंमतीच्या किमतीत वीस पटीने वाढ झाली आणि चार ते सहा महिन्यांसाठी वैद्यकीय वस्तूंच्या पुरवठ्यात विलंब झाला.\n",
            "जेव्हा आजाराचा प्रसार रोखणे आता शक्य नाही, तेव्हा प्रयत्न कमी करण्याच्या टप्प्यावर जातातः प्रसार कमी करण्यासाठी आणि आरोग्य सेवा प्रणाली आणि समाजावरील त्याचे परिणाम कमी करण्यासाठी उपाययोजना केल्या जातात.\n",
            "15 मार्चपासून सुरू झालेल्या या विषाणूचा प्रसार कमी करण्यासाठी अमेरिकेतील अनेक व्यवसाय बंद करण्यात आले किंवा त्यांचे तास कमी करण्यात आले.\n",
            "हा आकडा प्रांतानुसार बदलतो.\n",
            "त्यानंतर प्रजननक्षम विषाणू पेशीतून एक्सोसायटोसिसद्वारे स्रावाच्या पुटीतून बाहेर पडतात.\n",
            "राष्ट्राध्यक्ष हसन रुहानी यांनी 26 फेब्रुवारी 2020 रोजी सांगितले की या उद्रेकामुळे प्रभावित झालेल्या भागात विलगीकरण करण्याची कोणतीही योजना नाही आणि फक्त व्यक्तींना विलगीकरण केले जाईल.\n",
            "त्यामुळे, सुरुवातीच्या टप्प्यात किंवा इन्क्युबेशन कालावधीत संक्रमित रुग्ण दैनंदिन व्यवहारांमध्ये मोठ्या प्रमाणात विषाणूचे उत्पादन करू शकतात, ज्यामुळे साथीच्या नियंत्रणासाठी मोठी अडचण निर्माण होऊ शकते.\n",
            "एचसीओव्ही-एचकेयू१ आणि एचसीओव्ही-ओसी४३ या दोन्हीमध्ये नैसर्गिक पुनर्संयोजनाचे जनुकीय पुरावे सापडले आहेत, तसेच प्राणी सीओव्ही जसे की बॅट एसएल-सीओव्ही आणि बॅट सीओव्ही-एचकेयू९.\n",
            "फार्मास्युटिकल विकासाशी संबंधित उच्च अपयशाच्या दरांना 'अॅट्रिशन रेट' म्हणून ओळखले जाते, महाग अपयश टाळण्यासाठी ड्रग डेव्हलपमेंटच्या सुरुवातीच्या टप्प्यातील निर्णयांची आवश्यकता असते.\n",
            "SARS-CoV-2 चा अंदाजे सरासरी उष्मायन कालावधी 1-14 दिवस आहे, बहुतांश 3-7 दिवस वुहानमधील पहिल्या 425 प्रकरणांच्या अभ्यासावर आधारित आहे.\n",
            "वुहानमधून प्रवास करणाऱ्या लोकांसाठी दुबई, सिडनी आणि मेलबर्न हे लोकप्रिय ठिकाण असल्याचेही सांगण्यात आले.\n",
            "आणि हीच योग्य वेळ आहे का तुमच्या पराग तापासाठी?\n",
            "13 मार्च पर्यंत, द अटलांटिक ने अहवाल दिला की 14,000 पेक्षा कमी चाचण्या घेण्यात आल्या आहेत.\n",
            "SARS-CoV-2 च्या झ्यूनोटिक उत्पत्तीबद्दल अद्याप ज्युरी बाहेर आहे.\n",
            "इबोला व्हायरसमुळे सुरुवातीला पाच लाख लोकांचा मृत्यू होण्याची शक्यता वर्तवण्यात आली होती.\n",
            "कॉर्पोरेशनने कर्मचाऱ्यांच्या प्रवासावर निर्बंध लादले, कॉन्फरन्स रद्द केल्या आणि कर्मचाऱ्यांना घरून काम करण्यास प्रोत्साहित केले.\n",
            "सीबीएस न्यूजने जॉन्स हॉपकिन्स विद्यापीठाच्या आकडेवारीचा हवाला देत सांगितले की, बुधवारी कोरोनामुळे १, ००० पेक्षा जास्त लोकांचा मृत्यू झाला.\n",
            "\"कोलकातातील चिनी दूतावासाने नंतर या वक्तव्याचा निषेध केला आणि त्याला\" \"चुकीचा\" \"असे म्हटले. चीनमध्ये, परदेशी रहिवाशांना या साथीच्या आजाराने भडकवले गेले आहे, परदेशी\" \"विदेशी कचरा\" \"म्हणून वर्णन केले गेले आणि\" \"विल्हेवाट लावण्यासाठी\" \"लक्ष्य केले गेले.\"\n",
            "पॉलीप्रोटीनची पुढील प्रक्रिया 16 नॉन-स्ट्रक्चरल प्रथिने तयार करण्यासाठी केली जाते, ज्याला nsp1 ~ 16 असे नाव देण्यात आले आहे.\n",
            "इतर व्हायरल रोगांच्या उपचारांसाठी पूर्वी मंजूर झालेल्या अनेक संयुगांवर COVID-19 च्या उपचारासाठी वापरण्यासाठी संशोधन केले जात आहे.\n",
            "COVID-19 प्रामुख्याने हुबेई आणि आसपासच्या भागात पसरला.\n",
            "वटवाघळांना सीओव्हीचा संसर्ग झाला तेव्हा लक्षणे नसलेली किंवा फक्त सौम्य लक्षणे आढळली, जी सीओव्ही आणि वटवाघळांमधील परस्पर अनुकूलता दर्शवते.\n",
            "मानवी हक्क संघटनांनी यापैकी काही उपाययोजनांवर टीका केली आहे, आणि सरकारांना आक्रमक डिजिटल देखरेख सुरू करण्यासाठी साथीच्या आजाराचा वापर एक आवरण म्हणून न करण्याची विनंती केली आहे.\n",
            "एचसीओव्ही-२२९ई, एचसीओव्ही-ओसी४३, एचसीओव्ही-एचकेयू१ आणि एचसीओव्ही-एनएल६३ सहसा सामान्य सर्दी आणि/किंवा अतिसार सारख्या सौम्य लक्षणांना कारणीभूत ठरतात.\n",
            "साथीच्या आजाराचा इतिहासः (1) वुहान शहर आणि आसपासच्या भागात किंवा इतर समुदायांमध्ये COVID-19 ची प्रकरणे लक्षणांची सुरुवात होण्यापूर्वी गेल्या 14 दिवसांमध्ये नोंदवलेली प्रवास किंवा निवासाचा इतिहास. (2) SARS-CoV-2 संसर्गजन्य प्रकरणांशी (पॉझिटिव्ह न्यूक्लिक अॅसिड टेस्टसह) संपर्काचा इतिहास. (3) वुहान शहर आणि आसपासच्या भागातील ताप किंवा श्वसन लक्षणे असलेल्या रुग्णांशी किंवा इतर समुदायांशी संपर्क साधण्याचा इतिहास जिथे लक्षणांची सुरुवात होण्यापूर्वी गेल्या 14 दिवसांमध्ये COVID-19 ची नोंद झाली होती.\n",
            "तुम्हाला उच्च रक्तदाबासारखं किंवा त्यासारखं काही जुनाट आहे का?\n",
            "याव्यतिरिक्त, प्रतिबंधक नैसर्गिक किलर सेल रिसेप्टर NKG2/CD94 आणि प्रमुख हिस्टोकॉम्पॅटिबिलिटी कॉम्प्लेक्स क्लास I रेणूंच्या कमी अभिव्यक्ती पातळीमुळे वटवाघळांमधील नैसर्गिक किलर सेल क्रियाकलाप दडपला जातो.\n",
            "दुसरीकडे, एचसीओव्ही-२२९ई हा दुसऱ्या वटवाघळाच्या सीओव्हीशी जनुकीयदृष्ट्या संबंधित होता, ज्याला हिप्पोसिडेरोस/घानाक्वाम/१९/२००८ असे म्हणतात, जो घानामध्ये आढळला होता, तर उंटांनाही त्याचे मध्यवर्ती यजमान म्हणून संशय होता.\n",
            "प्राणी हा विषाणू मानवांमध्ये संक्रमित करू शकतात याचा कोणताही पुरावा नाही, जरी ब्रिटिश अधिकाऱ्यांनी प्राण्यांच्या संपर्कात आल्यानंतर हात धुण्याचा सल्ला दिला आहे, जसे की इतर पृष्ठभागांशी संपर्क आल्यानंतर संक्रमित लोकांना स्पर्श करता आला असता.\n",
            "सार्वजनिक वाहतूक वापरताना किंवा गर्दीच्या ठिकाणी राहताना सर्जिकल मास्क घालण्याचा सल्ला हाँगकाँगने दिला आहे.\n",
            "जागतिक आरोग्य संघटनेने (WHO) 11 मार्चला COVID-19 ला महामारी म्हणून घोषित केलं आहे.\n",
            "मृतांमध्ये दोन जण ढाक्यातील असल्याचंही त्यांनी सांगितलं.\n",
            "आणि त्यांनाही ताप येत आहे\n",
            "बरे झालेल्या रुग्णांच्या प्लाझ्माचाही उपचारांसाठी वापर करण्याचा प्रस्ताव ठेवण्यात आला होता.\n",
            "खरेतर, क्रायो-ईएम अभ्यास मानवी एसीई 2 आणि सार्स-सीओव्ही एस प्रथिनांच्या तुलनेत 10 ते 20 पट अधिक आत्मीयता दर्शवतो.\n",
            "स्टेरॉईडचा वापर परिणाम खराब करू शकतो.\n",
            "उष्णकटिबंधीय हवामानात विशिष्ट ऋतूला प्राधान्य नसते.\n",
            "प्राण्यांमधील सीओव्ही-होस्ट संवादांचा तपास केल्यास मानवांमध्ये सीओव्ही पॅथोजेनेसिसविषयी महत्त्वाची माहिती मिळू शकते.\n",
            "SARS साठी प्राण्यांच्या मॉडेल्समध्ये लाईव्ह-अटेन्यूएटेड लसींचे मूल्यांकन करण्यात आले आहे.\n",
            "कला आणि संस्कृती क्षेत्रातील संघटनांनी समुदायाला सांस्कृतिक वारसा उपलब्ध करून देण्यासाठी, त्यांच्या कर्मचारी आणि जनतेची सुरक्षा राखण्यासाठी आणि शक्य असल्यास कलाकारांना पाठिंबा देण्यासाठी त्यांचे (बर्याचदा सार्वजनिक निधी) अभियान कायम ठेवण्याचा प्रयत्न केला.\n",
            "सध्या, SARS-CoV-2 ला प्रतिकारशक्ती प्रतिसाद देण्याबाबत सविस्तर अभ्यास करण्यात आलेला नाही.\n",
            "एकीकडे, SARS-CoV-2 संसर्ग अशी वैशिष्ट्ये दर्शवितो जी संसर्गाच्या वेळी सामान्यतः समुदायाने अधिग्रहीत केलेल्या HCoV सह आढळतात, ज्यात नॉन-स्पेसिफिक, सौम्य किंवा अगदी कोणतीही लक्षणे नसणे देखील समाविष्ट आहे.\n",
            "सार्स-सीओव्ही-2 च्या उद्रेकामुळे सीओव्ही पुन्हा चर्चेत आले आहेत.\n",
            "व्हाईट हाऊस कोरोना व्हायरस टास्क फोर्सची स्थापना 29 जानेवारीला करण्यात आली होती.\n",
            "आणि तुमच्या मधुमेहाच्या इतिहासासह\n",
            "दुसरीकडे, लॅटिन अमेरिका आणि आफ्रिकेच्या काही भागांमध्ये चीनच्या मदतीला चांगला प्रतिसाद मिळाला आहे. 2 एप्रिल रोजी, जागतिक बँकेने विकसनशील देशांसाठी आपत्कालीन मदत मोहीम सुरू केली.\n",
            "त्यानंतर या नकारात्मकता-संवेदी उपजिनोमिक आरएनए रेणूंचे त्यांच्या संबंधित सकारात्मक-संवेदी एमआरएनएमध्ये प्रतिलेखन केले जाते.\n",
            "गंभीर COVID-19 संसर्ग झालेल्या रूग्णांच्या ग्लोबल सॉलिडॅरिटी आणि युरोपियन डिस्कव्हरी चाचण्या चार प्रायोगिक उपचारात्मक धोरणांचा उगम झाल्यामुळे चाचणीचे मापदंड वेगाने बदलण्यासाठी अनुकूल डिझाइन लागू करतात.\n",
            "ही आकडेवारी कालबद्ध नाही आणि केस रेझोल्यूशनद्वारे संसर्गापासून विशिष्ट लोकसंख्येचे पालन करते.\n",
            "सार्सच्या उद्रेकाच्या सुरुवातीच्या टप्प्यात, सतत नैराश्य, चिंता, घाबरण्याचे आजार, सायकोमोटर उत्साह, मानसिक लक्षणे, उन्माद आणि अगदी आत्महत्या यासह अनेक मानसिक आजारांची नोंद झाली.\n",
            "शक्य असल्यास, आम्ही COVID-19 ची तुलना SARS आणि आणखी एक CoV-मुळे होणारा आजार, मिडल ईस्ट रेस्पिरेटरी सिंड्रोम (MERS, 2012 मध्ये उद्रेक) यांच्याशी करण्याचा प्रयत्न करू.\n",
            "ते प्रकाशित झाल्यापासून त्याकडे सर्वांचे लक्ष लागले आहे.\n",
            "विषाणूच्या रिबोन्यूक्लिक ऍसिडचे पुनरुत्पादन करण्यासाठी यजमान पेशीसाठी हे एंजाइम आवश्यक आहे.\n",
            "COVID-19 चा तरुणांपेक्षा वृद्ध व्यक्तींवर आणि महिलांपेक्षा पुरुषांवर जास्त परिणाम होतो, आणि तरुणांपेक्षा वृद्ध व्यक्तींमध्ये तीव्रता आणि मृत्यूदर देखील जास्त असतो.\n",
            "तथापि, रुग्ण गंभीर आजारी असताना SARS-CoV चा प्रसार होतो असे मानले गेले होते, तर बहुतांश संक्रमण सुरुवातीच्या टप्प्यात झाले नाही.\n",
            "रिपर्पस्ड अँटीव्हायरल ड्रग्ज बहुतांश चिनी संशोधन बनवतात, एप्रिलच्या अखेरीस अहवालामुळे अनेक देशांमध्ये रेमडेसिविरवर 9 टप्पा III चाचण्या केल्या जातात.\n",
            "जपानने एक दशलक्ष फेस मास्क वुहान, तुर्कीला वैद्यकीय उपकरणे पाठवली, रशियाने वुहानला 13 टनांहून अधिक वैद्यकीय पुरवठा पाठवला, मलेशियाने चीनला 18 दशलक्ष वैद्यकीय ग्लोव्हज देण्याचे जाहीर केले, जर्मनीने 10,000 हॅजमेट सूटसह विविध वैद्यकीय पुरवठा केला आणि अमेरिकेने चीनला 17.8 टन वैद्यकीय पुरवठा केला आणि बाधित देशांना अतिरिक्त 100 दशलक्ष डॉलर्सची आर्थिक मदत देण्याचे आश्वासन दिले.\n",
            "22 मार्च रोजी, असोसिएटेड प्रेसने अहवाल दिलाः \"लक्षणे आणि डॉक्टरांचा आदेश असलेल्या अनेक लोकांनी चाचणीसाठी तास किंवा दिवस वाट पाहिली आहे.\" 29 फेब्रुवारीला वॉशिंग्टन राज्यात पहिल्या मृत्यूची नोंद झाल्यानंतर, गव्हर्नर जे इन्स्ली यांनी आणीबाणी जाहीर केली, जी कृती लवकरच इतर राज्यांनी पाळली.\n",
            "एचसीओव्ही-२२९ई चा संसर्ग झालेल्या रुग्णांना डोकेदुखी, शिंकणे, आजार आणि घसा खवखवणे यासह सामान्य सर्दी लक्षणे आढळतात, १०-२०% प्रकरणांमध्ये ताप आणि खोकला दिसून येतो.\n",
            "एनटी न्यूजच्या गुरुवारी आवृत्तीत, डार्विनमध्ये छापल्या जाणाऱ्या दैनंदिन आवृत्तीत आठ पानांचा समावेश होता, जो कापण्यासाठी आणि टॉयलेट पेपर म्हणून वापरण्यासाठी होता.\n",
            "याचा अर्थ असा आहे की देशांकडे इटलीपेक्षा कमी किंवा जास्त संसाधने असू शकतात (2010-11 मध्ये प्रति 100,000 लोकसंख्येमागे 12.5 इंटेंसिव्ह केअर आणि इंटरमीडिएट केअर बेड).\n",
            "पाच सर्जिकल मास्क एकत्र जोडल्यावरही कण प्रवेश करू शकतात, त्यामुळे रुग्णांच्या थेट संपर्कात असलेल्या आरोग्य सेवा पुरवठादारांनी N95 (मालिका #1860) मास्क घातले पाहिजेत, पण सर्जिकल मास्क घातले नाहीत.\n",
            "माझ्या छातीत आहे.\n",
            "अनेक शहरांमध्ये सार्वजनिक हालचालींवर नियंत्रण आणण्यात आले आणि अंदाजे 760 दशलक्ष लोकांना (लोकसंख्येच्या अर्ध्याहून अधिक) बाहेरील निर्बंधांचा सामना करावा लागला. मार्चमध्ये हा उद्रेक जागतिक स्तरावर पोहोचल्यानंतर चिनी अधिकाऱ्यांनी इतर देशांमधून विषाणू 'आयात' करण्यापासून रोखण्यासाठी कठोर उपाययोजना केल्या.\n",
            "तथापि, कोरोनाव्हायरस आजार 2019 (COVID-19) हा एक नवीन आजार आहे, चालू संशोधन निष्कर्ष आणि क्लिनिकल प्रॅक्टिस अनुभवाच्या आधारे आमची जागरूकता आणि ज्ञान हळूहळू वाढत आहे.\n",
            "अनेक चिनी प्रदेशांमध्ये दूरस्थ कार्य उपाययोजना सुरू करण्यात आल्या.\n",
            "इटलीचा अनुभव आणि इतर देशांमधील सध्याचे कल हे दाखवतात की युरोपियन युनियन/ईईए आणि युकेमध्ये कोविड-19 महामारी वेगाने पुढे जात आहे.\n",
            "SARS, MERS आणि COVID-19 च्या आव्हानांसह, एक चांगली तयारी आणि प्रतिसाद योजना असावी.\n",
            "वुहान आणि हुबेई येथील अनेक रहिवाशांनी त्यांच्या प्रादेशिक मूळ आधारावर भेदभावाची तक्रार केली आहे.\n",
            "30 मार्चला प्रसिद्ध झालेल्या सांख्यिकीय विश्लेषणानुसार इटलीमध्ये संसर्गाच्या केसेसपेक्षा संसर्गाची संख्या बरीच जास्त होती.\n",
            "22 मार्च रोजी, इटलीचे पंतप्रधान ज्युसेपे कोंटे यांच्याशी फोन कॉलनंतर, रशियन राष्ट्राध्यक्ष व्लादिमीर पुतीन यांनी इटलीला लष्करी वैद्यकीय, विशेष निर्जंतुकीकरण वाहने आणि इतर वैद्यकीय उपकरणे पाठवण्यासाठी रशियन सैन्याची व्यवस्था केली.\n",
            "चिनी सरकारने 30 मार्चला व्यवसाय आणि कारखान्यांना पुन्हा उघडण्यास प्रोत्साहन दिले आणि कंपन्यांसाठी आर्थिक प्रोत्साहन पॅकेज दिले.\n",
            "शहरात खासगी वाहनांच्या वापरावर बंदी घातली आहे.\n",
            "सुमारे 200 देश आणि प्रदेशांमध्ये किमान एक प्रकरण समोर आले आहे.\n",
            "युरोपियन सेंटर फॉर डिसीज प्रिव्हेंशन अँड कंट्रोल (ईसीडीसी) म्हणते की हा आजार किती सहजपणे पसरतो हे पूर्णपणे स्पष्ट नसले तरी एक व्यक्ती सामान्यतः दोन ते तीन लोकांना संसर्ग करते.\n",
            "सुपर स्प्रेडर्स व्यतिरिक्त, असा अंदाज होता की प्रत्येक प्रकरणामुळे अंदाजे दोन दुय्यम प्रकरणे उद्भवू शकतात, ज्यामध्ये 4 ते 7 दिवसांचा इनक्युबेशन कालावधी आणि आजारपणाच्या 10 व्या दिवशी व्हायरल लोडचा उच्चांक दिसून येतो.\n",
            "हे घडण्यासाठी, एचसीओव्हींना मानवात पुरेशा प्रमाणात प्रतिकृती करावी लागेल जेणेकरून होस्ट प्रतिबंध घटकांना प्रतिकार करणाऱ्या अनुकूली उत्परिवर्तनांचा संचय होऊ शकेल.\n",
            "इम्युनोसप्रेसन्ट्स म्हणून स्टेरॉइड्सचा वापर सार्सच्या उपचारांमध्ये दाहक नुकसानाची तीव्रता कमी करण्यासाठी मोठ्या प्रमाणात केला जात होता.\n",
            "15 मार्च रोजी सकाळी 8:00 वाजल्याप्रमाणे, इतर 15 युरोपियन संघ/EEA देश आणि UK ने इटलीच्या तुलनेत फक्त 3 आठवड्यांपूर्वी किंवा त्यापेक्षा कमी कालावधीत एकूण प्रकरणांची नोंद केली होती.\n",
            "या उद्रेकामुळे 2020 च्या उन्हाळी ऑलिम्पिकची योजना विस्कळीत झाली, जी मूळतः जुलै अखेरीस सुरू होणार होती-आंतरराष्ट्रीय ऑलिम्पिक समितीने 24 मार्च रोजी जाहीर केले की ही स्पर्धा 2020 नंतरच्या तारखेपर्यंत पुन्हा आयोजित केली जाईल परंतु उन्हाळी 2021 पर्यंत नाही.\n",
            "तुम्हाला श्वास घेण्यास त्रास होत आहे का?\n",
            "MERS रुग्णांमध्ये अतिसार (26%) आणि घसा खवखवणे (21%) देखील आढळले.\n",
            "आरोग्य संघटनांनी अशी शिफारस केली आहे की खोकताना किंवा शिंकताना लोक आपले तोंड आणि नाक कोपराने किंवा टिश्यूने झाकतात आणि कोणत्याही टिश्यूची त्वरित विल्हेवाट लावतात.\n",
            "तर 3,64,000 लोक बरे झाले आहेत.\n",
            "कोरोना विषाणूंमुळे न्युमोनिया (थेट व्हायरल न्युमोनिया किंवा दुय्यम जीवाणू न्युमोनिया) आणि ब्रोंकायटिस (एकतर थेट व्हायरल ब्रोंकायटिस किंवा दुय्यम जीवाणू ब्रोंकायटिस) होऊ शकतात.\n",
            "1950 च्या दशकात, मानवी कोरोनाव्हायरस OC43 त्याच्या सध्याच्या जनुकीय प्रकारांमध्ये वेगळे होऊ लागले.\n",
            "एचसीओव्हीच्या प्राण्यांच्या उत्पत्तीची चर्चा करण्यापूर्वी, उत्क्रांतीवादी, नैसर्गिक, जलाशय, मध्यवर्ती आणि एचसीओव्हीच्या यजमानांच्या व्याख्या आणि वैशिष्ट्यांवर चर्चा करणे चांगले ठरेल.\n",
            "WHO ने मास्कचा वापर कधी आणि कसा करावा याबाबत सूचना जारी केल्या आहेत.\n",
            "त्यानंतर आणखी रुग्णांना हाताळण्यासाठी लेशेनशान रुग्णालय हे आणखी एक रुग्णालय बांधण्यात आले.\n",
            "6 फेब्रुवारी 2020 रोजी आमच्या पथकाने 2019 च्या नोवेल कोरोना विषाणूच्या (2019-nCoV) संसर्गाचे निदान आणि उपचारांसाठी जलद सल्लामसलत मार्गदर्शक सूचना प्रकाशित केल्या होत्या आणि या मार्गदर्शक सूचनांनी आपला अनुभव आणि जगभरातील या साथीच्या आजाराविरुद्ध लढण्यासाठी चांगला संदर्भ दिला होता.\n",
            "SARS-CoV-2 ची वैशिष्ट्ये SARS-CoV/MERS-CoV आणि चार समुदायाने अधिग्रहीत HCoV या दोन्हीसारखीच आहेत.\n",
            "त्यांच्या मार्गदर्शक सूचनांनुसार कोविड-19 संसर्गामुळे रुग्णालयात दाखल झालेल्या कोणत्याही गरोदर व्यक्तीला रुग्णालयातून डिस्चार्ज दिल्यानंतर किमान 10 दिवसांच्या रोगप्रतिबंधक कमी-अणू-वजनाच्या हेपरिन देण्यात याव्यात.\n",
            "मूळ आणि मध्यवर्ती यजमान\n",
            "जे लोक असे करत नाहीत, त्यांच्यासाठी लक्षणे विकसित होण्यापासून मृत्यूपर्यंत 6 ते 41 दिवसांचा कालावधी असतो, ज्यामध्ये सर्वात सामान्य 14 दिवस असतात.\n",
            "6 पुष्टी झालेल्या COVID-19 मातांचा समावेश असलेल्या एका छोट्याशा अभ्यासात त्यांच्या नवजात बाळाच्या घशात किंवा सीरममध्ये SARS-COV-19 चा कोणताही संकेत आढळला नाही, परंतु दोन बाळांच्या IGM सह नवजात बाळाच्या रक्त सेराच्या नमुन्यांमध्ये अँटीबॉडीज उपस्थित होत्या.\n",
            "गंभीर रुग्णांमध्ये, डी-डायमरची पातळी, रक्तामध्ये उपस्थित असलेल्या फायब्रिन डिग्रेडेशन उत्पादनाची पातळी वाढली होती आणि लिम्फोसायट्सची संख्या हळूहळू कमी झाली होती.\n",
            "23 जानेवारीला, वुहानमध्ये वाहतूक बंदी लागू करण्याच्या केंद्रीय अधिकाऱ्यांच्या निर्णयाच्या प्रतिक्रियेत, डब्ल्यूएचओचे प्रतिनिधी गॉडेन गॅलिया यांनी टिप्पणी केली की ही निश्चितपणे डब्ल्यूएचओने केलेली शिफारस नव्हती, \"ती ज्या ठिकाणी सर्वात जास्त केंद्रित आहे त्या ठिकाणी साथीचा प्रसार रोखण्याच्या वचनबद्धतेचा हा एक अतिशय महत्त्वाचा संकेत होता\" आणि त्याला \"सार्वजनिक आरोग्य इतिहासात अभूतपूर्व\" असे नाव देण्यात आले. 30 जानेवारीला, चीनबाहेर मानवी-ते-मानवी संक्रमणाची पुष्टी झाल्यानंतर आणि इतर देशांमध्ये प्रकरणांची वाढती संख्या लक्षात घेऊन डब्ल्यूएचओने उद्रेक हा आंतरराष्ट्रीय चिंताजनक सार्वजनिक आरोग्य आणीबाणी (PHEIC), 2009 च्या स्वाईन फ्लू साथीच्या पहिल्याच उपाय लागू केल्यापासून सहावा PHEIC चा उद्रेक जाहीर केला.\n",
            "या थेरपीमध्ये अँटीव्हायरल औषधे, इम्युनोसप्रेसन्ट्स, स्टेरॉईड्स, बरे झालेल्या रुग्णांकडून प्लाझ्मा, चिनी औषध आणि मानसिक पाठबळ असलेल्या सध्याच्या आणि संभाव्य उपचारांचा समावेश आहे.\n",
            "मेटाजेनोमिक सिक्वेंसिंगवर आधारित अनेक अलीकडील अभ्यासांनी असे सुचवले आहे की पॅंगोलिन (मॅनिस जॅवानिका) म्हणून ओळखल्या जाणाऱ्या लुप्तप्राय लहान सस्तन प्राण्यांचा एक गट देखील SARS-CoV-2 शी संबंधित पूर्वजांच्या बीटा-CoV ला आश्रय देऊ शकतो.\n",
            "ते मध्य पूर्व आणि आफ्रिकेत मोठ्या प्रमाणात पसरले आहेत.\n",
            "तुम्हाला सतत ताप येत राहिला तर\n",
            "पंतप्रधान ग्यूसेपे कोंटे म्हणाले, \"उद्रेक झालेल्या भागात प्रवेश आणि बाहेर पडण्याची सोय केली जाणार नाही.\n",
            "रशियाने भूराजकीय आणि राजनैतिक आकर्षण आक्रमण सुरू केल्याचा आरोप सूत्राने केला.\n",
            "याव्यतिरिक्त, यशस्वी यजमान स्विचची आवश्यकता आणि रोगाच्या तीव्रतेवर विषाणूच्या उत्क्रांतीचा परिणाम देखील अधोरेखित केला जातो.\n",
            "वूलवर्थच्या प्रवक्त्याने दिलेल्या माहितीनुसार, गेल्या आठवड्यात विक्रीत लक्षणीय वाढ झाली.\n",
            "विविध मार्गांद्वारे, विषाणू दाहक घटकांची अभिव्यक्ती, डेंड्रिटिक पेशींची परिपक्वता आणि प्रकार I इंटरफेरॉन्सचे (आयएफएन) संश्लेषण प्रेरित करतो जे विषाणूच्या प्रसाराला मर्यादित करतात आणि व्हायरल अँटीजेन्सच्या मॅक्रोफेज फॅगोसायटोसिसला गती देतात.\n",
            "SARS-CoV सहाय्यक प्रथिनांमध्ये, ORF8 हा मानवांशी जुळवून घेण्यात महत्त्वाचा मानला जातो, कारण SARS-CoV संबंधित वटवाघळांचे विषाणू वेगळे करण्यात आले होते परंतु ते वेगळे ORF8 प्रथिने एन्कोड करतात.\n",
            "मध्य चीनमध्ये विलगीकरणाचे प्रयत्न हाताळल्याबद्दल कम्युनिस्ट पार्टी ऑफ चायनाच्या (सीपीसी) अनेक प्रांतीय-स्तरीय प्रशासकांना बरखास्त करण्यात आले, जे त्या प्रदेशांमधील उद्रेकाबाबत राजकीय संस्थेच्या प्रतिसादाबद्दल असंतोषाचे लक्षण होते.\n",
            "अमेरिकेत अशी देखील शिफारस आहे की नवजात आणि मातांना संप्रेषण-आधारित खबरदारी बंद होईपर्यंत तात्पुरते वेगळे केले पाहिजे आणि जिथे हे शक्य नाही तिथे नवजात बाळाला आईपासून 2 मीटर अंतरावर ठेवले पाहिजे.\n",
            "फेब्रुवारीच्या अहवालांमध्ये (जेव्हा बहुतांश प्रकरणे अद्याप चीनपुरतीच मर्यादित होती) जगभरातील विविध गटांमध्ये व्यक्त करण्यात आलेल्या वांशिक भावनांची नोंद करण्यात आली आहे ज्यात विषाणूसाठी पात्र असलेल्या चिनी लोकांचा किंवा न्याय्य सूड घेण्याचा दावा करण्यात आला आहे.\n",
            "या अर्थाने, SARS-CoV-2 चा उद्रेक जितका जास्त काळ सुरू राहील आणि जितके जास्त लोक त्याचा संसर्ग करतील, तितकाच तो पूर्णपणे माणसांशी जुळवून घेण्याची जास्त शक्यता आहे.\n",
            "या परिवर्तनशीलतेमुळे नोंदवलेल्या केसेस डेथ रेटवर देखील लक्षणीय परिणाम होण्याची शक्यता आहे, जे काही देशांमध्ये लक्षणीयरित्या जास्त होण्याची शक्यता आहे.\n",
            "त्याचप्रमाणे, नोव्हेंबर 2002 पर्यंत सार्सचा मृत्यू दर 8,096 पुष्टी झालेल्या प्रकरणांपैकी 10% होता.\n",
            "चीनच्या जवळजवळ 300 दशलक्ष ग्रामीण स्थलांतरित कामगारांपैकी अनेकजण अंतर्गत प्रांतात घरी अडकले आहेत किंवा हुबेई प्रांतात अडकले आहेत. मार्च 2020 मध्ये, 10 दशलक्षहून अधिक अमेरिकन नागरिकांनी त्यांची नोकरी गमावली आणि सरकारी मदतीसाठी अर्ज केला.\n",
            "MERS ची क्लिनिकल अभिव्यक्ती SARS सारखीच दिसते, जी प्रगतीशील तीव्र न्युमोनियाने ओळखली जाते.\n",
            "प्रादुर्भावाच्या सुरुवातीच्या टप्प्यात प्रतिबंधात्मक उपाय हाती घेतले जातात आणि संसर्ग झालेल्यांचा शोध घेऊन त्यांना वेगळे करणे तसेच संसर्ग नियंत्रणाच्या इतर उपाययोजना सुरू करणे आणि उर्वरित लोकसंख्येत हा आजार पसरण्यापासून रोखण्यासाठी लसीकरण सुरू करणे हे उद्दीष्ट आहे.\n",
            "हाँगकाँगने अशी एक योजना तयार केली आहे जिथे संशयित रुग्ण घरी राहू शकतात, \"आपत्कालीन विभाग रुग्णाला एक नमुना ट्यूब देईल,\" ते त्यावर थुंकतील, परत पाठवतील आणि त्यानंतर थोड्या वेळाने चाचणी निकाल मिळवतील.\n",
            "उदाहरणार्थ, शू फेंग जी डू कॅप्सूल आणि लियन हुआ क्विंग वेन कॅप्सूल हे COVID-19 च्या उपचारांसाठी प्रभावी असल्याचे आढळले.\n",
            "डिसेंबर 2019 मध्ये, 2019 नोवेल कोरोनाव्हायरस (2019-nCoV) ने उद्रेक घडवून आणला आहे, ज्याला आता अधिकृतपणे कोरोनाव्हायरस रोग 2019 (COVID-19) असे नाव देण्यात आले आहे आणि या विषाणूला गंभीर तीव्र श्वसन सिंड्रोम कोरोनाव्हायरस 2 (SARS-CoV-2) असे नाव देण्यात आले आहे.\n",
            "मास्क, सॅनिटायझर, कोरड्या वस्तू, हँडवॉश आणि पीठ यासह इतर उत्पादनांना देखील मोठी मागणी आहे, असे रसेल झिमरमॅन यांनी सांगितले.\n",
            "कधी कधी छातीत दुखतं\n",
            "त्यांना चार गटात विभागले जाऊ शकते, म्हणजे अल्फा, बीटा, गामा आणि डेल्टा, ज्यापैकी अल्फा-आणि बीटा-सीओव्ही मानवांना संक्रमित करतात.\n",
            "त्यामुळे, बरे झालेल्या रुग्णांपासून बी पेशींना वेगळे करणे आणि विषाणूच्या आवश्यक प्रथिनांच्या विरोधात प्रभावी अँटीबॉडीज किंवा स्क्रीनसाठी प्रभावी अँटीबॉडीज एनकोडिंग करणारे जेनेटिक कोड ओळखणे अधिक गंभीर आणि व्यावहारिक आहे.\n",
            "अमेरिकेत सेलेक्सने विकसित केलेल्या सेरोलॉजिकल चाचणीला केवळ प्रमाणित प्रयोगशाळांद्वारे आपत्कालीन वापरासाठी मान्यता देण्यात आली आहे.\n",
            "इराणवरील अमेरिकेच्या निर्बंधांमुळे विषाणूच्या उद्रेकाला प्रतिसाद देण्याच्या देशाच्या आर्थिक क्षमतेवर परिणाम होऊ शकतो, असेही सुचवण्यात आले आहे.\n",
            "याउलट, SARS-CoV, MERS-CoV आणि नव्याने ओळखले गेलेले SARS-CoV-2 हे अत्यंत रोगजनक आहेत, ज्यामुळे एक्युट रेस्पिरेटरी डिस्ट्रेस सिंड्रोम (ARDS) आणि एक्स्ट्रापल्मोनरी एक्सप्रेशन होण्याची शक्यता असलेल्या तुलनेने जास्त रुग्णांमध्ये गंभीर कमी श्वसन मार्गाचा संसर्ग होतो.\n",
            "आतापर्यंत, MERS-CoV जंगली वटवाघळांमध्ये आढळत नाही.\n",
            "\"ते म्हणाले, फेब्रुवारीत सीएनएनने प्रकाशित केलेल्या टिप्पणीमध्ये,\" \"इन्फ्लुएन्झा व्यतिरिक्त, उद्भवलेल्या श्वसनाच्या विषाणूपासून सतत जागतिक प्रसारापर्यंत इतर कोणताही विषाणू आढळला नाही.\"\n",
            "\"प्रवासावरील निर्बंधांच्या अंमलबजावणीला प्रतिसाद देताना, टेड्रोस म्हणाले की\" \"आंतरराष्ट्रीय प्रवास आणि व्यापारामध्ये अनावश्यकपणे हस्तक्षेप करणाऱ्या उपाययोजनांसाठी कोणतेही कारण नाही\" \"आणि\" \"WHO व्यापार आणि हालचाली मर्यादित करण्याची शिफारस करत नाही.\"\n",
            "हे वगळणे ORF8 ला ORF8a आणि ORF8b मध्ये विभागते आणि हे होस्टच्या स्विचला प्रोत्साहन देणारे एक अनुकूली उत्परिवर्तन आहे असे मानले जाते.\n",
            "SARS-CoV-2 96.2% न्यूक्लियोटाइड होमोलॉजीचे राइनोलोफस अॅफिनिसच्या वटवाघळांपासून वेगळे केलेल्या वटवाघळांच्या RaTG13 सह विभाजन करते.\n",
            "\"परिणामी संयुक्त राष्ट्रांच्या संपूर्ण प्रतिसादाच्या समन्वयाने संयुक्त राष्ट्र आपत्ती व्यवस्थापन पथक सक्रिय करण्यात आले, ज्यामुळे डब्ल्यूएचओ राज्ये त्यांना\" \"आरोग्य प्रतिसादावर लक्ष केंद्रित करण्यास परवानगी देतील, तर इतर संस्था प्रादुर्भावाच्या व्यापक सामाजिक, आर्थिक आणि विकासात्मक परिणामांवर आपले कौशल्य आणू शकतात.\"\n",
            "हे चारही समुदाय-अधिग्रहीत एचसीओव्ही मानवांशी चांगल्या प्रकारे जुळवून घेतले गेले आहेत आणि सामान्यतः उच्च रोगजनक आजारांसाठी उत्परिवर्तन होण्याची शक्यता कमी असते, जरी दुर्मिळ कारणांमुळे एचसीओव्ही-एनएल६३ च्या अधिक विषाणू उपप्रकाराच्या दुर्मिळ प्रकरणांमध्ये अपघात होतात, ज्यामुळे नुकतेच चीनमध्ये गंभीर कमी श्वसन मार्गाचा संसर्ग झाल्याची नोंद झाली आहे.\n",
            "आयईडीसीआरच्या संचालक डॉ. मीरजादी सेब्रिना फ्लोरा यांनी ऑनलाइन पत्रकार परिषदेत सांगितले की, मृतांमध्ये चार पुरुष आणि एका महिलेचा समावेश आहे.\n",
            "MERS-CoV आणि त्याच्या जवळच्या नातेवाईक बॅट CoV-HKU25 फक्त 87% न्यूक्लिओटाइड अनुक्रम होमोलॉजी शेअर करतात.\n",
            "5 मार्च 2020 च्या युरोसर्व्हिलेन्स 2020 च्या अंकात, WHO च्या प्रकरणाच्या व्याख्येनुसार पहिल्या युरोपियन पुष्टीकृत COVID-19 प्रकरणांवर अहवाल देण्यात आला.\n",
            "सामान्यतः, जेव्हा हे एचसीओव्ही कार्यक्षमतेने संचरिण्याची क्षमता प्राप्त करतात आणि मानवांमध्ये स्वतःला सतत टिकवून ठेवतात, तेव्हा ते कमी विषाणू किंवा रोगजनक देखील बनतात.\n",
            "सायलोडाक्रायडेनिटिस व्हायरस (SDAV) हा प्रयोगशाळेतील उंदरांचा अत्यंत संसर्गजन्य विषाणू आहे, जो व्यक्तींमध्ये थेट संपर्काद्वारे आणि अप्रत्यक्षपणे एरोसोलद्वारे प्रसारित होऊ शकतो.\n",
            "सायटोकिन वादळांच्या उपचारांमध्ये, विशेषतः गंभीर रुग्णांमध्ये इम्युनोसप्रेशन आवश्यक आहे.\n",
            "चीनमधील एका मोठ्या अभ्यासाने छातीच्या CT निकालांची तुलना PCR शी केली आणि हे दाखवून दिले की जरी संसर्गासाठी इमेजिंग कमी विशिष्ट आहे, तरीही ते वेगवान आणि अधिक संवेदनशील आहे, जे साथीच्या क्षेत्रांमध्ये स्क्रीनिंग टूल म्हणून त्याचा विचार सुचवते.\n",
            "तथापि, COVID-19 ची तीव्रता आणि मृत्यू सार्सपेक्षा कमी आहे, परंतु ते संसर्गजन्य आहे आणि तरुणांपेक्षा वयोवृद्ध व्यक्तींवर आणि महिलांपेक्षा पुरुषांवर अधिक परिणाम करते.\n",
            "आणि जर्मनी, ऑस्ट्रिया आणि स्वित्झर्लंड आणि चेक रिपब्लिक आणि इटलीसारख्या इतर देशांमध्ये मास्कशी संबंधित वाद झाल्याची माहिती समोर आली आहे.\n",
            "सेल्युलर रिसेप्टर्स व्यतिरिक्त, एचसीओव्हीच्या आंतरप्रजाती संक्रमणाचा परिणाम देखील इतर यजमान अवलंबन आणि प्रतिबंध घटकांद्वारे नियंत्रित केला जातो.\n",
            "सिएटल परिसरातील शाळांनी 3 मार्चला वर्ग रद्द केले, आणि मार्चच्या मध्यापर्यंत देशभरातील शाळा बंद पडत होत्या. 6 मार्च 2020 रोजी, इंपीरियल कॉलेज लंडनमधील साथीच्या तज्ज्ञांच्या गटाने अमेरिकेला नवीन कोरोनाविषाणूचा देशावर होणारा परिणाम काय असेल याचा अंदाज काढण्याचा सल्ला दिला होता.\n",
            "अनेक वैज्ञानिक प्रकाशकांनी या उद्रेकाशी संबंधित वैज्ञानिक कागदपत्रे ओपन ऍक्सेससह उपलब्ध करून दिली.\n",
            "बीजिंगमधील निषिद्ध शहर आणि पारंपारिक मंदिराच्या मेळाव्यांसह मोठ्या प्रमाणात गर्दी होऊ नये म्हणून अनेक चंद्र नववर्षाचे कार्यक्रम आणि पर्यटन आकर्षणे बंद करण्यात आली आहेत.\n",
            "सुरुवातीच्या गर्भधारणेबाबत अद्याप कोणतीही माहिती समोर आलेली नाही.\n",
            "\"\" \"पॅनडेमिक\" \"हा शब्द केवळ एखाद्या आजाराचा प्रसार किती व्यापक प्रमाणात झाला आहे याचा संदर्भ देत असला तरी, विशिष्ट प्रकरणे किती धोकादायक आहेत याचा संदर्भ देत नसला तरी, डब्ल्यूएचओने सरकारांना कारवाईसाठी प्रवृत्त करण्याची आवश्यकता लक्षात घेतली आहेः\"\n",
            "SARS-CoV, MERS-CoV आणि SARS-CoV-2 या विषाणूंचा उगम वटवाघळांपासून झाला आहे आणि ते मध्यवर्ती यजमानांमार्फत मानवांमध्ये संक्रमित होतात, हे पारवेसिव्ह पुराव्यांवरून दिसून आले आहे.\n",
            "इतर काही लक्षणं दिसतात का?\n",
            "चाचणी केलेल्या औषधांच्या सुरक्षा आणि परिणामकारकतेवरील निर्णयांमध्ये मदत करण्यासाठी आणि चाचणी डिझाइनमध्ये बदल करण्यासाठी किंवा प्रभावी उपचाराची शिफारस करण्यासाठी डब्ल्यूएचओ डॉक्टरांचे जागतिक सुरक्षा देखरेख मंडळ अंतरिम निकालांची तपासणी करते.\n",
            "एचसीओव्ही-एनएल63 हा अवरोधी स्वरयंत्राचा संसर्ग आहे, ज्याला खवखवणे असेही म्हणतात.\n",
            "सार्स-सीओव्ही आणि मर्स-सीओव्हीच्या तुलनेत सार्स-सीओव्ही-२ हे स्पष्टपणे कमी रोगजनक आहे परंतु अधिक संसर्गक्षम आहे.\n",
            "COVID-19 साठी मूलभूत प्रजनन संख्या (R0) चा प्रारंभिक अंदाज 1.4 ते 2.4 होता.\n",
            "COVID-19 बद्दल अजून बरेच काही शोधणे बाकी आहे आणि ऑस्ट्रेलिया महामारीला प्रतिसाद देताना सीमा नियंत्रण आणि संप्रेषणावर जोर देईल असे त्यात म्हटले आहे.\n",
            "14 फेब्रुवारी 2020 पर्यंत, 2500 हून अधिक प्रयोगशाळेत पुष्टी झालेल्या प्रकरणांमध्ये 34.4% चा मृत्यू झाला होता, ज्यामुळे MERS-CoV हा मानवाला ज्ञात झालेला सर्वात विनाशकारी विषाणू बनला.\n",
            "एका महिन्यात हुबेईमध्ये कोरोनाबाधितांची संख्या हळूहळू वाढली.\n",
            "जागतिक आरोग्य संघटना आणि सेंटर फॉर डिसीज कंट्रोल अँड प्रिव्हेन्शन ऑफ युनायटेड स्टेट्स गरोदर महिलांना संसर्ग टाळण्यासाठी सर्वसामान्य लोकांसारखीच कामे करण्याचा सल्ला देतात, जसे की खोकला, आजारी लोकांशी संपर्क टाळा, साबण आणि पाण्याने हात धुवा किंवा सॅनिटायझर.\n",
            "ऑस्ट्रेलियात, साथीच्या आजाराने डेगू दुकानदारांना ऑस्ट्रेलियातील उत्पादनांची चीनमध्ये विक्री करण्याची नवीन संधी दिली.\n",
            "संशोधकांवर आधारित या सुधारणांनी काम चालू ठेवले की जलद निदानासाठी एक ऑप्टिमल न्यूक्लिक अॅसिड डिटेक्शन किट शोधण्यासाठी, तसेच रक्त नमुन्यासह श्वसन मार्गापासून नमुने शोधण्यासाठी, ज्यामुळे विविध नमुन्यांची उपलब्धता वाढली आणि निश्चित निकषांमध्ये विशिष्ट अँटीबॉडी पॉझिटिव्ह परिणाम आणण्यास मदत झाली.\n",
            "सीओव्ही आणि त्यांच्या नैसर्गिक यजमानांच्या पर्यावरणाची चांगली समज मिळवण्यासाठी सस्तन प्राण्यांमध्ये सातत्याने देखरेख ठेवणे आवश्यक आहे, जे प्राण्यांपासून मानवांमध्ये होणारा संसर्ग आणि भविष्यातील उद्रेक रोखण्यासाठी उपयुक्त ठरेल.\n",
            "माझ्या छातीच्या मधोमध वेदना होतात.\n",
            "संपूर्ण मानवी लोकसंख्येमध्ये सामान्यतः SARS-CoV-2 साठी रोगप्रतिकारशक्ती कमी असते आणि त्यामुळे नवीन विषाणूला बळी पडण्याची शक्यता असते.\n",
            "शेवटी, विषाणूजन्य झूनोसिस रोखण्याचा सर्वात प्रभावी मार्ग म्हणजे मानवांनी झूनोटिक विषाणूंच्या नैसर्गिक साठ्यांच्या पर्यावरणीय ठिकाणांपासून दूर राहणे.\n",
            "मानसिक तणावः वर नमूद केल्याप्रमाणे, कोविड-19 च्या उद्रेकादरम्यान अनेक रुग्णांना असाधारण तणावाचा सामना करावा लागला आहे कारण त्यांनी बर्याचदा विलगीकरण आणि प्रचंड अनिश्चितता सहन केली आहे आणि जवळच्या नातेवाईक आणि सह रुग्णांचा मृत्यू पाहिला आहे.\n",
            "ताप आणि खोकला, डोकेदुखी आणि स्नायू दुखण्याबाबतही अगदी असंच आहे\n",
            "उच्च रोगजनक एचसीओव्ही व्यतिरिक्त, एचसीओव्ही-229ई, एचसीओव्ही-ओसी43, एचसीओव्ही-एनएल63 आणि एचसीओव्ही-एचकेयू1 च्या झुनोटिक उत्पत्तीचाही अभ्यास करण्यात आला आहे.\n",
            "16 मार्च रोजी प्रकाशित झालेल्या एका अभ्यासात असे आढळून आले की चीनमध्ये 23 जानेवारीपर्यंत अंदाजे 86% COVID-19 संसर्ग आढळले नव्हते आणि हे अनधिकृत संसर्ग 79% दस्तऐवजीकृत प्रकरणांसाठी संसर्गाचा स्रोत होते.\n",
            "प्रस्थान करण्यापूर्वी वैद्यकीय तपासणी करण्यात आली आणि कोरोनाविषाणूची लक्षणे दिसणाऱ्या चार दक्षिण आफ्रिकन लोकांना धोका कमी करण्यासाठी मागे सोडण्यात आले.\n",
            "फार्मास्युटिकल कंपन्या विषाणूविरोधात अँटीबॉडीज आणि लस विकसित करण्यासाठी झगडत आहेत.\n",
            "याचा विरळपणे होणारा प्रसार हा एक अपघात आहे आणि MERS-CoV चा मृत-अंत यजमान मानच असतो कारण त्याचे संक्रमण टिकू शकत नाही.\n",
            "ओपन रीडिंग फ्रेम 1a आणि 1b, जे जीनोमच्या पहिल्या दोन तृतीयांश भाग व्यापतात, रेप्लिकेज/ट्रान्सक्रिप्टेज पॉलीप्रोटीन एनकोड करतात.\n",
            "या कृतींमुळे अर्थव्यवस्था आणि देशाच्या इतर क्षेत्रांना नाटकीयदृष्ट्या नुकसान होत असले तरी, नवीन रुग्णांची संख्या कमी होत आहे, जी साथीच्या आजाराची मंदी दर्शवते.\n",
            "23 मार्चपर्यंत, कोणत्याही देशाने त्यांच्या लोकसंख्येच्या 3% पेक्षा जास्त चाचण्या केल्या नव्हत्या, आणि देशांमध्ये किती चाचण्या केल्या गेल्या यात मोठ्या प्रमाणात फरक आहेत.\n",
            "हाँगकाँगने संसर्गजन्य रोगाच्या प्रतिसादाची पातळी सर्वोच्च पातळीवर नेली आणि आणीबाणी जाहीर केली, मार्च पर्यंत शाळा बंद ठेवल्या आणि नववर्षाचा उत्सव रद्द केला.\n",
            "असे करूनही, अमेरिकेत चाचणीची संथगतीने सुरुवात झाली, ज्यामुळे त्या वेळी उद्रेकाची खरी व्याप्ती अस्पष्ट झाली.\n",
            "या विषाणूंना प्राण्यांच्या साठवणुकीची गरज नाही.\n",
            "काहींनी असे सुचवले आहे की हा विषाणू हवेत जास्त काळ राहणाऱ्या लहान थेंबांद्वारेही प्रसारित होऊ शकतो, जे बोलताना निर्माण होऊ शकते.\n",
            "बाजारातील सिवेट आणि इतर प्राण्यांमध्ये SARS-CoV सारखेच विषाणू आढळले असले तरी SARS-CoV-2 साठी तात्काळ मध्यवर्ती होस्ट ओळखले गेले नाहीत.\n",
            "स्टेरॉईडचा वापर-वर वर्णन केल्याप्रमाणे, स्टेरॉईडचा वापर संसर्गजन्य रोगांसाठी सहसा संसर्गजन्य उपचार म्हणून केला जातो.\n",
            "COVID-19 च्या साथीची तुलना SARS आणि MERS शी खाली दिली आहे (चित्र-55).\n",
            "SARS-CoV-2 हा एक नवीन प्रकारचा बीटा-सीओव्ही असल्याचे आढळून आले होते, ज्यामध्ये 99.98% पेक्षा जास्त अनुवांशिक ओळख वुहानमधील हुआनान सीफूड मार्केटमधून संकलित केलेल्या 10 अनुक्रमित नमुन्यांपैकी होती.\n",
            "23 जानेवारीला वुहान शहर बंद करण्यात आलं आणि सर्व सार्वजनिक वाहतूक बंद करण्यात आली.\n",
            "दुसरे म्हणजे, एचसीओव्ही-२२९ई संबंधित वटवाघळांमध्ये अल्फा-सीओव्ही विविध आणि नॉन-पॅथोजेनिक असतात, तर अल्फा-सीओव्ही संसर्गित प्राण्यांमध्ये श्वसन रोगाचा उद्रेक करते.\n",
            "पण तू आत्ता श्वास घेत आहेस?\n",
            "2016 च्या आढाव्यात 106 औषध उमेदवारांचे क्लिनिकल ट्रायल्सच्या माध्यमातून मूल्यमापन करण्यात आले, तिसर्या टप्प्यातील यशस्वी चाचण्यांद्वारे मंजूर केलेल्या औषधाच्या उत्पादकासाठी एकूण भांडवली खर्च $2.6 अब्ज (2013 डॉलर्स मध्ये) होता, वार्षिक 8.5% च्या दराने रक्कम वाढली.\n",
            "5 मार्च 2020 पर्यंत LabCorp ने RT-PCR वर आधारित COVID-19 चाचणीची देशव्यापी उपलब्धता जाहीर केली.\n",
            "दोन घटकांचा वापर करून केल्या जाणाऱ्या चाचण्या 28 फेब्रुवारी 2020 पर्यंत विश्वासार्ह ठरत नव्हत्या, आणि तोपर्यंत राज्य आणि स्थानिक प्रयोगशाळांना चाचणी सुरू करण्याची परवानगी देण्यात आली नव्हती.\n",
            "मिश्रण पात्र म्हणून काम करणाऱ्या होस्टमध्ये, सीओव्ही आरएनए ट्रान्सक्रिप्शन दरम्यान स्ट्रँड स्विचिंग वारंवार होते.\n",
            "2020 च्या सुरुवातीला, COVID-19 चा आजार कमी करण्यासाठी नवीन क्लिनिकल संशोधन प्रयत्नांमध्ये इतर संसर्गावर उपचार करण्यासाठी अनेक स्थापित अँटीव्हायरल संयुगे पुन्हा तयार केली जात होती किंवा विकसित केली जात होती.\n",
            "बांगलादेशात कोव्हिड-19 संसर्गाची पहिली नोंद 8 मार्च रोजी इटलीहून परतलेल्या दोन व्यक्तींमध्ये आणि त्यातील एकाच्या पत्नीमध्ये झाली होती.\n",
            "Cases म्हणजे COVID-19 साठी चाचणी केलेल्या आणि अधिकृत प्रोटोकॉलनुसार चाचणी पॉझिटिव्ह आल्याची पुष्टी झालेल्या लोकांची संख्या.\n",
            "काही रुग्णांमध्ये अतिसार देखील दिसून येतो.\n",
            "जागतिक आरोग्य संघटनेने या साथीच्या आजाराचे व्यवस्थापन आणि नियंत्रण करण्याच्या चिनी अधिकाऱ्यांच्या प्रयत्नांची प्रशंसा केली आहे.\n",
            "ते त्यांच्या स्वतःच्या नैसर्गिक साठ्यांमध्ये राहतात जोपर्यंत गळती होण्याची शक्यता नसते.\n",
            "SARS-CoV-2 आणि पॅंगोलिन यांच्यातील RBDs मध्ये सर्वाधिक अनुक्रम होमोलॉजी आढळली आहे, तर SARS-CoV-2 संबंधित बीटा-CoV, SARS-CoV-2 आणि RATG-13 मध्ये सर्वाधिक अनुक्रम होमोलॉजी आढळली आहे.\n",
            "दुसरे म्हणजे, जर वटवाघळांची मानवी संक्रमणात अधिक थेट भूमिका असेल, तर मानव वटवाघळांच्या संपर्कात कसा येतो हे ठरवले पाहिजे.\n",
            "थायलंडचे आरोग्य अधिकारी लोकांना घरी कपड्यांचे फेस मास्क बनवण्यास आणि ते दररोज धुण्यास प्रोत्साहन देत आहेत.\n",
            "तथापि, नोंदवलेल्या केसेसची संख्या आणि मृत्यूच्या संख्येवर लक्ष केंद्रित करणाऱ्या सध्याच्या देखरेखीची आकडेवारी पूर्ण करण्यासाठी ते पद्धतशीरपणे गोळा केले पाहिजेत.\n",
            "विशेषतः, झूनोटिक क्षमता असलेल्या वटवाघळांचे CoV इतके वैविध्यपूर्ण आहेत.\n",
            "1 एप्रिल रोजी प्रसारमाध्यमांच्या वृत्तानुसार, दक्षिण कोरियाला 121 वेगवेगळ्या देशांकडून विषाणू चाचणी सहाय्यासाठी विनंती प्राप्त झाली आहे.\n",
            "सप्रेशनला अधिक कठोर उपायांची आवश्यकता असते जेणेकरून मूलभूत पुनरुत्पादन संख्या 1 पेक्षा कमी करून साथीच्या रोगाचे निराकरण केले जाऊ शकते. संसर्गजन्य रोगाचा उद्रेक होण्याचा भाग साथीचा उच्चांक कमी करण्याचा प्रयत्न करत आहे, ज्याला महामारी वक्र सपाट करणे म्हणतात.\n",
            "छातीत दुखत असल्याबद्दल सांगा\n",
            "सुपरमार्केट, फार्मसी, बँका, हार्डवेअरची दुकाने, पेट्रोल पंप आणि गॅरेज यांसारख्या अत्यावश्यक समजल्या जाणाऱ्या व्यवसायांना वगळून बहुतांश व्यवसाय बंद करण्याचे आदेश देण्यात आले होते.\n",
            "SARS-CoV-2 चा मध्यवर्ती आणि प्रवर्धित प्राणी यजमान (s) शोधण्यासाठी हे मार्गदर्शन करू शकते किंवा सुकर करू शकते, ज्याचा भविष्यातील गळती रोखण्यात महत्त्वपूर्ण परिणाम होऊ शकतात.\n",
            "ते प्राण्यांच्या यजमानांकडून आंतरप्रजाती संसर्गानंतर मानवांमध्ये या सीओव्हीच्या यशस्वी रूपांतरणासाठी देखील जबाबदार असू शकतात.\n",
            "याचे मूळ प्राणी आहे असे मानले जाते.\n",
            "21 फेब्रुवारीला लोम्बार्डीमध्ये 16 पुष्टी झालेल्या केसेससह कोविड-19 च्या केसेसचा एक असंबद्ध क्लस्टर नंतर आढळला. 22 फेब्रुवारीला, मंत्री परिषदेने हा उद्रेक रोखण्यासाठी नवीन आदेश-कायदा जाहीर केला, ज्यामध्ये उत्तर इटलीतील 11 वेगवेगळ्या नगरपालिकांमधील 50,000 हून अधिक लोकांना विलगीकरणात ठेवण्यात आले.\n",
            "त्याच दिवशी, यूएसएनएस कंफर्ट, सुमारे 1000 खाटांचे रुग्णालय जहाज, न्यूयॉर्कमध्ये लंगर तयार केले.\n",
            "काही संस्थांनी सिंड्रोमिक देखरेखीसाठी क्राउडसोर्स्ड अॅप्स तयार केले आहेत, जिथे लोक COVID-19 लक्षणांच्या एकाग्रतेसह संशोधकांना त्यांच्या लक्षणांचा नकाशा तयार करण्यास मदत करू शकतात.\n",
            "193 देशांमध्ये शाळा आणि विद्यापीठे एकतर देशव्यापी किंवा स्थानिक आधारावर बंद ठेवण्यात आली आहेत, ज्याचा परिणाम जगातील सुमारे 99.4 टक्के विद्यार्थी लोकसंख्येवर झाला आहे.\n",
            "इराणमध्ये उद्रेकाच्या उद्रेकाला प्रतिसाद म्हणून, WHO ने परिस्थितीचे मूल्यमापन करण्यासाठी तेथे एक संयुक्त मिशन पथक पाठवले. 28 फेब्रुवारी रोजी, WHO च्या अधिकाऱ्यांनी सांगितले की जागतिक पातळीवर कोरोना विषाणूच्या धोक्याचे मूल्यमापन \"उच्च\" वरून \"खूप उच्च\" पर्यंत वाढवले जाईल, जे त्याच्या सर्वोच्च पातळीवरील अलर्ट आणि जोखीम मूल्यांकन आहे.\n",
            "या अहवालापर्यंत, हा रोग चीनमध्ये आणि जगभरातील 50 इतर देशांमध्ये आधीच पसरला आहे (चित्र-2).\n",
            "इराणी संसद बंद करण्यात आली, त्यातील 290 सदस्यांपैकी 23 सदस्यांना 3 मार्च रोजी विषाणूची लागण झाल्याचे निष्पन्न झाले.\n",
            "RdRp थेट सकारात्मक-संवेदी जीनोमिक RNA पासून नकारात्मक-संवेदी जीनोमिक RNA च्या संश्लेषणात मध्यस्थी करते.\n",
            "इराणमध्ये उद्रेकाची व्याप्ती कव्हर-अप करण्याच्या दाव्यांच्या दरम्यान, दहाहून अधिक देशांनी 28 फेब्रुवारीपर्यंत त्यांचे रुग्ण इराणमध्ये शोधून काढले होते, जे सूचित करते की त्या तारखेपर्यंत इराण सरकारने नोंदवलेल्या 388 प्रकरणांपेक्षा उद्रेकाची व्याप्ती अधिक गंभीर असू शकते.\n",
            "अनेक वंश-विशिष्ट सहाय्यक प्रथिने देखील सीओव्हीच्या विविध वंशाद्वारे एनकोड केले जातात.\n",
            "सर्व देश अजूनही या साथीच्या आजाराचा मार्ग बदलू शकतात.\n",
            "सीओव्ही हे मोठ्या आणि आच्छादित विषाणूंचे एक उपकुटुंब आहे ज्यात सेन्स आरएनएचा एक स्ट्रँड असतो.\n",
            "ही चाचणी रिअल-टाईम रिव्हर्स ट्रान्सक्रिप्शन पॉलिमरेज चेन रिअॅक्शन (आरआरटी-पीसीआर) चा वापर करते.\n",
            "नव्या हॉटस्पॉट देशांमध्ये प्रादुर्भावाच्या प्रगतीनंतर, कोविड-19 चा गंभीर उद्रेक झालेला युरोपमधील पहिला देश असलेल्या इटलीच्या लोकांना देखील संशय आणि झेनोफोबियाचा सामना करावा लागू शकतो. मलेशिया, न्यूझीलंड, सिंगापूर आणि दक्षिण कोरियासह इतर देशांतील नागरिकांनी सुरुवातीला हा आजार रोखण्याच्या प्रयत्नात चिनी लोकांना त्यांच्या देशात प्रवेश करण्यापासून रोखण्यासाठी याचिकांवर स्वाक्षऱ्या केल्या.\n",
            "SARS-CoV-2 व्यतिरिक्त, हे MERS-CoV ला देखील लागू होते, जे ड्रॉमडेरी उंटांसाठी चांगले अनुकूलित आहे.\n",
            "कालपर्यंत, बांगलादेशच्या इन्स्टिट्यूट ऑफ एपिडेमियोलॉजी, डिसीज कंट्रोल अँड रिसर्च (आयईडीसीआर) ने नोंदवलेल्या संसर्ग झालेल्या रुग्णांच्या संख्येमध्ये 114 सक्रिय रुग्ण आणि घरी राहणाऱ्या 33 बरे झालेल्या रुग्णांचा समावेश आहे.\n",
            "बहुतांश प्रभावी घटक अज्ञात राहतात किंवा अस्पष्ट असतात कारण अशा घटकांचे किंवा त्यांच्या इष्टतम संयोजनांचे निष्कर्षण आणि पडताळणी करणे कठीण असते.\n",
            "SARS-CoV प्रमाणेच SARS-CoV-2 संसर्गात कमकुवत होऊ शकतो आणि कालांतराने मरू शकतो किंवा मनुष्यांसोबत कमी रोगजनक विषाणू बनू शकतो.\n",
            "18 फेब्रुवारी 2020 रोजी, COVID-19 च्या पहिल्या पॅथोलॉजिकल विश्लेषणाने न्यूमोसाइट्स, हायलाइन झिल्ली निर्मिती आणि इंटरस्टिटियल लिंफोसाइट घुसखोरी आणि या आजाराने मरण पावलेल्या रुग्णाच्या फुफ्फुसातील मल्टीन्यूक्लिएटेड सिन्सिटियल पेशी, व्हायरल इन्फेक्शन आणि ARDS आणि सारख्याच SARS आणि MERS रुग्णांच्या पॅथोलॉजीशी सुसंगत असल्याचे दर्शविले.\n",
            "वन्यजीवांची तस्करी आणि प्राणी तस्करी-विदेशी वन्यजीवांच्या व्यापाराशी संबंधित आरोग्याची जोखीम\n",
            "सीएलटीसाठी सामान्यतः परिघीय रक्ताचा एक नमुना वापरला जातो, जरी रोगप्रतिकार प्रतिसादाचे अनुसरण करण्यासाठी अनुक्रमिक नमुने वापरले जाऊ शकतात.\n",
            "हा विषाणू कदाचित आपल्या वाटेवर असेल आणि आपण तयार असणे आवश्यक आहे, \"योग्य प्रतिसादाच्या उपाययोजनांमुळे जगाला\" त्यातील सर्वात वाईट \"टाळण्यास मदत होऊ शकते.\n",
            "आमची टीम मदत देण्यासाठी आमची मार्गदर्शक तत्वे देखील वेळेवर अद्ययावत करेल.\n",
            "2010-11 मध्ये केलेल्या अभ्यासातून युरोपमध्ये इंटेन्सिव्ह केअर आणि इंटरमीडिएट केअर बेड्सच्या उपलब्धतेत मोठ्या प्रमाणात फरक दिसून आला, जर्मनीमध्ये 29.2 ते पोर्तुगालमध्ये 100,000 लोकसंख्येमागे 4.2 बेड्सपर्यंत.\n",
            "याउलट, जर एचसीओव्ही (HCoV) नव्याने एखाद्या मध्यवर्ती यजमानाला नव्याने सादर केला गेला असेल तर तो नवीन यजमानाशी चांगल्या प्रकारे जुळवून घेत नाही आणि बर्याचदा रोगजनक असतो.\n",
            "त्यामुळे MERS-CoV आणि SARS-CoV च्या तुलनेत SARS-CoV-2 च्या साथीवर नियंत्रण ठेवणे अधिक आव्हानात्मक आहे.\n",
            "प्रथम, जर वटवाघळांनी SARS-CoV-2 चा पूर्वजांचा विषाणू पॅंगोलिनमध्ये संक्रमित केला, तर कोणत्या परिस्थितीत वटवाघळ आणि पॅंगोलिन समान पर्यावरणीय स्थान सामायिक करू शकतात हे पाहणे हिताचे ठरेल.\n",
            "या व्हायरसशी लढण्यासाठी इराणने पाच ट्रिलियन रियालची तरतूद केली आहे.\n",
            "त्याचप्रमाणे, जलाशय यजमान एचसीओव्हीला सतत आणि दीर्घकाळासाठी आश्रय देतो.\n",
            "मात्र, कठोर विलगीकरण आणि अलगीकरणाच्या माध्यमातून हा आजार अखेर नियंत्रणात आणण्यात आला आहे.\n",
            "MERS-CoV हे वटवाघळांपासून ड्रॉमेडरी उंट आणि ड्रॉमेडरी उंटांपासून मानवांमध्ये आंतरप्रजाती संक्रमणाचे उत्कृष्ट उदाहरण म्हणून काम करते.\n",
            "मध्यवर्ती यजमानामध्ये संसर्ग टिकवून ठेवता न आल्यास एचसीओव्ही मृत-शेवट संसर्ग होऊ शकतो.\n",
            "SARS-CoV-2 च्या प्राण्यांच्या उत्पत्तीचा शोध अद्याप सुरू आहे.\n",
            "आता आमच्या मार्गदर्शक सूचनेवर झोऊ एट अल यांनी भाष्य केले, त्यांनी त्यांच्या क्लिनिकल अनुभवावर आधारित एक सोपा स्कोरिंग प्रस्ताव सादर केला.\n",
            "आजारपणादरम्यान अस्वस्थता दूर करण्यासाठी \"सहाय्यक\" उपचार म्हणून अभ्यासातील अनेक औषधे जसे की एनएसएआयडी किंवा ब्रोंकोडायलेटर्स, खालील तक्त्यात समाविष्ट नाहीत.\n",
            "SARS-CoV सह 95% न्यूक्लियोटाइड होमोलॉजी शेअर करणारा बॅट बीटा-CoV आढळला आहे, तर SARS-CoV-2 सह 96% न्यूक्लियोटाइड होमोलॉजी शेअर करणारा बॅट-CoV देखील अस्तित्वात आहे.\n",
            "हे सहसा आईकडून भ्रूणाकडे जात नाही म्हणून विषाणूने प्लेसेंटा ओलांडला किंवा अभ्यासातील महिलांचे प्लेसेंटा खराब झाले किंवा असामान्य होते हे जाणून घेण्यासाठी आणखी संशोधन आवश्यक आहे.\n",
            "11 फेब्रुवारी, 2020 रोजी, 4,021 पुष्टी झालेल्या कोविड-19 रूग्णांसह 8,866 रूग्णांवर मल्टी-सेंटर अभ्यासाने या साथीच्या आजाराचे अधिक अद्ययावत चित्र पुढील प्रमाणे सादर केले (https:// mp. weixin. qc. com/s/UlBi-HX _ rHPXa1qHA2BdA).\n",
            "पण हृदयाच्या छातीत दुखण्यासाठीही आपण बाजूला ठेवू नये\n",
            "अनेक भागात घाबरलेल्या खरेदीमुळे अन्न, टॉयलेट पेपर आणि बाटलीबंद पाणी यासारख्या किराणा जीवनावश्यक वस्तूंपासून शेल्फ साफ करण्यात आले, ज्यामुळे पुरवठ्याची टंचाई निर्माण झाली.\n",
            "हे छातीच्या मध्यभागी आहे.\n",
            "शेती जनावरांच्या आर्थिकदृष्ट्या महत्त्वपूर्ण कोरोना विषाणूंमध्ये पोर्सिन कोरोनाव्हायरस (संसर्गजन्य जठराचा विषाणू, टीजीई) आणि बोवाइन कोरोनाव्हायरस यांचा समावेश आहे, ज्यामुळे तरुण जनावरांमध्ये अतिसार होतो.\n",
            "मला काल ताप आला होता\n",
            "या अधिसूचनांमुळे, वुहानमधील डॉक्टरांना या उद्रेकाविषयी अफवा पसरवल्याबद्दल पोलिसांनी इशारा दिला होता.\n",
            "प्राण्यांचे आश्रयस्थान ओळखणे याचा मानवी रोगांपासून बचाव करण्यावर थेट परिणाम होतो.\n",
            "COVID-19 च्या उद्रेकाला सार्वजनिक आरोग्य प्रतिसादांचा एक भाग म्हणून अनिवार्य संपर्क शोध आणि विलगीकरण, लोकांना संसर्ग, विलगीकरण आणि त्यांच्या कुटुंबीय आणि मित्रांवर कलंक लागण्याच्या परिणामांबद्दल अधिक चिंतित आणि दोषी बनवू शकतात.\n",
            "19 फेब्रुवारीला सिंगापूर रेड क्रॉसने चीनला 2.26 दशलक्ष डॉलर्सची मदत पाठवण्याची घोषणा केली.\n",
            "एचसीओव्ही-एनएल63, एचसीओव्ही-229ई आणि एचसीओव्ही-ओसी43 प्रमाणेच एचसीओव्ही-एचकेयू1 जगभरात आढळले, ज्यामुळे सौम्य श्वसनाचे आजार होतात.\n",
            "1890 चा फ्लू साथीचा आजार या स्पिलओव्हरच्या घटनेमुळे झाला असावा, इन्फ्लूएन्झा विषाणूमुळे नाही, कारण संबंधित वेळ, मज्जातंतूविषयक लक्षणे आणि साथीच्या आजाराचे अज्ञात कारण.\n",
            "सर्व सात एचसीओव्हीचे उंदीर, वटवाघूळ किंवा पाळीव प्राण्यांपासून उत्पत्ती होते.\n",
            "त्यासोबतच तुम्हाला काही श्वसनाचा त्रास होत आहे का?\n",
            "पाळीव प्राणी आणि इतर प्राण्यांची COVID-19 चाचणी पॉझिटिव्ह आली आहे.\n",
            "क्वेस्ट डायग्नोस्टिक्सने 9 मार्च 2020 पर्यंत देशव्यापी कोविड-19 चाचण्या उपलब्ध केल्या.\n",
            "एक नवीन आजार म्हणून, COVID-19 ने नुकताच हजारो रूग्णांमध्ये आपला पूर्ण वैद्यकीय अभ्यासक्रम दाखवण्यास सुरुवात केली आहे.\n",
            "14 फेब्रुवारीपर्यंत जगभरात कोविड-19 ची पुष्टी झालेल्या रुग्णांची संख्या 66,576 वर पोहोचली तेव्हा मृत्यूदर 2% होता.\n",
            "सर्वात प्रभावीपणे, लक्षणे बिघडण्याचा दर (प्रकाशापासून गंभीर पर्यंत) फक्त WM गटापेक्षा WM + TCM गटासाठी लक्षणीयरित्या कमी होता (7.4% विरुद्ध 46.2%) आणि WM फक्त गटापेक्षा WM + TCM गटात मृत्यूदर कमी होता (8.8% विरुद्ध 39%).\n",
            "पहिल्या आणि दुसऱ्या टप्प्यातील चाचण्यांमधील औषध उमेदवारांना अंतिम मंजुरी मिळवण्यासाठी सर्व चाचण्या टप्प्यांमधून उत्तीर्ण होण्याचा कमी दर (12% पेक्षा कमी) असतो.\n",
            "Cytokine storm हा प्रणालीबद्ध दाहक प्रतिसादाचा एक प्रकार आहे ज्यामध्ये TNFishere, IL-1ishere, IL-2, IL-6, IFNnéxere, IFNéxere, IFNéxere आणि MCP-1 यासह अनेक सायटोकीनची मालिका प्रकाशित केली जाते.\n",
            "मानवी आणि सिवेट सार्स-सीओव्हीच्या अलगीकरणांमधील तुलनात्मक विश्लेषणाच्या आधारे, सार्स-सीओव्हीला विविध यजमानांमध्ये, विशेषतः एस प्रथिनांच्या आरबीडीमध्ये उत्परिवर्तनांसह जलद रूपांतरणातून जावे असे मानले जाते.\n",
            "विशेषतः, पॅंगोलिन बीटा-सीओव्ही पॅंगोलिनमध्ये अत्यंत रोगजनक असतात.\n",
            "जपान, दक्षिण कोरिया, मलेशिया आणि सिंगापूरमध्येही फेस मास्कचा मोठ्या प्रमाणावर वापर करण्यात आला आहे.\n",
            "या संदर्भात, SARS-CoV-2 इतर सहा HCoV च्या सामान्य ट्रेंडचे अनुसरण करते.\n",
            "मार्च 2020 मध्ये, SARS-CoV-2 विषाणूचे मुख्य प्रोटीज हे संसर्ग नंतरच्या औषधांचे लक्ष्य म्हणून ओळखले गेले होते.\n",
            "नोवेल कोरोना विषाणूची पहिली घटना 1 डिसेंबर 2019 ला चीनच्या वुहान, हुबेई येथे आढळू शकते.\n",
            "SARS-CoV-2 विषाणूची सर्व वैशिष्ट्ये निसर्गातील संबंधित कोरोना विषाणूंमध्ये आढळतात. मानवी शरीराबाहेर हा विषाणू घरगुती साबणाने मारला जातो, जो त्याचे संरक्षक कवच वितळवतो. SARS-CoV-2 चा मूळ SARS-CoV शी जवळचा संबंध आहे.\n",
            "आणि तुम्ही मला सांगू शकाल की यासोबत तुम्हाला कोणती इतर लक्षणे आहेत?\n",
            "COVID-19 पेक्षा SARS चा मृत्यू दर जास्त आहे (10.91% विरुद्ध 1.44%).\n",
            "स्नायू वेदना इतर लक्षणे किंवा समस्या लक्षात?\n",
            "विशेषज्ञांनी अधोरेखित केले की प्रत्येक व्यक्तीला आरोग्याचा अधिकार आहे, ज्यात अपंग लोक, अल्पसंख्याक गट, वृद्ध लोक, अंतर्गत विस्थापित लोक, बेघर, अत्यंत गरीब परिस्थितीत राहणारे लोक, नजरकैदेत असलेले लोक तसेच निर्वासित आणि सरकारच्या मदतीची गरज असलेल्या इतर अनिर्दिष्ट गटांचा समावेश आहे.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPqneByPxilN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "519ae680-31b8-4be3-d709-a4efe360b233"
      },
      "source": [
        "# to compute bleu scores for the predicitions with a reference file, use the following command\n",
        "# arguments:\n",
        "# pred_fname: file that contains model predictions\n",
        "# ref_fname: file that contains references\n",
        "# src_lang and tgt_lang : the source and target language\n",
        "\n",
        "!bash /content/finetuning/indicTrans/compute_bleu.sh en_mr_outputs.txt /content/finetuning/dataset/test/test.mr 'en' 'mr'\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 500/500 [00:00<00:00, 7296.22it/s]\n",
            "100% 500/500 [00:00<00:00, 6176.47it/s]\n",
            "BLEU+case.mixed+numrefs.1+smooth.exp+tok.none+version.1.5.1 = 15.8 49.0/22.7/11.9/6.6 (BP = 0.917 ratio = 0.920 hyp_len = 11898 ref_len = 12934)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7etV5Lf7mbge"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
